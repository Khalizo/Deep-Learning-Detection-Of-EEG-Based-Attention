{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.EEG_Toolbox import *\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import sys, io\n",
    "import pandas as pd \n",
    "import pickle\n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from braindecode.datasets.xy import create_from_X_y\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet , Deep4Net\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "from collections import namedtuple\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on user 1\n",
      "(2832, 8, 30)\n",
      "(2832,)\n",
      "Datasets created! Time elapsed: 9.665364980697632 seconds\n",
      "Loading data for 1 events and 30 original time points ...\n",
      "Loading data for 1 events and 30 original time points ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-375e2797b979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m#     filter_length_2  = 1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m#     filter_length_3 = 1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mpool_time_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/braindecode/models/deep4.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_chans, n_classes, input_window_samples, final_conv_length, n_filters_time, n_filters_spat, filter_time_length, pool_time_length, pool_time_stride, n_filters_2, filter_length_2, n_filters_3, filter_length_3, n_filters_4, filter_length_4, first_nonlin, first_pool_mode, first_pool_nonlin, later_nonlin, later_pool_mode, later_pool_nonlin, drop_prob, double_time_convs, split_first_layer, batch_norm, batch_norm_alpha, stride_before_pool)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_conv_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             ),\n\u001b[1;32m    218\u001b[0m         )\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    340\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    341\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_channels must be divisible by groups'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mvalid_padding_modes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'circular'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "window_size_list = [1,2,5,10,15,30]\n",
    "results = []\n",
    "label = 'attention'\n",
    "window_size_samples = 30\n",
    "\n",
    "saved_file = \"/cs/home/ybk1/Dissertation/data/all_users_sampled_30_window_annotated_EEG.pickle\"\n",
    "with open(saved_file, 'rb') as handle:\n",
    "    all_tests = pickle.load(handle)\n",
    "users = all_tests.keys()\n",
    "\n",
    "for user in users:\n",
    "    print(\"Working on user {0}\".format(user))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dt = all_tests[user]\n",
    "\n",
    "    X = np.array(dt[\"inputs\"]).transpose(0,2,1).astype(np.float32)\n",
    "    y = dt[label]\n",
    "\n",
    "    #Convert the categories into labels \n",
    "    le = LabelEncoder()\n",
    "    y =  le.fit_transform(y)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "\n",
    "    # Implement Train Test Split\n",
    "    time_start = time.time()\n",
    "    train_X, X_test, train_y, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.20, random_state=42, stratify=train_y)\n",
    "\n",
    "    # standardize per channel\n",
    "    means = train_X.mean(axis=(0,2), keepdims=True)\n",
    "    stds = train_X.std(axis=(0,2), keepdims=True)\n",
    "    train_X = (train_X - means) / (stds)\n",
    "    valid_X = (valid_X - means) / (stds)\n",
    "    X_test = (X_test - means) / (stds)\n",
    "\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "    train_set = create_from_X_y(train_X, train_y, drop_last_window=False)\n",
    "    valid_set = create_from_X_y(valid_X, valid_y, drop_last_window=False)\n",
    "    sys.stdout = save_stdout\n",
    "\n",
    "    print('Datasets created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "    cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "    device = 'cuda' if cuda else 'cpu'\n",
    "    if cuda:\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    seed = 20200220  # random seed to make results reproducible\n",
    "    # Set random seed to be able to reproduce results\n",
    "    set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "    n_classes= len(le.classes_)\n",
    "\n",
    "    # Extract number of chans and time steps from dataset\n",
    "    n_chans = train_set[0][0].shape[0]\n",
    "    input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "    # model =  ShallowFBCSPNet(\n",
    "    #     n_chans,\n",
    "    #     n_classes,\n",
    "    #     input_window_samples=input_window_samples,\n",
    "    #     final_conv_length=\"auto\",\n",
    "    # )\n",
    "\n",
    "    \"\"\"\n",
    "    For 30 samples, filter time_length = 1\n",
    "    For 60 > samples, filter time length is left empty\n",
    "    for 15 samples, filter_time length = 1, filter_length_2 = 1, filter_length_3 = 1\n",
    "    \"\"\"\n",
    "    model =  Deep4Net(\n",
    "        n_chans,\n",
    "        n_classes,\n",
    "        input_window_samples=input_window_samples,\n",
    "        final_conv_length=\"auto\", pool_time_length=1, filter_time_length = 1,\n",
    "    #     filter_length_2  = 1, \n",
    "    #     filter_length_3 = 1,\n",
    "            pool_time_stride=1,\n",
    "    )\n",
    "\n",
    "    # Send model to GPU\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    time_start = time.time()\n",
    "\n",
    "    # These values we found good for shallow network:\n",
    "    # lr = 0.0625 * 0.01\n",
    "    # weight_decay = 0\n",
    "\n",
    "    # For deep4 they should be:\n",
    "    lr = 1 * 0.01\n",
    "    weight_decay = 0.5 * 0.001\n",
    "\n",
    "    batch_size = 32\n",
    "    n_epochs = 50\n",
    "\n",
    "    sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "\n",
    "    clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "        optimizer__lr=lr,\n",
    "        optimizer__weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "        ],\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "    # in the dataset.\n",
    "    clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "    sys.stdout = save_stdout\n",
    "    print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "    y_pred = le.inverse_transform(clf.predict(valid_X))\n",
    "    y_true = le.inverse_transform(valid_y)\n",
    "    r = get_results(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # get results\n",
    "    Results = namedtuple(\"Results\",\"user label n_epochs window_size time num_classes size accuracy bal_acc precision recall f1_score_macro f1_score_micro\")\n",
    "    results.append(Results(user, label, n_epochs, window_size_samples, time.time()-time_start,  n_classes,len(X), r['Accuracy'], r['Balanced Accuracy'], r['Precision'], r['Recall'], \n",
    "                          r['F1 Score Macro'], r['F1 Score Micro']))\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, le.classes_, normalize=True)\n",
    "    plt.savefig(\"results/CNN/confusion/User_{0}_{1}.png\".format(user,label))\n",
    "    #plot loss curve\n",
    "    plot_loss_curve(clf)\n",
    "    plt.savefig(\"results/CNN/loss curves/User_{0}_{1}.png\".format(user,label))\n",
    "    print(\"Finished analysis on User {0}\".format(user))\n",
    "results  = pd.DataFrame(results).to_csv(\"results/CNN/tabulated/DeepCNN_Valid_performance_window_size_{0}_{1}_withclasses.csv\".format(window_size_samples,label), index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # save model \n",
    "# saved_file = \"models/attention_user_1_with_fi.pickle\"\n",
    "# with open(saved_file, 'wb') as handle:            \n",
    "#     pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function RandomState.f>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

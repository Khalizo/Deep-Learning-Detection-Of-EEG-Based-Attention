{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cs/home/ybk1/python/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import scipy.io as sc\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to transfer one column label to one hot label\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29738, 65)\n"
     ]
    }
   ],
   "source": [
    "#  Data loading\n",
    "feature = sc.loadmat(\"S1_nolabel6.mat\")\n",
    "all = feature['S1_nolabel6']\n",
    "\n",
    "print (all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(all)   # mix eeg_all\n",
    "\n",
    "final=2800*10\n",
    "all=all[0:final]\n",
    "feature_all =all[:,0:64]\n",
    "label=all[:,64:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 6)\n"
     ]
    }
   ],
   "source": [
    "#z-score\n",
    "feature_all=preprocessing.scale(feature_all)\n",
    "no_fea=feature_all.shape[-1]\n",
    "label_all=one_hot(label)\n",
    "print (label_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn input feature shape (28000, 64)\n"
     ]
    }
   ],
   "source": [
    "n_classes=6\n",
    "###CNN code,\n",
    "feature_all=feature_all# the input data of CNN\n",
    "print (\"cnn input feature shape\", feature_all.shape)\n",
    "n_fea=feature_all.shape[-1]\n",
    "# label_all=one_hot(label_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_testing (7000, 6)\n",
      "(21000, 64)\n",
      "(7000, 64)\n"
     ]
    }
   ],
   "source": [
    "final=all.shape[0]\n",
    "middle_number=int(final*3/4)\n",
    "feature_training =feature_all[0:middle_number]\n",
    "feature_testing =feature_all[middle_number:final]\n",
    "label_training =label_all[0:middle_number]\n",
    "label_testing =label_all[middle_number:final]\n",
    "label_ww=label_all[middle_number:final]  # for the confusion matrix\n",
    "print (\"label_testing\",label_testing.shape)\n",
    "a=feature_training\n",
    "b=feature_testing\n",
    "print(feature_training.shape)\n",
    "print(feature_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 64)\n"
     ]
    }
   ],
   "source": [
    "keep=1\n",
    "batch_size=final-middle_number\n",
    "n_group=3\n",
    "train_fea=[]\n",
    "for i in range(n_group):\n",
    "    f =a[(0+batch_size*i):(batch_size+batch_size*i)]\n",
    "    train_fea.append(f)\n",
    "print (train_fea[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_label=[]\n",
    "for i in range(n_group):\n",
    "    f =label_training[(0+batch_size*i):(batch_size+batch_size*i), :]\n",
    "    train_label.append(f)\n",
    "print (train_label[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the CNN code\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess3.run(prediction, feed_dict={xs: v_xs, keep_prob: keep})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess3.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: keep})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# def max_pool_2x2(x):\n",
    "#     # stride [1, x_movement, y_movement, 1]\n",
    "#     return tf.nn.max_pool(x, ksize=[1,1,2,1], strides=[1,1,2,1], padding='SAME')\n",
    "def max_pool_1x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,1,2,1], strides=[1,1,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 64, 1)\n",
      "WARNING:tensorflow:From <ipython-input-12-f85701484c28>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-12-f85701484c28>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, n_fea]) # 1*64\n",
    "ys = tf.placeholder(tf.float32, [None, n_classes])  # 2 is the classes of the data\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 1, n_fea, 1])\n",
    "print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([1,1, 1,20]) # patch 1*1, in size is 1, out size is 2\n",
    "b_conv1 = bias_variable([20])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 1*64*2\n",
    "h_pool1 = max_pool_1x2(h_conv1)                          # output size 1*32x2\n",
    "\n",
    "## conv2 layer ##\n",
    "# W_conv2 = weight_variable([1,1, 2, 4]) # patch 1*1, in size 2, out size 4\n",
    "# b_conv2 = bias_variable([4])\n",
    "# h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 1*32*4\n",
    "# h_pool2 = max_pool_1x2(h_conv2)                          # output size 1*16*4\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([int(1*(n_fea/2)*20), 120])\n",
    "b_fc1 = bias_variable([120])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool1, [-1, int(1*(n_fea/2)*20)])\n",
    "h_fc1 = tf.nn.sigmoid(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([120, n_classes])\n",
    "b_fc2 = bias_variable([n_classes])\n",
    "prediction = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# the error between prediction and real data\n",
    "l2 = 0.001 * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=ys))+l2   # Softmax loss\n",
    "train_step = tf.train.AdamOptimizer(0.04).minimize(cross_entropy) # learning rate is 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the step is: 5 ,the acc is 0.32171428 , the cost is 1.9275148\n",
      "the step is: 10 ,the acc is 0.33614287 , the cost is 1.5975415\n",
      "the step is: 15 ,the acc is 0.38742858 , the cost is 1.5022268\n",
      "the step is: 20 ,the acc is 0.3732857 , the cost is 1.5093236\n",
      "the step is: 25 ,the acc is 0.46685714 , the cost is 1.4015162\n",
      "the step is: 30 ,the acc is 0.4632857 , the cost is 1.4010655\n",
      "the step is: 35 ,the acc is 0.46114287 , the cost is 1.385227\n",
      "the step is: 40 ,the acc is 0.47457144 , the cost is 1.3613017\n",
      "the step is: 45 ,the acc is 0.45514286 , the cost is 1.3955327\n",
      "the step is: 50 ,the acc is 0.47614285 , the cost is 1.3993589\n",
      "the step is: 55 ,the acc is 0.53342855 , the cost is 1.2996106\n",
      "the step is: 60 ,the acc is 0.53514284 , the cost is 1.2783434\n",
      "the step is: 65 ,the acc is 0.5224286 , the cost is 1.3051665\n",
      "the step is: 70 ,the acc is 0.5552857 , the cost is 1.2381438\n",
      "the step is: 75 ,the acc is 0.51442856 , the cost is 1.355237\n",
      "the step is: 80 ,the acc is 0.5468571 , the cost is 1.274174\n",
      "the step is: 85 ,the acc is 0.5888571 , the cost is 1.1917373\n",
      "the step is: 90 ,the acc is 0.5354286 , the cost is 1.3083363\n",
      "the step is: 95 ,the acc is 0.5882857 , the cost is 1.2075086\n",
      "the step is: 100 ,the acc is 0.56442857 , the cost is 1.2379596\n",
      "the step is: 105 ,the acc is 0.48257142 , the cost is 1.4072472\n",
      "the step is: 110 ,the acc is 0.58514285 , the cost is 1.226898\n",
      "the step is: 115 ,the acc is 0.57685715 , the cost is 1.2322441\n",
      "the step is: 120 ,the acc is 0.5878571 , the cost is 1.20422\n",
      "the step is: 125 ,the acc is 0.5641429 , the cost is 1.2416471\n",
      "the step is: 130 ,the acc is 0.55714285 , the cost is 1.2913818\n",
      "the step is: 135 ,the acc is 0.6194286 , the cost is 1.1592228\n",
      "the step is: 140 ,the acc is 0.579 , the cost is 1.2284002\n",
      "the step is: 145 ,the acc is 0.568 , the cost is 1.2780287\n",
      "the step is: 150 ,the acc is 0.6134286 , the cost is 1.1786792\n",
      "the step is: 155 ,the acc is 0.6391429 , the cost is 1.1242783\n",
      "the step is: 160 ,the acc is 0.55857146 , the cost is 1.3052146\n",
      "the step is: 165 ,the acc is 0.611 , the cost is 1.1909292\n",
      "the step is: 170 ,the acc is 0.6398571 , the cost is 1.126179\n",
      "the step is: 175 ,the acc is 0.6348571 , the cost is 1.14463\n",
      "the step is: 180 ,the acc is 0.6332857 , the cost is 1.1478428\n",
      "the step is: 185 ,the acc is 0.55385715 , the cost is 1.3255942\n",
      "the step is: 190 ,the acc is 0.6208571 , the cost is 1.2039659\n",
      "the step is: 195 ,the acc is 0.64357144 , the cost is 1.1360376\n",
      "the step is: 200 ,the acc is 0.62 , the cost is 1.1630839\n",
      "the step is: 205 ,the acc is 0.6087143 , the cost is 1.2009789\n",
      "the step is: 210 ,the acc is 0.656 , the cost is 1.1059818\n",
      "the step is: 215 ,the acc is 0.55314285 , the cost is 1.2878245\n",
      "the step is: 220 ,the acc is 0.63528574 , the cost is 1.1489081\n",
      "the step is: 225 ,the acc is 0.63928574 , the cost is 1.1412597\n",
      "the step is: 230 ,the acc is 0.58271426 , the cost is 1.2881583\n",
      "the step is: 235 ,the acc is 0.6168572 , the cost is 1.1872659\n",
      "the step is: 240 ,the acc is 0.64485717 , the cost is 1.1294703\n",
      "the step is: 245 ,the acc is 0.54071426 , the cost is 1.4129755\n",
      "the step is: 250 ,the acc is 0.61985713 , the cost is 1.1962863\n",
      "the step is: 255 ,the acc is 0.6331428 , the cost is 1.1433775\n",
      "the step is: 260 ,the acc is 0.61614287 , the cost is 1.1740369\n",
      "the step is: 265 ,the acc is 0.64442855 , the cost is 1.1218094\n",
      "the step is: 270 ,the acc is 0.61628574 , the cost is 1.1739142\n",
      "the step is: 275 ,the acc is 0.6417143 , the cost is 1.1527814\n",
      "the step is: 280 ,the acc is 0.64114285 , the cost is 1.1166681\n",
      "the step is: 285 ,the acc is 0.6437143 , the cost is 1.1268141\n",
      "the step is: 290 ,the acc is 0.614 , the cost is 1.1945908\n",
      "the step is: 295 ,the acc is 0.58 , the cost is 1.2729002\n",
      "the step is: 300 ,the acc is 0.6407143 , the cost is 1.1448513\n",
      "the step is: 305 ,the acc is 0.6452857 , the cost is 1.1285532\n",
      "the step is: 310 ,the acc is 0.6184286 , the cost is 1.1710261\n",
      "the step is: 315 ,the acc is 0.66985714 , the cost is 1.0804195\n",
      "the step is: 320 ,the acc is 0.6184286 , the cost is 1.1958469\n",
      "the step is: 325 ,the acc is 0.6455714 , the cost is 1.1382588\n",
      "the step is: 330 ,the acc is 0.66885716 , the cost is 1.0878803\n",
      "the step is: 335 ,the acc is 0.6331428 , the cost is 1.1572261\n",
      "the step is: 340 ,the acc is 0.6592857 , the cost is 1.1224647\n",
      "the step is: 345 ,the acc is 0.6471428 , the cost is 1.1418477\n",
      "the step is: 350 ,the acc is 0.61314285 , the cost is 1.1783918\n",
      "the step is: 355 ,the acc is 0.6207143 , the cost is 1.184726\n",
      "the step is: 360 ,the acc is 0.65114284 , the cost is 1.1188279\n",
      "the step is: 365 ,the acc is 0.6025714 , the cost is 1.2129985\n",
      "the step is: 370 ,the acc is 0.6037143 , the cost is 1.2169757\n",
      "the step is: 375 ,the acc is 0.666 , the cost is 1.0933919\n",
      "the step is: 380 ,the acc is 0.66 , the cost is 1.0870485\n",
      "the step is: 385 ,the acc is 0.6452857 , the cost is 1.1357312\n",
      "the step is: 390 ,the acc is 0.6521429 , the cost is 1.1231198\n",
      "the step is: 395 ,the acc is 0.6342857 , the cost is 1.1808434\n",
      "the step is: 400 ,the acc is 0.57614285 , the cost is 1.3057473\n",
      "the step is: 405 ,the acc is 0.6292857 , the cost is 1.18658\n",
      "the step is: 410 ,the acc is 0.65442854 , the cost is 1.1300397\n",
      "the step is: 415 ,the acc is 0.655 , the cost is 1.1107376\n",
      "the step is: 420 ,the acc is 0.63542855 , the cost is 1.1473439\n",
      "the step is: 425 ,the acc is 0.6487143 , the cost is 1.1292998\n",
      "the step is: 430 ,the acc is 0.57271427 , the cost is 1.3079689\n",
      "the step is: 435 ,the acc is 0.6225714 , the cost is 1.190162\n",
      "the step is: 440 ,the acc is 0.658 , the cost is 1.1151446\n",
      "the step is: 445 ,the acc is 0.65171427 , the cost is 1.1271654\n",
      "the step is: 450 ,the acc is 0.65185714 , the cost is 1.1099316\n",
      "the step is: 455 ,the acc is 0.64671427 , the cost is 1.1403992\n",
      "the step is: 460 ,the acc is 0.62871426 , the cost is 1.1869173\n",
      "the step is: 465 ,the acc is 0.6111429 , the cost is 1.2148895\n",
      "the step is: 470 ,the acc is 0.6557143 , the cost is 1.1295531\n",
      "the step is: 475 ,the acc is 0.6761429 , the cost is 1.0697898\n",
      "the step is: 480 ,the acc is 0.62185717 , the cost is 1.1918\n",
      "the step is: 485 ,the acc is 0.6414286 , the cost is 1.1433089\n",
      "the step is: 490 ,the acc is 0.6732857 , the cost is 1.0869105\n",
      "the step is: 495 ,the acc is 0.6241429 , the cost is 1.1901162\n",
      "the step is: 500 ,the acc is 0.62214285 , the cost is 1.1771973\n",
      "the step is: 505 ,the acc is 0.66342854 , the cost is 1.1070505\n",
      "the step is: 510 ,the acc is 0.6627143 , the cost is 1.1027565\n",
      "the step is: 515 ,the acc is 0.6397143 , the cost is 1.1359593\n",
      "the step is: 520 ,the acc is 0.67 , the cost is 1.0946413\n",
      "the step is: 525 ,the acc is 0.69 , the cost is 1.0554483\n",
      "the step is: 530 ,the acc is 0.60157144 , the cost is 1.2290719\n",
      "the step is: 535 ,the acc is 0.6275714 , the cost is 1.1668563\n",
      "the step is: 540 ,the acc is 0.67228574 , the cost is 1.0710164\n",
      "the step is: 545 ,the acc is 0.6718571 , the cost is 1.0778515\n",
      "the step is: 550 ,the acc is 0.66057146 , the cost is 1.1133204\n",
      "the step is: 555 ,the acc is 0.65914285 , the cost is 1.1147373\n",
      "the step is: 560 ,the acc is 0.5535714 , the cost is 1.3652765\n",
      "the step is: 565 ,the acc is 0.62714285 , the cost is 1.1930416\n",
      "the step is: 570 ,the acc is 0.65985715 , the cost is 1.116339\n",
      "the step is: 575 ,the acc is 0.62185717 , the cost is 1.1952338\n",
      "the step is: 580 ,the acc is 0.673 , the cost is 1.0851369\n",
      "the step is: 585 ,the acc is 0.6482857 , the cost is 1.1379709\n",
      "the step is: 590 ,the acc is 0.6654286 , the cost is 1.1087494\n",
      "the step is: 595 ,the acc is 0.6702857 , the cost is 1.1063457\n",
      "the step is: 600 ,the acc is 0.64657146 , the cost is 1.1485302\n",
      "the step is: 605 ,the acc is 0.64657146 , the cost is 1.1696553\n",
      "the step is: 610 ,the acc is 0.65342855 , the cost is 1.1250426\n",
      "the step is: 615 ,the acc is 0.6917143 , the cost is 1.0540447\n",
      "the step is: 620 ,the acc is 0.61957145 , the cost is 1.2201586\n",
      "the step is: 625 ,the acc is 0.6011429 , the cost is 1.2466639\n",
      "the step is: 630 ,the acc is 0.6602857 , the cost is 1.1242867\n",
      "the step is: 635 ,the acc is 0.66071427 , the cost is 1.1050904\n",
      "the step is: 640 ,the acc is 0.66985714 , the cost is 1.0948647\n",
      "the step is: 645 ,the acc is 0.63771427 , the cost is 1.1715395\n",
      "the step is: 650 ,the acc is 0.6677143 , the cost is 1.1011434\n",
      "the step is: 655 ,the acc is 0.64942855 , the cost is 1.1431851\n",
      "the step is: 660 ,the acc is 0.63085717 , the cost is 1.1844695\n",
      "the step is: 665 ,the acc is 0.6578571 , the cost is 1.1205196\n",
      "the step is: 670 ,the acc is 0.5097143 , the cost is 1.4637828\n",
      "the step is: 675 ,the acc is 0.6087143 , the cost is 1.2366083\n",
      "the step is: 680 ,the acc is 0.64757144 , the cost is 1.1595023\n",
      "the step is: 685 ,the acc is 0.63371426 , the cost is 1.1555816\n",
      "the step is: 690 ,the acc is 0.617 , the cost is 1.1931177\n",
      "the step is: 695 ,the acc is 0.63042855 , the cost is 1.1727018\n",
      "the step is: 700 ,the acc is 0.6362857 , the cost is 1.1349162\n",
      "the step is: 705 ,the acc is 0.6695714 , the cost is 1.0857999\n",
      "the step is: 710 ,the acc is 0.64914286 , the cost is 1.1256865\n",
      "the step is: 715 ,the acc is 0.65114284 , the cost is 1.1281538\n",
      "the step is: 720 ,the acc is 0.6677143 , the cost is 1.1018151\n",
      "the step is: 725 ,the acc is 0.5847143 , the cost is 1.2788044\n",
      "the step is: 730 ,the acc is 0.63357145 , the cost is 1.1671215\n",
      "the step is: 735 ,the acc is 0.66 , the cost is 1.1258531\n",
      "the step is: 740 ,the acc is 0.59842855 , the cost is 1.2410032\n",
      "the step is: 745 ,the acc is 0.63757145 , the cost is 1.1573615\n",
      "the step is: 750 ,the acc is 0.646 , the cost is 1.137812\n",
      "the step is: 755 ,the acc is 0.6711429 , the cost is 1.0993859\n",
      "the step is: 760 ,the acc is 0.48628572 , the cost is 1.566553\n",
      "the step is: 765 ,the acc is 0.60057145 , the cost is 1.257\n",
      "the step is: 770 ,the acc is 0.6391429 , the cost is 1.1545582\n",
      "the step is: 775 ,the acc is 0.65157145 , the cost is 1.1155955\n",
      "the step is: 780 ,the acc is 0.5832857 , the cost is 1.3046749\n",
      "the step is: 785 ,the acc is 0.63 , the cost is 1.1709502\n",
      "the step is: 790 ,the acc is 0.6554286 , the cost is 1.1171052\n",
      "the step is: 795 ,the acc is 0.6545714 , the cost is 1.1217495\n",
      "the step is: 800 ,the acc is 0.53828573 , the cost is 1.4115367\n",
      "the step is: 805 ,the acc is 0.60785717 , the cost is 1.2110475\n",
      "the step is: 810 ,the acc is 0.62957144 , the cost is 1.174507\n",
      "the step is: 815 ,the acc is 0.63714284 , the cost is 1.1426154\n",
      "the step is: 820 ,the acc is 0.64085716 , the cost is 1.1300317\n",
      "the step is: 825 ,the acc is 0.65414286 , the cost is 1.1096802\n",
      "the step is: 830 ,the acc is 0.62714285 , the cost is 1.156639\n",
      "the step is: 835 ,the acc is 0.6431429 , the cost is 1.145148\n",
      "the step is: 840 ,the acc is 0.62785715 , the cost is 1.1631969\n",
      "the step is: 845 ,the acc is 0.6108571 , the cost is 1.1898608\n",
      "the step is: 850 ,the acc is 0.6547143 , the cost is 1.108189\n",
      "the step is: 855 ,the acc is 0.6314286 , the cost is 1.158447\n",
      "the step is: 860 ,the acc is 0.63114285 , the cost is 1.1616815\n",
      "the step is: 865 ,the acc is 0.659 , the cost is 1.1164296\n",
      "the step is: 870 ,the acc is 0.6272857 , the cost is 1.1750418\n",
      "the step is: 875 ,the acc is 0.5944286 , the cost is 1.2599034\n",
      "the step is: 880 ,the acc is 0.65314287 , the cost is 1.1377324\n",
      "the step is: 885 ,the acc is 0.6562857 , the cost is 1.1038861\n",
      "the step is: 890 ,the acc is 0.64485717 , the cost is 1.1265603\n",
      "the step is: 895 ,the acc is 0.6438571 , the cost is 1.1401161\n",
      "the step is: 900 ,the acc is 0.64485717 , the cost is 1.1303644\n",
      "the step is: 905 ,the acc is 0.6432857 , the cost is 1.1511235\n",
      "the step is: 910 ,the acc is 0.64442855 , the cost is 1.1459863\n",
      "the step is: 915 ,the acc is 0.61142856 , the cost is 1.1957414\n",
      "the step is: 920 ,the acc is 0.6482857 , the cost is 1.1180464\n",
      "the step is: 925 ,the acc is 0.6712857 , the cost is 1.0764467\n",
      "the step is: 930 ,the acc is 0.64614284 , the cost is 1.1278474\n",
      "the step is: 935 ,the acc is 0.6602857 , the cost is 1.1006391\n",
      "the step is: 940 ,the acc is 0.66385716 , the cost is 1.1045841\n",
      "the step is: 945 ,the acc is 0.6725714 , the cost is 1.071543\n",
      "the step is: 950 ,the acc is 0.6504286 , the cost is 1.122735\n",
      "the step is: 955 ,the acc is 0.6744286 , the cost is 1.0720941\n",
      "the step is: 960 ,the acc is 0.6331428 , the cost is 1.2005205\n",
      "the step is: 965 ,the acc is 0.60985714 , the cost is 1.2218329\n",
      "the step is: 970 ,the acc is 0.65085715 , the cost is 1.1306834\n",
      "the step is: 975 ,the acc is 0.6851429 , the cost is 1.0674189\n",
      "the step is: 980 ,the acc is 0.6668571 , the cost is 1.0920403\n",
      "the step is: 985 ,the acc is 0.64014286 , the cost is 1.148864\n",
      "the step is: 990 ,the acc is 0.6782857 , the cost is 1.0908277\n",
      "the step is: 995 ,the acc is 0.627 , the cost is 1.1936419\n",
      "the step is: 1000 ,the acc is 0.608 , the cost is 1.2217668\n",
      "the step is: 1005 ,the acc is 0.6571429 , the cost is 1.114527\n",
      "the step is: 1010 ,the acc is 0.67157143 , the cost is 1.0819433\n",
      "the step is: 1015 ,the acc is 0.6827143 , the cost is 1.0585785\n",
      "the step is: 1020 ,the acc is 0.63528574 , the cost is 1.1592082\n",
      "the step is: 1025 ,the acc is 0.659 , the cost is 1.0983387\n",
      "the step is: 1030 ,the acc is 0.5945714 , the cost is 1.2702123\n",
      "the step is: 1035 ,the acc is 0.661 , the cost is 1.1048038\n",
      "the step is: 1040 ,the acc is 0.6822857 , the cost is 1.0612806\n",
      "the step is: 1045 ,the acc is 0.67885715 , the cost is 1.0653572\n",
      "the step is: 1050 ,the acc is 0.62285715 , the cost is 1.1913128\n",
      "the step is: 1055 ,the acc is 0.65985715 , the cost is 1.1115568\n",
      "the step is: 1060 ,the acc is 0.6844286 , the cost is 1.0551133\n",
      "the step is: 1065 ,the acc is 0.66485715 , the cost is 1.1011845\n",
      "the step is: 1070 ,the acc is 0.6824286 , the cost is 1.0785584\n",
      "the step is: 1075 ,the acc is 0.6578571 , the cost is 1.1131251\n",
      "the step is: 1080 ,the acc is 0.6415714 , the cost is 1.1449682\n",
      "the step is: 1085 ,the acc is 0.6874286 , the cost is 1.0550686\n",
      "the step is: 1090 ,the acc is 0.6594286 , the cost is 1.1090657\n",
      "the step is: 1095 ,the acc is 0.6898571 , the cost is 1.0535634\n",
      "the step is: 1100 ,the acc is 0.5782857 , the cost is 1.2789768\n",
      "the step is: 1105 ,the acc is 0.6528571 , the cost is 1.1306977\n",
      "the step is: 1110 ,the acc is 0.68614286 , the cost is 1.0722655\n",
      "the step is: 1115 ,the acc is 0.68642855 , the cost is 1.054429\n",
      "the step is: 1120 ,the acc is 0.5367143 , the cost is 1.4429404\n",
      "the step is: 1125 ,the acc is 0.622 , the cost is 1.2342328\n",
      "the step is: 1130 ,the acc is 0.6618571 , the cost is 1.1386458\n",
      "the step is: 1135 ,the acc is 0.67385715 , the cost is 1.1020501\n",
      "the step is: 1140 ,the acc is 0.68214285 , the cost is 1.0804963\n",
      "the step is: 1145 ,the acc is 0.66314286 , the cost is 1.1117245\n",
      "the step is: 1150 ,the acc is 0.69585717 , the cost is 1.0528367\n",
      "the step is: 1155 ,the acc is 0.58114284 , the cost is 1.3432422\n",
      "the step is: 1160 ,the acc is 0.649 , the cost is 1.1572216\n",
      "the step is: 1165 ,the acc is 0.6884286 , the cost is 1.06566\n",
      "the step is: 1170 ,the acc is 0.663 , the cost is 1.119951\n",
      "the step is: 1175 ,the acc is 0.6891429 , the cost is 1.0707291\n",
      "the step is: 1180 ,the acc is 0.6757143 , the cost is 1.0827981\n",
      "the step is: 1185 ,the acc is 0.6725714 , the cost is 1.0877366\n",
      "the step is: 1190 ,the acc is 0.6692857 , the cost is 1.0975128\n",
      "the step is: 1195 ,the acc is 0.6275714 , the cost is 1.1934301\n",
      "the step is: 1200 ,the acc is 0.67628574 , the cost is 1.0978951\n",
      "the step is: 1205 ,the acc is 0.66485715 , the cost is 1.0942284\n",
      "the step is: 1210 ,the acc is 0.6407143 , the cost is 1.1396477\n",
      "the step is: 1215 ,the acc is 0.67628574 , the cost is 1.0837835\n",
      "the step is: 1220 ,the acc is 0.696 , the cost is 1.0466578\n",
      "the step is: 1225 ,the acc is 0.69785714 , the cost is 1.0497074\n",
      "the step is: 1230 ,the acc is 0.6362857 , the cost is 1.1732738\n",
      "the step is: 1235 ,the acc is 0.6382857 , the cost is 1.168724\n",
      "the step is: 1240 ,the acc is 0.6445714 , the cost is 1.1699234\n",
      "the step is: 1245 ,the acc is 0.6415714 , the cost is 1.1741756\n",
      "the step is: 1250 ,the acc is 0.6841428 , the cost is 1.075173\n",
      "the step is: 1255 ,the acc is 0.702 , the cost is 1.0406954\n",
      "the step is: 1260 ,the acc is 0.63214284 , the cost is 1.1889569\n",
      "the step is: 1265 ,the acc is 0.6682857 , the cost is 1.1068544\n",
      "the step is: 1270 ,the acc is 0.69042856 , the cost is 1.0831692\n",
      "the step is: 1275 ,the acc is 0.67957145 , the cost is 1.0805905\n",
      "the step is: 1280 ,the acc is 0.66657144 , the cost is 1.1071659\n",
      "the step is: 1285 ,the acc is 0.69285715 , the cost is 1.0645186\n",
      "the step is: 1290 ,the acc is 0.67457145 , the cost is 1.1025624\n",
      "the step is: 1295 ,the acc is 0.699 , the cost is 1.0551399\n",
      "the step is: 1300 ,the acc is 0.6447143 , the cost is 1.1584847\n",
      "the step is: 1305 ,the acc is 0.68685716 , the cost is 1.0742811\n",
      "the step is: 1310 ,the acc is 0.6865714 , the cost is 1.0646068\n",
      "the step is: 1315 ,the acc is 0.67728573 , the cost is 1.0672894\n",
      "the step is: 1320 ,the acc is 0.6668571 , the cost is 1.1243546\n",
      "the step is: 1325 ,the acc is 0.68685716 , the cost is 1.0571402\n",
      "the step is: 1330 ,the acc is 0.6255714 , the cost is 1.2662029\n",
      "the step is: 1335 ,the acc is 0.6654286 , the cost is 1.1471119\n",
      "the step is: 1340 ,the acc is 0.6851429 , the cost is 1.0943973\n",
      "the step is: 1345 ,the acc is 0.6312857 , the cost is 1.1843184\n",
      "the step is: 1350 ,the acc is 0.65842855 , the cost is 1.1304555\n",
      "the step is: 1355 ,the acc is 0.678 , the cost is 1.0673932\n",
      "the step is: 1360 ,the acc is 0.6941429 , the cost is 1.035922\n",
      "the step is: 1365 ,the acc is 0.624 , the cost is 1.1924926\n",
      "the step is: 1370 ,the acc is 0.682 , the cost is 1.0909677\n",
      "the step is: 1375 ,the acc is 0.695 , the cost is 1.059906\n",
      "the step is: 1380 ,the acc is 0.55614287 , the cost is 1.3388537\n",
      "the step is: 1385 ,the acc is 0.68457144 , the cost is 1.0849669\n",
      "the step is: 1390 ,the acc is 0.6947143 , the cost is 1.0615478\n",
      "the step is: 1395 ,the acc is 0.6662857 , the cost is 1.123677\n",
      "the step is: 1400 ,the acc is 0.6472857 , the cost is 1.1362067\n",
      "the step is: 1405 ,the acc is 0.661 , the cost is 1.1065422\n",
      "the step is: 1410 ,the acc is 0.6578571 , the cost is 1.1339899\n",
      "the step is: 1415 ,the acc is 0.6991429 , the cost is 1.0551546\n",
      "the step is: 1420 ,the acc is 0.6837143 , the cost is 1.0791843\n",
      "the step is: 1425 ,the acc is 0.6965714 , the cost is 1.0629182\n",
      "the step is: 1430 ,the acc is 0.646 , the cost is 1.1484184\n",
      "the step is: 1435 ,the acc is 0.65842855 , the cost is 1.1491629\n",
      "the step is: 1440 ,the acc is 0.6362857 , the cost is 1.2050657\n",
      "the step is: 1445 ,the acc is 0.64985716 , the cost is 1.1547279\n",
      "the step is: 1450 ,the acc is 0.67971426 , the cost is 1.0749266\n",
      "the step is: 1455 ,the acc is 0.703 , the cost is 1.0395551\n",
      "the step is: 1460 ,the acc is 0.68042856 , the cost is 1.0729057\n",
      "the step is: 1465 ,the acc is 0.6464286 , the cost is 1.1568179\n",
      "the step is: 1470 ,the acc is 0.6761429 , the cost is 1.1180619\n",
      "the step is: 1475 ,the acc is 0.65171427 , the cost is 1.1307108\n",
      "the step is: 1480 ,the acc is 0.66571426 , the cost is 1.1091553\n",
      "the step is: 1485 ,the acc is 0.667 , the cost is 1.1030675\n",
      "the step is: 1490 ,the acc is 0.6867143 , the cost is 1.0691017\n",
      "the step is: 1495 ,the acc is 0.6817143 , the cost is 1.080257\n",
      "the shape of cnn output features (28000, 64) (28000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "sess3 = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess3.run(init)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "step = 1\n",
    "while step < 1500:\n",
    "    for i in range(n_group):\n",
    "        sess3.run(train_step, feed_dict={xs: train_fea[i], ys: train_label[i], keep_prob:keep})\n",
    "    if step % 5 == 0:\n",
    "        cost=sess3.run(cross_entropy, feed_dict={xs: b, ys: label_testing, keep_prob: keep})\n",
    "        acc_cnn_t=compute_accuracy(b, label_testing)\n",
    "        print('the step is:',step,',the acc is',acc_cnn_t,', the cost is', cost)\n",
    "    step+=1\n",
    "acc_cnn=compute_accuracy(b, label_testing)\n",
    "time2=time.clock()\n",
    "feature_all_cnn=sess3.run(h_fc1_drop, feed_dict={xs: feature_all, keep_prob: keep})\n",
    "print (\"the shape of cnn output features\",feature_all.shape,label_all.shape)\n",
    "\n",
    "time3=time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######RNN\n",
    "feature_all=feature_all\n",
    "no_fea=feature_all.shape[-1]\n",
    "print no_fea\n",
    "feature_all =feature_all.reshape([final,1,no_fea])\n",
    "print tf.argmax(label_all,1)\n",
    "\n",
    "\n",
    "print label_all.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

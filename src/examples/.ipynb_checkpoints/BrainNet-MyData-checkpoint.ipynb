{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import scipy.io as sc\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to transfer one column label to one hot label\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29738, 65)\n"
     ]
    }
   ],
   "source": [
    "#  Data loading\n",
    "feature = sc.loadmat(\"S1_nolabel6.mat\")\n",
    "all = feature['S1_nolabel6']\n",
    "\n",
    "print (all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(all)   # mix eeg_all\n",
    "\n",
    "final=2800*10\n",
    "all=all[0:final]\n",
    "feature_all =all[:,0:64]\n",
    "label=all[:,64:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 6)\n"
     ]
    }
   ],
   "source": [
    "#z-score\n",
    "feature_all=preprocessing.scale(feature_all)\n",
    "no_fea=feature_all.shape[-1]\n",
    "label_all=one_hot(label)\n",
    "print (label_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn input feature shape (28000, 64)\n"
     ]
    }
   ],
   "source": [
    "n_classes=6\n",
    "###CNN code,\n",
    "feature_all=feature_all# the input data of CNN\n",
    "print (\"cnn input feature shape\", feature_all.shape)\n",
    "n_fea=feature_all.shape[-1]\n",
    "# label_all=one_hot(label_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_testing (7000, 6)\n",
      "(21000, 64)\n",
      "(7000, 64)\n"
     ]
    }
   ],
   "source": [
    "final=all.shape[0]\n",
    "middle_number=int(final*3/4)\n",
    "feature_training =feature_all[0:middle_number]\n",
    "feature_testing =feature_all[middle_number:final]\n",
    "label_training =label_all[0:middle_number]\n",
    "label_testing =label_all[middle_number:final]\n",
    "label_ww=label_all[middle_number:final]  # for the confusion matrix\n",
    "print (\"label_testing\",label_testing.shape)\n",
    "a=feature_training\n",
    "b=feature_testing\n",
    "print(feature_training.shape)\n",
    "print(feature_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 64)\n"
     ]
    }
   ],
   "source": [
    "keep=1\n",
    "batch_size=final-middle_number\n",
    "n_group=3\n",
    "train_fea=[]\n",
    "for i in range(n_group):\n",
    "    f =a[(0+batch_size*i):(batch_size+batch_size*i)]\n",
    "    train_fea.append(f)\n",
    "print (train_fea[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_label=[]\n",
    "for i in range(n_group):\n",
    "    f =label_training[(0+batch_size*i):(batch_size+batch_size*i), :]\n",
    "    train_label.append(f)\n",
    "print (train_label[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the CNN code\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess3.run(prediction, feed_dict={xs: v_xs, keep_prob: keep})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess3.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: keep})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# def max_pool_2x2(x):\n",
    "#     # stride [1, x_movement, y_movement, 1]\n",
    "#     return tf.nn.max_pool(x, ksize=[1,1,2,1], strides=[1,1,2,1], padding='SAME')\n",
    "def max_pool_1x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,1,2,1], strides=[1,1,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 64, 1)\n",
      "WARNING:tensorflow:From <ipython-input-20-f85701484c28>:26: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-20-f85701484c28>:35: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, n_fea]) # 1*64\n",
    "ys = tf.placeholder(tf.float32, [None, n_classes])  # 2 is the classes of the data\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 1, n_fea, 1])\n",
    "print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([1,1, 1,20]) # patch 1*1, in size is 1, out size is 2\n",
    "b_conv1 = bias_variable([20])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 1*64*2\n",
    "h_pool1 = max_pool_1x2(h_conv1)                          # output size 1*32x2\n",
    "\n",
    "## conv2 layer ##\n",
    "# W_conv2 = weight_variable([1,1, 2, 4]) # patch 1*1, in size 2, out size 4\n",
    "# b_conv2 = bias_variable([4])\n",
    "# h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 1*32*4\n",
    "# h_pool2 = max_pool_1x2(h_conv2)                          # output size 1*16*4\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([int(1*(n_fea/2)*20), 120])\n",
    "b_fc1 = bias_variable([120])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool1, [-1, int(1*(n_fea/2)*20)])\n",
    "h_fc1 = tf.nn.sigmoid(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([120, n_classes])\n",
    "b_fc2 = bias_variable([n_classes])\n",
    "prediction = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# the error between prediction and real data\n",
    "l2 = 0.001 * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=ys))+l2   # Softmax loss\n",
    "train_step = tf.train.AdamOptimizer(0.04).minimize(cross_entropy) # learning rate is 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the step is: 5 ,the acc is 0.3272857 , the cost is 1.9305128\n",
      "the step is: 10 ,the acc is 0.36814284 , the cost is 1.590658\n",
      "the step is: 15 ,the acc is 0.39085713 , the cost is 1.5091811\n",
      "the step is: 20 ,the acc is 0.43285716 , the cost is 1.4587798\n",
      "the step is: 25 ,the acc is 0.45371428 , the cost is 1.4091653\n",
      "the step is: 30 ,the acc is 0.47471428 , the cost is 1.3827319\n",
      "the step is: 35 ,the acc is 0.47685716 , the cost is 1.3797286\n",
      "the step is: 40 ,the acc is 0.509 , the cost is 1.3178829\n",
      "the step is: 45 ,the acc is 0.52085716 , the cost is 1.3077307\n",
      "the step is: 50 ,the acc is 0.55 , the cost is 1.2508254\n",
      "the step is: 55 ,the acc is 0.558 , the cost is 1.2523178\n",
      "the step is: 60 ,the acc is 0.54071426 , the cost is 1.2833279\n",
      "the step is: 65 ,the acc is 0.5855714 , the cost is 1.1959289\n",
      "the step is: 70 ,the acc is 0.55385715 , the cost is 1.2511188\n",
      "the step is: 75 ,the acc is 0.5952857 , the cost is 1.172133\n",
      "the step is: 80 ,the acc is 0.5902857 , the cost is 1.2051319\n",
      "the step is: 85 ,the acc is 0.5882857 , the cost is 1.1972333\n",
      "the step is: 90 ,the acc is 0.6142857 , the cost is 1.1539987\n",
      "the step is: 95 ,the acc is 0.59 , the cost is 1.2027081\n",
      "the step is: 100 ,the acc is 0.621 , the cost is 1.1311291\n",
      "the step is: 105 ,the acc is 0.5672857 , the cost is 1.268622\n",
      "the step is: 110 ,the acc is 0.5964286 , the cost is 1.20752\n",
      "the step is: 115 ,the acc is 0.625 , the cost is 1.1398668\n",
      "the step is: 120 ,the acc is 0.6267143 , the cost is 1.1448708\n",
      "the step is: 125 ,the acc is 0.5674286 , the cost is 1.2692696\n",
      "the step is: 130 ,the acc is 0.61214286 , the cost is 1.1795824\n",
      "the step is: 135 ,the acc is 0.63371426 , the cost is 1.1280974\n",
      "the step is: 140 ,the acc is 0.6355714 , the cost is 1.1206902\n",
      "the step is: 145 ,the acc is 0.581 , the cost is 1.2598369\n",
      "the step is: 150 ,the acc is 0.627 , the cost is 1.1829882\n",
      "the step is: 155 ,the acc is 0.6488571 , the cost is 1.1071925\n",
      "the step is: 160 ,the acc is 0.617 , the cost is 1.1738045\n",
      "the step is: 165 ,the acc is 0.6282857 , the cost is 1.1616127\n",
      "the step is: 170 ,the acc is 0.66085714 , the cost is 1.0821092\n",
      "the step is: 175 ,the acc is 0.6075714 , the cost is 1.2142591\n",
      "the step is: 180 ,the acc is 0.6382857 , the cost is 1.1240104\n",
      "the step is: 185 ,the acc is 0.6595714 , the cost is 1.0984882\n",
      "the step is: 190 ,the acc is 0.637 , the cost is 1.1299746\n",
      "the step is: 195 ,the acc is 0.665 , the cost is 1.0730522\n",
      "the step is: 200 ,the acc is 0.57 , the cost is 1.287865\n",
      "the step is: 205 ,the acc is 0.636 , the cost is 1.1519588\n",
      "the step is: 210 ,the acc is 0.6628571 , the cost is 1.0797561\n",
      "the step is: 215 ,the acc is 0.6432857 , the cost is 1.1679739\n",
      "the step is: 220 ,the acc is 0.5748571 , the cost is 1.2543414\n",
      "the step is: 225 ,the acc is 0.64 , the cost is 1.1291823\n",
      "the step is: 230 ,the acc is 0.67214286 , the cost is 1.0638685\n",
      "the step is: 235 ,the acc is 0.61457145 , the cost is 1.1882272\n",
      "the step is: 240 ,the acc is 0.6725714 , the cost is 1.0774264\n",
      "the step is: 245 ,the acc is 0.68285716 , the cost is 1.0511812\n",
      "the step is: 250 ,the acc is 0.63514286 , the cost is 1.1493982\n",
      "the step is: 255 ,the acc is 0.6021429 , the cost is 1.2212126\n",
      "the step is: 260 ,the acc is 0.66385716 , the cost is 1.1010302\n",
      "the step is: 265 ,the acc is 0.67814285 , the cost is 1.0562048\n",
      "the step is: 270 ,the acc is 0.5831429 , the cost is 1.2549186\n",
      "the step is: 275 ,the acc is 0.64985716 , the cost is 1.1266828\n",
      "the step is: 280 ,the acc is 0.67 , the cost is 1.0685952\n",
      "the step is: 285 ,the acc is 0.68685716 , the cost is 1.044169\n",
      "the step is: 290 ,the acc is 0.65257144 , the cost is 1.1193252\n",
      "the step is: 295 ,the acc is 0.60485715 , the cost is 1.2523806\n",
      "the step is: 300 ,the acc is 0.6587143 , the cost is 1.11726\n",
      "the step is: 305 ,the acc is 0.67071426 , the cost is 1.0720762\n",
      "the step is: 310 ,the acc is 0.64085716 , the cost is 1.1376816\n",
      "the step is: 315 ,the acc is 0.66014284 , the cost is 1.1140164\n",
      "the step is: 320 ,the acc is 0.68542856 , the cost is 1.0502605\n",
      "the step is: 325 ,the acc is 0.63514286 , the cost is 1.1627625\n",
      "the step is: 330 ,the acc is 0.66514283 , the cost is 1.1042843\n",
      "the step is: 335 ,the acc is 0.655 , the cost is 1.1108814\n",
      "the step is: 340 ,the acc is 0.6717143 , the cost is 1.0803865\n",
      "the step is: 345 ,the acc is 0.58585715 , the cost is 1.2405182\n",
      "the step is: 350 ,the acc is 0.66785717 , the cost is 1.0901643\n",
      "the step is: 355 ,the acc is 0.6564286 , the cost is 1.0918626\n",
      "the step is: 360 ,the acc is 0.66742855 , the cost is 1.0912826\n",
      "the step is: 365 ,the acc is 0.6815714 , the cost is 1.0598106\n",
      "the step is: 370 ,the acc is 0.64285713 , the cost is 1.1444106\n",
      "the step is: 375 ,the acc is 0.6592857 , the cost is 1.1101214\n",
      "the step is: 380 ,the acc is 0.6802857 , the cost is 1.0652397\n",
      "the step is: 385 ,the acc is 0.65328574 , the cost is 1.1058462\n",
      "the step is: 390 ,the acc is 0.6452857 , the cost is 1.1575123\n",
      "the step is: 395 ,the acc is 0.68614286 , the cost is 1.0634931\n",
      "the step is: 400 ,the acc is 0.6827143 , the cost is 1.0663793\n",
      "the step is: 405 ,the acc is 0.6552857 , the cost is 1.1248473\n",
      "the step is: 410 ,the acc is 0.64042854 , the cost is 1.1632165\n",
      "the step is: 415 ,the acc is 0.65342855 , the cost is 1.1334298\n",
      "the step is: 420 ,the acc is 0.6802857 , the cost is 1.0843765\n",
      "the step is: 425 ,the acc is 0.6597143 , the cost is 1.1246278\n",
      "the step is: 430 ,the acc is 0.66 , the cost is 1.1185379\n",
      "the step is: 435 ,the acc is 0.6784286 , the cost is 1.0576285\n",
      "the step is: 440 ,the acc is 0.64585716 , the cost is 1.1554729\n",
      "the step is: 445 ,the acc is 0.6554286 , the cost is 1.126792\n",
      "the step is: 450 ,the acc is 0.655 , the cost is 1.1338145\n",
      "the step is: 455 ,the acc is 0.68471426 , the cost is 1.0736248\n",
      "the step is: 460 ,the acc is 0.69685715 , the cost is 1.0390689\n",
      "the step is: 465 ,the acc is 0.70585716 , the cost is 1.0176103\n",
      "the step is: 470 ,the acc is 0.61142856 , the cost is 1.2360815\n",
      "the step is: 475 ,the acc is 0.68057144 , the cost is 1.1052336\n",
      "the step is: 480 ,the acc is 0.68814284 , the cost is 1.0624503\n",
      "the step is: 485 ,the acc is 0.56042856 , the cost is 1.3508662\n",
      "the step is: 490 ,the acc is 0.6388571 , the cost is 1.1861453\n",
      "the step is: 495 ,the acc is 0.6692857 , the cost is 1.11808\n",
      "the step is: 500 ,the acc is 0.6037143 , the cost is 1.2248933\n",
      "the step is: 505 ,the acc is 0.633 , the cost is 1.2010612\n",
      "the step is: 510 ,the acc is 0.68285716 , the cost is 1.088998\n",
      "the step is: 515 ,the acc is 0.68185717 , the cost is 1.0771077\n",
      "the step is: 520 ,the acc is 0.6594286 , the cost is 1.1461445\n",
      "the step is: 525 ,the acc is 0.6742857 , the cost is 1.1020961\n",
      "the step is: 530 ,the acc is 0.67557144 , the cost is 1.0813617\n",
      "the step is: 535 ,the acc is 0.6514286 , the cost is 1.144759\n",
      "the step is: 540 ,the acc is 0.66014284 , the cost is 1.1173112\n",
      "the step is: 545 ,the acc is 0.68642855 , the cost is 1.068936\n",
      "the step is: 550 ,the acc is 0.6782857 , the cost is 1.0795149\n",
      "the step is: 555 ,the acc is 0.6974286 , the cost is 1.0480545\n",
      "the step is: 560 ,the acc is 0.6414286 , the cost is 1.1648962\n",
      "the step is: 565 ,the acc is 0.6265714 , the cost is 1.1844859\n",
      "the step is: 570 ,the acc is 0.6765714 , the cost is 1.0707989\n",
      "the step is: 575 ,the acc is 0.6504286 , the cost is 1.149685\n",
      "the step is: 580 ,the acc is 0.6841428 , the cost is 1.0761485\n",
      "the step is: 585 ,the acc is 0.6765714 , the cost is 1.0710479\n",
      "the step is: 590 ,the acc is 0.64614284 , the cost is 1.137274\n",
      "the step is: 595 ,the acc is 0.678 , the cost is 1.0812812\n",
      "the step is: 600 ,the acc is 0.6877143 , the cost is 1.0527058\n",
      "the step is: 605 ,the acc is 0.6292857 , the cost is 1.1985523\n",
      "the step is: 610 ,the acc is 0.67 , the cost is 1.1210003\n",
      "the step is: 615 ,the acc is 0.6834286 , the cost is 1.0866004\n",
      "the step is: 620 ,the acc is 0.6767143 , the cost is 1.0785407\n",
      "the step is: 625 ,the acc is 0.64414287 , the cost is 1.1829488\n",
      "the step is: 630 ,the acc is 0.625 , the cost is 1.2046458\n",
      "the step is: 635 ,the acc is 0.67 , the cost is 1.1192399\n",
      "the step is: 640 ,the acc is 0.67785716 , the cost is 1.0804156\n",
      "the step is: 645 ,the acc is 0.65657145 , the cost is 1.1058302\n",
      "the step is: 650 ,the acc is 0.6992857 , the cost is 1.049967\n",
      "the step is: 655 ,the acc is 0.6865714 , the cost is 1.0729481\n",
      "the step is: 660 ,the acc is 0.67557144 , the cost is 1.0861094\n",
      "the step is: 665 ,the acc is 0.69757146 , the cost is 1.0449412\n",
      "the step is: 670 ,the acc is 0.60085714 , the cost is 1.3256986\n",
      "the step is: 675 ,the acc is 0.624 , the cost is 1.2284008\n",
      "the step is: 680 ,the acc is 0.6704286 , the cost is 1.1058578\n",
      "the step is: 685 ,the acc is 0.6792857 , the cost is 1.073469\n",
      "the step is: 690 ,the acc is 0.55314285 , the cost is 1.3232218\n",
      "the step is: 695 ,the acc is 0.6255714 , the cost is 1.2143246\n",
      "the step is: 700 ,the acc is 0.6802857 , the cost is 1.0887735\n",
      "the step is: 705 ,the acc is 0.6702857 , the cost is 1.1019013\n",
      "the step is: 710 ,the acc is 0.65442854 , the cost is 1.1336261\n",
      "the step is: 715 ,the acc is 0.70214283 , the cost is 1.0401134\n",
      "the step is: 720 ,the acc is 0.6807143 , the cost is 1.0761456\n",
      "the step is: 725 ,the acc is 0.67985713 , the cost is 1.0797927\n",
      "the step is: 730 ,the acc is 0.6932857 , the cost is 1.0348012\n",
      "the step is: 735 ,the acc is 0.5847143 , the cost is 1.3119951\n",
      "the step is: 740 ,the acc is 0.657 , the cost is 1.1583985\n",
      "the step is: 745 ,the acc is 0.6858571 , the cost is 1.0686789\n",
      "the step is: 750 ,the acc is 0.70042855 , the cost is 1.0402641\n",
      "the step is: 755 ,the acc is 0.68285716 , the cost is 1.0756048\n",
      "the step is: 760 ,the acc is 0.65685713 , the cost is 1.1320689\n",
      "the step is: 765 ,the acc is 0.70028573 , the cost is 1.0439155\n",
      "the step is: 770 ,the acc is 0.65242857 , the cost is 1.1376667\n",
      "the step is: 775 ,the acc is 0.6942857 , the cost is 1.0608866\n",
      "the step is: 780 ,the acc is 0.7135714 , the cost is 1.0191581\n",
      "the step is: 785 ,the acc is 0.69857144 , the cost is 1.044041\n",
      "the step is: 790 ,the acc is 0.59414285 , the cost is 1.2817711\n",
      "the step is: 795 ,the acc is 0.66385716 , the cost is 1.1598209\n",
      "the step is: 800 ,the acc is 0.61971426 , the cost is 1.209225\n",
      "the step is: 805 ,the acc is 0.676 , the cost is 1.1249001\n",
      "the step is: 810 ,the acc is 0.67785716 , the cost is 1.091198\n",
      "the step is: 815 ,the acc is 0.66785717 , the cost is 1.1077384\n",
      "the step is: 820 ,the acc is 0.69957143 , the cost is 1.055478\n",
      "the step is: 825 ,the acc is 0.5814286 , the cost is 1.2902312\n",
      "the step is: 830 ,the acc is 0.65257144 , the cost is 1.1453972\n",
      "the step is: 835 ,the acc is 0.679 , the cost is 1.0785714\n",
      "the step is: 840 ,the acc is 0.63542855 , the cost is 1.1876243\n",
      "the step is: 845 ,the acc is 0.57257146 , the cost is 1.3045158\n",
      "the step is: 850 ,the acc is 0.6488571 , the cost is 1.1583298\n",
      "the step is: 855 ,the acc is 0.66014284 , the cost is 1.1248859\n",
      "the step is: 860 ,the acc is 0.6587143 , the cost is 1.1171476\n",
      "the step is: 865 ,the acc is 0.68185717 , the cost is 1.0696423\n",
      "the step is: 870 ,the acc is 0.6912857 , the cost is 1.0583166\n",
      "the step is: 875 ,the acc is 0.647 , the cost is 1.1410319\n",
      "the step is: 880 ,the acc is 0.69614285 , the cost is 1.0451629\n",
      "the step is: 885 ,the acc is 0.6564286 , the cost is 1.1201237\n",
      "the step is: 890 ,the acc is 0.67628574 , the cost is 1.0835786\n",
      "the step is: 895 ,the acc is 0.6844286 , the cost is 1.0725973\n",
      "the step is: 900 ,the acc is 0.6777143 , the cost is 1.0683279\n",
      "the step is: 905 ,the acc is 0.68457144 , the cost is 1.0652329\n",
      "the step is: 910 ,the acc is 0.6535714 , the cost is 1.1189836\n",
      "the step is: 915 ,the acc is 0.6932857 , the cost is 1.0401518\n",
      "the step is: 920 ,the acc is 0.6697143 , the cost is 1.0785528\n",
      "the step is: 925 ,the acc is 0.629 , the cost is 1.1784438\n",
      "the step is: 930 ,the acc is 0.6744286 , the cost is 1.0951521\n",
      "the step is: 935 ,the acc is 0.68642855 , the cost is 1.0538083\n",
      "the step is: 940 ,the acc is 0.6654286 , the cost is 1.0997007\n",
      "the step is: 945 ,the acc is 0.6101429 , the cost is 1.2454292\n",
      "the step is: 950 ,the acc is 0.6645714 , the cost is 1.1298945\n",
      "the step is: 955 ,the acc is 0.6768571 , the cost is 1.0921319\n",
      "the step is: 960 ,the acc is 0.662 , the cost is 1.1145371\n",
      "the step is: 965 ,the acc is 0.6614286 , the cost is 1.12796\n",
      "the step is: 970 ,the acc is 0.686 , the cost is 1.0744832\n",
      "the step is: 975 ,the acc is 0.67242855 , the cost is 1.0935893\n",
      "the step is: 980 ,the acc is 0.6357143 , the cost is 1.1906743\n",
      "the step is: 985 ,the acc is 0.6462857 , the cost is 1.1614866\n",
      "the step is: 990 ,the acc is 0.69042856 , the cost is 1.0701478\n",
      "the step is: 995 ,the acc is 0.6437143 , the cost is 1.1726052\n",
      "the step is: 1000 ,the acc is 0.6445714 , the cost is 1.1655802\n",
      "the step is: 1005 ,the acc is 0.62057143 , the cost is 1.2181411\n",
      "the step is: 1010 ,the acc is 0.6775714 , the cost is 1.0911238\n",
      "the step is: 1015 ,the acc is 0.6874286 , the cost is 1.0825605\n",
      "the step is: 1020 ,the acc is 0.691 , the cost is 1.0563428\n",
      "the step is: 1025 ,the acc is 0.6374286 , the cost is 1.2057378\n",
      "the step is: 1030 ,the acc is 0.64857143 , the cost is 1.1453106\n",
      "the step is: 1035 ,the acc is 0.6822857 , the cost is 1.0775703\n",
      "the step is: 1040 ,the acc is 0.64657146 , the cost is 1.1522238\n",
      "the step is: 1045 ,the acc is 0.6711429 , the cost is 1.0960094\n",
      "the step is: 1050 ,the acc is 0.67785716 , the cost is 1.0839167\n",
      "the step is: 1055 ,the acc is 0.66257143 , the cost is 1.1026782\n",
      "the step is: 1060 ,the acc is 0.65757143 , the cost is 1.1302061\n",
      "the step is: 1065 ,the acc is 0.6751429 , the cost is 1.0825393\n",
      "the step is: 1070 ,the acc is 0.67 , the cost is 1.0987484\n",
      "the step is: 1075 ,the acc is 0.66242856 , the cost is 1.0909923\n",
      "the step is: 1080 ,the acc is 0.6192857 , the cost is 1.197827\n",
      "the step is: 1085 ,the acc is 0.6891429 , the cost is 1.0723797\n",
      "the step is: 1090 ,the acc is 0.6892857 , the cost is 1.0620924\n",
      "the step is: 1095 ,the acc is 0.70014286 , the cost is 1.0297723\n",
      "the step is: 1100 ,the acc is 0.629 , the cost is 1.1841031\n",
      "the step is: 1105 ,the acc is 0.6727143 , the cost is 1.1004792\n",
      "the step is: 1110 ,the acc is 0.70442855 , the cost is 1.0311881\n",
      "the step is: 1115 ,the acc is 0.6002857 , the cost is 1.2706765\n",
      "the step is: 1120 ,the acc is 0.6594286 , the cost is 1.1366446\n",
      "the step is: 1125 ,the acc is 0.6972857 , the cost is 1.0421516\n",
      "the step is: 1130 ,the acc is 0.7104286 , the cost is 1.0131514\n",
      "the step is: 1135 ,the acc is 0.596 , the cost is 1.3830198\n",
      "the step is: 1140 ,the acc is 0.63114285 , the cost is 1.2003955\n",
      "the step is: 1145 ,the acc is 0.6645714 , the cost is 1.1219928\n",
      "the step is: 1150 ,the acc is 0.663 , the cost is 1.1182724\n",
      "the step is: 1155 ,the acc is 0.6572857 , the cost is 1.1166588\n",
      "the step is: 1160 ,the acc is 0.61785716 , the cost is 1.1887904\n",
      "the step is: 1165 ,the acc is 0.66257143 , the cost is 1.1092402\n",
      "the step is: 1170 ,the acc is 0.6578571 , the cost is 1.1260942\n",
      "the step is: 1175 ,the acc is 0.6802857 , the cost is 1.0795485\n",
      "the step is: 1180 ,the acc is 0.68128574 , the cost is 1.0535104\n",
      "the step is: 1185 ,the acc is 0.56 , the cost is 1.3434625\n",
      "the step is: 1190 ,the acc is 0.63514286 , the cost is 1.170523\n",
      "the step is: 1195 ,the acc is 0.6502857 , the cost is 1.1262032\n",
      "the step is: 1200 ,the acc is 0.64014286 , the cost is 1.1617938\n",
      "the step is: 1205 ,the acc is 0.6647143 , the cost is 1.1042926\n",
      "the step is: 1210 ,the acc is 0.6622857 , the cost is 1.1082908\n",
      "the step is: 1215 ,the acc is 0.6727143 , the cost is 1.090563\n",
      "the step is: 1220 ,the acc is 0.6277143 , the cost is 1.2013434\n",
      "the step is: 1225 ,the acc is 0.67142856 , the cost is 1.1092322\n",
      "the step is: 1230 ,the acc is 0.67957145 , the cost is 1.070461\n",
      "the step is: 1235 ,the acc is 0.6504286 , the cost is 1.1228817\n",
      "the step is: 1240 ,the acc is 0.66157144 , the cost is 1.1040899\n",
      "the step is: 1245 ,the acc is 0.67714286 , the cost is 1.0817616\n",
      "the step is: 1250 ,the acc is 0.675 , the cost is 1.0795007\n",
      "the step is: 1255 ,the acc is 0.6687143 , the cost is 1.0851797\n",
      "the step is: 1260 ,the acc is 0.6324286 , the cost is 1.1431577\n",
      "the step is: 1265 ,the acc is 0.6682857 , the cost is 1.1126511\n",
      "the step is: 1270 ,the acc is 0.669 , the cost is 1.1149187\n",
      "the step is: 1275 ,the acc is 0.6984286 , the cost is 1.0401373\n",
      "the step is: 1280 ,the acc is 0.64942855 , the cost is 1.1381832\n",
      "the step is: 1285 ,the acc is 0.667 , the cost is 1.0948901\n",
      "the step is: 1290 ,the acc is 0.686 , the cost is 1.0606325\n",
      "the step is: 1295 ,the acc is 0.6948571 , the cost is 1.0461466\n",
      "the step is: 1300 ,the acc is 0.55628574 , the cost is 1.363634\n",
      "the step is: 1305 ,the acc is 0.6507143 , the cost is 1.1445894\n",
      "the step is: 1310 ,the acc is 0.6768571 , the cost is 1.0764855\n",
      "the step is: 1315 ,the acc is 0.6407143 , the cost is 1.1528556\n",
      "the step is: 1320 ,the acc is 0.642 , the cost is 1.1728737\n",
      "the step is: 1325 ,the acc is 0.6697143 , the cost is 1.1087701\n",
      "the step is: 1330 ,the acc is 0.69285715 , the cost is 1.063108\n",
      "the step is: 1335 ,the acc is 0.63285714 , the cost is 1.1858916\n",
      "the step is: 1340 ,the acc is 0.68057144 , the cost is 1.0713322\n",
      "the step is: 1345 ,the acc is 0.6125714 , the cost is 1.2403464\n",
      "the step is: 1350 ,the acc is 0.6527143 , the cost is 1.1490016\n",
      "the step is: 1355 ,the acc is 0.65328574 , the cost is 1.1248711\n",
      "the step is: 1360 ,the acc is 0.67914283 , the cost is 1.0739564\n",
      "the step is: 1365 ,the acc is 0.64757144 , the cost is 1.1528682\n",
      "the step is: 1370 ,the acc is 0.6815714 , the cost is 1.0828317\n",
      "the step is: 1375 ,the acc is 0.7037143 , the cost is 1.0310208\n",
      "the step is: 1380 ,the acc is 0.6011429 , the cost is 1.2170913\n",
      "the step is: 1385 ,the acc is 0.65414286 , the cost is 1.1240696\n",
      "the step is: 1390 ,the acc is 0.685 , the cost is 1.0680628\n",
      "the step is: 1395 ,the acc is 0.68 , the cost is 1.0466186\n",
      "the step is: 1400 ,the acc is 0.647 , the cost is 1.1322461\n",
      "the step is: 1405 ,the acc is 0.6802857 , the cost is 1.0612876\n",
      "the step is: 1410 ,the acc is 0.692 , the cost is 1.0304871\n",
      "the step is: 1415 ,the acc is 0.64114285 , the cost is 1.1379702\n",
      "the step is: 1420 ,the acc is 0.68685716 , the cost is 1.0472426\n",
      "the step is: 1425 ,the acc is 0.70085716 , the cost is 1.0197072\n",
      "the step is: 1430 ,the acc is 0.5871429 , the cost is 1.2622297\n",
      "the step is: 1435 ,the acc is 0.638 , the cost is 1.1791832\n",
      "the step is: 1440 ,the acc is 0.6758571 , the cost is 1.1080387\n",
      "the step is: 1445 ,the acc is 0.67985713 , the cost is 1.0726386\n",
      "the step is: 1450 ,the acc is 0.66714287 , the cost is 1.0943023\n",
      "the step is: 1455 ,the acc is 0.6314286 , the cost is 1.1761276\n",
      "the step is: 1460 ,the acc is 0.6635714 , the cost is 1.1123893\n",
      "the step is: 1465 ,the acc is 0.6495714 , the cost is 1.134635\n",
      "the step is: 1470 ,the acc is 0.67542857 , the cost is 1.0884548\n",
      "the step is: 1475 ,the acc is 0.659 , the cost is 1.1200771\n",
      "the step is: 1480 ,the acc is 0.69942856 , the cost is 1.0454435\n",
      "the step is: 1485 ,the acc is 0.63 , the cost is 1.1739408\n",
      "the step is: 1490 ,the acc is 0.631 , the cost is 1.2020698\n",
      "the step is: 1495 ,the acc is 0.665 , the cost is 1.1242634\n",
      "the shape of cnn output features (28000, 64) (28000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "sess3 = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess3.run(init)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "step = 1\n",
    "while step < 1500:\n",
    "    for i in range(n_group):\n",
    "        sess3.run(train_step, feed_dict={xs: train_fea[i], ys: train_label[i], keep_prob:keep})\n",
    "    if step % 5 == 0:\n",
    "        cost=sess3.run(cross_entropy, feed_dict={xs: b, ys: label_testing, keep_prob: keep})\n",
    "        acc_cnn_t=compute_accuracy(b, label_testing)\n",
    "        print('the step is:',step,',the acc is',acc_cnn_t,', the cost is', cost)\n",
    "    step+=1\n",
    "acc_cnn=compute_accuracy(b, label_testing)\n",
    "time2=time.clock()\n",
    "feature_all_cnn=sess3.run(h_fc1_drop, feed_dict={xs: feature_all, keep_prob: keep})\n",
    "print (\"the shape of cnn output features\",feature_all.shape,label_all.shape)\n",
    "\n",
    "time3=time.clock()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

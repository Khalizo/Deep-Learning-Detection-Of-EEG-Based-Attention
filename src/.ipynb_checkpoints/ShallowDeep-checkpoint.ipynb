{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import sys, io\n",
    "import pandas as pd \n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from braindecode.datasets.xy import create_from_X_y\n",
    "from braindecode.training.losses import CroppedLoss\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet , Deep4Net \n",
    "from skorch.callbacks import LRScheduler, EarlyStopping\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier , EEGRegressor\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "class ShallowDeep:\n",
    "    def __init__(self, model_type, bandpass, eval_type, class_type):\n",
    "        self.model_type = model_type\n",
    "        self.bandpass = bandpass\n",
    "        self.eval_type = eval_type\n",
    "        self.class_type = class_type\n",
    "   \n",
    "\n",
    "\n",
    "    def choose_cnn (self, model_depth, model_type, trainset, validset , n_classes , device, cuda , n_epochs):\n",
    "        # Extract number of chans and time steps from dataset\n",
    "        n_chans = trainset[0][0].shape[0]\n",
    "        input_window_samples = trainset[0][0].shape[1]\n",
    "\n",
    "        if model_type =='reg':\n",
    "            n_classes = 1\n",
    "            \n",
    "        if model_depth == 'shallow':\n",
    "            lr = 0.0625 * 0.01\n",
    "            weight_decay = 0\n",
    "            model =  ShallowFBCSPNet(n_chans, n_classes, input_window_samples=input_window_samples, final_conv_length=\"auto\")\n",
    "        else:\n",
    "            lr = 1 * 0.01\n",
    "            weight_decay = 0.5 * 0.001\n",
    "            \"\"\"\n",
    "            For 30 samples, filter time_length = 1\n",
    "            For 60 > samples, filter time length is left empty\n",
    "            for 15 samples, filter_time length = 1, filter_length_2 = 1, filter_length_3 = 1\n",
    "            \"\"\"\n",
    "            model =  Deep4Net(n_chans, n_classes, input_window_samples=input_window_samples,\n",
    "                      final_conv_length='auto', pool_time_length=1, filter_time_length = 1,pool_time_stride=1)\n",
    "        if cuda:\n",
    "            model = model.cuda(0)\n",
    "\n",
    "        batch_size = 32\n",
    "\n",
    "        if model_type == 'clf':\n",
    "            clf = EEGClassifier(\n",
    "            model,\n",
    "            criterion=torch.nn.NLLLoss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            train_split=predefined_split(validset),  # using valid_set for validation\n",
    "            optimizer__lr=lr,\n",
    "            optimizer__weight_decay=weight_decay,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[\n",
    "                \"accuracy\", \n",
    "                (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)), \n",
    "               (\"EarlyStopping\", EarlyStopping(monitor = 'valid_loss', threshold = 0.00001)),\n",
    "            ],\n",
    "            device=device,)\n",
    "            return clf\n",
    "        else:\n",
    "\n",
    "            # remove softmax\n",
    "            new_model = torch.nn.Sequential()\n",
    "            for name, module_ in model.named_children():\n",
    "                if \"softmax\" in name:\n",
    "                    continue\n",
    "                new_model.add_module(name, module_)\n",
    "\n",
    "            model = new_model\n",
    "\n",
    "            regressor = EEGRegressor(\n",
    "            model,\n",
    "            cropped = False,\n",
    "            criterion=CroppedLoss,\n",
    "            criterion__loss_function=torch.nn.functional.mse_loss,\n",
    "            optimizer=torch.optim.AdamW,\n",
    "            train_split=predefined_split(validset),\n",
    "            optimizer__lr=lr,\n",
    "            optimizer__weight_decay=weight_decay,\n",
    "            iterator_train__shuffle=True,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[\n",
    "                \"neg_root_mean_squared_error\",\n",
    "                # seems n_epochs -1 leads to desired behavior of lr=0 after end of training?\n",
    "                (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)), \n",
    "               (\"EarlyStopping\", EarlyStopping(monitor = 'valid_loss', threshold = 0.00001)),\n",
    "            ],\n",
    "            device=device)\n",
    "            return regressor\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def kfold_predict (self, X,y, model_type, n_epochs, model_depth,class_type):\n",
    "        kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "\n",
    "        if model_type == 'clf':\n",
    "            results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "                  \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "        else:\n",
    "            results = {'RMSE':[], 'R2':[]}\n",
    "\n",
    "        total_predictions = []\n",
    "        total_true = []\n",
    "        num_classes = 0\n",
    "        clf = None\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print(\"Train: \", train_index, \"Validation: \", test_index)\n",
    "\n",
    "            #Train/test split\n",
    "            X_train, X_valid = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "            y_train, y_valid = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "\n",
    "            # check the the classes in the validation set\n",
    "            y_valid_classes = list(set(y_valid))\n",
    "            y_train_classes = list(set(y_train))\n",
    "            if check_if_valid_labels_are_in_train(y_train_classes, y_valid_classes) == False: \n",
    "                continue\n",
    "\n",
    "\n",
    "            size = len(X_train) + len(X_valid) #get dataset size\n",
    "\n",
    "            #standardise per channel\n",
    "            X_train, X_valid = standardise(X_train, X_valid)\n",
    "            \n",
    "            #convert to binary if binary classification\n",
    "            if class_type == 'binary':\n",
    "                y_train = convert_to_binary(y_train)\n",
    "                y_valid = convert_to_binary(y_valid)\n",
    "\n",
    "            #label the categorical variables\n",
    "            if model_type == 'clf':\n",
    "                y_train, y_valid, le = categorise(y_train, y_valid)\n",
    "\n",
    "            # Convert training and validation sets into a suitable format\n",
    "            save_stdout = sys.stdout\n",
    "            sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "            trainset = create_from_X_y(X_train, y_train, drop_last_window=False)\n",
    "            validset = create_from_X_y(X_valid, y_valid, drop_last_window=False)\n",
    "            sys.stdout = save_stdout\n",
    "\n",
    "            # count the number of classes\n",
    "            if len(set(y_train)) > num_classes:\n",
    "                num_classes = len(set(y_train))\n",
    "\n",
    "            # commence the training process\n",
    "            time_start = time.time()\n",
    "            save_stdout = sys.stdout\n",
    "            sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "            cnn = self.choose_cnn (model_depth, model_type, trainset, validset , num_classes , device, cuda, n_epochs).fit(trainset, y=None, epochs=n_epochs)\n",
    "\n",
    "            sys.stdout = save_stdout\n",
    "            print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "            # make predictions\n",
    "            if model_type == 'clf':\n",
    "                y_pred = le.inverse_transform(cnn.predict(X_valid))\n",
    "                y_true = le.inverse_transform(y_valid)\n",
    "            else:\n",
    "                y_pred = cnn.predict(X_valid)\n",
    "                y_true = y_valid\n",
    "\n",
    "            total_predictions.append(y_pred)\n",
    "            total_true.append(y_true) \n",
    "            r = get_results(y_true, y_pred, model_type)\n",
    "\n",
    "            for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "                results[key].append(r[key])\n",
    "\n",
    "\n",
    "        for key in results: # finallly average out the results \n",
    "            results[key] = average(results[key])\n",
    "\n",
    "        return results, np.concatenate(total_predictions), np.concatenate(total_true), num_classes, size, cnn\n",
    "\n",
    "    def save_plots(self,y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn,class_type):\n",
    "        if model_type == 'clf':\n",
    "            # plot confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            saved_file = \"results/CNN/{5}/confusion/k fold/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}_class_type{6}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type, class_type)\n",
    "            plot_confusion_matrix(cm, set(y_true), saved_file ,normalize=True)\n",
    "\n",
    "        #plot loss curve\n",
    "        plot_loss_curve(cnn)\n",
    "        plt.savefig(\"results/CNN/{5}/loss curves/k fold/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}_class_type{6}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type, class_type))\n",
    "\n",
    "        if model_type == 'reg':\n",
    "            saved_file = \"results/CNN/{5}/y vs y_pred/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}_class_type{6}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type, class_type)\n",
    "            plot_model(y_true, y_pred, user, label,file=saved_file)   \n",
    "\n",
    "    def run_per_user_sd(self, model_type, bandpass, class_type):\n",
    "        \"\"\"\n",
    "        Method for running the CNN per user\n",
    "        \"\"\"\n",
    "        multiple = None\n",
    "        sigma = None\n",
    "\n",
    "        model_depths = ['deep']\n",
    "        results = []\n",
    "        for model_depth in model_depths:\n",
    "\n",
    "            time_original = time.time()\n",
    "\n",
    "\n",
    "            labels = ['attention','interest','effort']\n",
    "            window_size_samples = 120\n",
    "            n_epochs = 100\n",
    "        #     saved_file = \"/cs/home/ybk1/Dissertation/data/all_users_sampled_with_individual_tests_30_window_annotated_EEG.pickle\"\n",
    "            saved_file = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_users_sampled_{0}_window_annotated_EEG_no_agg_bandpass_{1}_slider_{0}.pickle\".format(window_size_samples, bandpass)\n",
    "            all_tests = load_file(saved_file)\n",
    "            users = all_tests.keys()\n",
    "\n",
    "            for user in users:\n",
    "                torch.backends.cudnn.benchmark = True\n",
    "\n",
    "                for label in labels:\n",
    "                    print(\"Running - Model_type: {4}, ClassType:{3}, Model: {0}, User: {1}, label: {2}\".format(model_depth, user,label, class_type, model_type))\n",
    "\n",
    "                    time_start = time.time()\n",
    "                    dt = all_tests[user] # dictionary of all the individual tests per user\n",
    "\n",
    "                    X = np.array([np.array(x).transpose(0,2,1).astype(np.float32) for x in dt['inputs']])     \n",
    "                    y = np.array([np.array(x) for x in dt[label]]) #Convert the categories into labels\n",
    "\n",
    "                    # train and make predictions\n",
    "                    r, y_pred, y_true, num_classes, size, cnn = self.kfold_predict(X,y, model_type, n_epochs, model_depth,class_type)\n",
    "                    print(r['Accuracy'])\n",
    "\n",
    "                     # get results\n",
    "                    duration = time.time() - time_start\n",
    "                    results.append(collate_results(r, user, label, duration, \n",
    "                                                   num_classes, size, model_type, \n",
    "                                                   n_epochs, window_size_samples, \n",
    "                                                   model_depth, multiple, sigma, bandpass, class_type))\n",
    "\n",
    "                    self.save_plots(y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn, class_type)\n",
    "\n",
    "                    print(\"Finished analysis on User {0}_{1}\".format(user,label))\n",
    "                print(\"Finished analysis on User {0}\".format(user))\n",
    "                \n",
    "        results  = pd.DataFrame(results)\n",
    "        results.to_csv(\"results/bulk/shallow_deep_performance_window_size_{0}_per_user_model_type_{1}bandpass_{3}_class-type{3}.csv\".format(window_size_samples, model_type, bandpass, class_type), index=False )\n",
    "        final_duration = time.time()- time_original\n",
    "        print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))\n",
    "        return results\n",
    "\n",
    "    def run_cross_user_sd(self, model_type, bandpass, class_type):\n",
    "        multiple = None\n",
    "        sigma = None\n",
    "        \n",
    "        model_depths = ['deep']\n",
    "        for model_depth in model_depths:\n",
    "\n",
    "            time_original = time.time()\n",
    "\n",
    "            window_size_samples = 120\n",
    "\n",
    "            n_epochs = 100\n",
    "            results = []\n",
    "            labels = ['attention','interest','effort']\n",
    "\n",
    "            saved_file = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_users_sampled_{0}_window_annotated_EEG_agg_bandpass_{1}_slider_{0}.pickle\".format(window_size_samples, bandpass)\n",
    "            all_tests_agg = load_file(saved_file)\n",
    "            users = all_tests_agg.keys()\n",
    "            user ='all'\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "\n",
    "            for label in labels:\n",
    "                print(\"Running - Model_type: {4}, ClassType:{3}, Model: {0}, User: {1}, label: {2}\".format(model_depth, user,label, class_type, model_type))\n",
    "\n",
    "                time_start = time.time()\n",
    "\n",
    "\n",
    "                # convert the inputs  into #samples, channels, #timepoints format\n",
    "                X = np.array([all_tests_agg[user]['inputs'].transpose(0,2,1).astype(np.float32) for user in all_tests_agg])\n",
    "                y = np.array([all_tests_agg[user][label] for user in all_tests_agg])  \n",
    "\n",
    "                # train and make predictions\n",
    "                r, y_pred, y_true, num_classes, size, cnn = self.kfold_predict(X,y, model_type, n_epochs, model_depth,class_type)\n",
    "\n",
    "                 # get results\n",
    "                duration = time.time() - time_start\n",
    "                results.append(collate_results(r, user, label, duration, \n",
    "                                               num_classes, size, model_type, \n",
    "                                               n_epochs, window_size_samples, \n",
    "                                               model_depth, multiple, sigma, bandpass, class_type))\n",
    "\n",
    "                #save plots\n",
    "                self.save_plots(y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn,class_type)\n",
    "\n",
    "\n",
    "                print(\"Finished analysis on label {0}\".format(label))\n",
    "        print(\"Finished analysis on User {0}\".format(user))\n",
    "        results  = pd.DataFrame(results)\n",
    "        results.to_csv(\"results/CNN/{3}/tabulated/k fold/{1}/{1}CNN_Valid_performance_window_size_{0}_cross_user_bandpass_{2}_classtype_{4}.csv\".format(window_size_samples , \n",
    "                                                                                                                                                        model_depth,bandpass, model_type, class_type), index=False )\n",
    "        final_duration = time.time()- time_original\n",
    "        print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def run_shallow_deep(self):\n",
    "        if self.eval_type == 'per user':\n",
    "            results = self.run_per_user_sd(self.model_type, self.bandpass, self.class_type)\n",
    "            return results\n",
    "        elif self.eval_type == 'cross user':\n",
    "            results = self.run_cross_user_sd(self.model_type, self.bandpass,self.class_type)\n",
    "            return results\n",
    "        elif self.eval_type == 'both':\n",
    "\n",
    "            results = []\n",
    "            results.append(self.run_cross_user_sd(self.model_type, self.bandpass))\n",
    "            results.append(self.run_per_user_sd(self.model_type, self.bandpass))\n",
    "\n",
    "            results = pd.concat(results)\n",
    "            return results\n",
    "\n",
    "sd2 =ShallowDeep('clf', False, 'cross user', 'multi')\n",
    "sd2.run_shallow_deep()\n",
    "\n",
    "# bandpasses = [False]\n",
    "# results = []\n",
    "# for bandpass in bandpasses:\n",
    "#     sd = ShallowDeep('clf',bandpass, 'per user','multi')\n",
    "#     results.append(sd.run_shallow_deep())\n",
    "\n",
    "# results = pd.concat(results).to_csv(\"results/bulk/deep_bandpass_test_per_user.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

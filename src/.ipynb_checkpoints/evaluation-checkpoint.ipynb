{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, accuracy_score, balanced_accuracy_score , mean_squared_error, r2_score\n",
    "import pickle\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(y_test, y_pred, model_type):\n",
    "    \n",
    "    if model_type == 'clf':\n",
    "        results = {}\n",
    "        results[\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "        results[\"Precision\"] = precision_score(y_test, y_pred, average='macro')\n",
    "        results[\"Recall\"] = recall_score(y_test, y_pred, average='macro')\n",
    "        results[\"F1 Score Macro\"] = f1_score(y_test, y_pred, average='macro')\n",
    "        results[\"F1 Score Micro\"] = f1_score(y_test, y_pred, average='micro')\n",
    "        results[\"Balanced Accuracy\"] = balanced_accuracy_score(y_test, y_pred)\n",
    "    else:\n",
    "        results = {}\n",
    "        results['RMSE'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        results['R2'] = r2_score(y_test,y_pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_results(r, user, label, duration, num_classes, size, model_type, n_epochs, window_size_samples):\n",
    "    \"\"\"\n",
    "    Method for collating the results in a single tuple\n",
    "    :r: results \n",
    "    :user: current user\n",
    "    :num_classes: number of targets \n",
    "    \"\"\"\n",
    "    if model_type == 'clf':        \n",
    "        Results = namedtuple(\"Results\",\"user label n_epochs window_size duration num_classes size accuracy bal_acc precision recall f1_score_macro f1_score_micro\")\n",
    "        collated_results = Results(user, label, n_epochs, window_size_samples, duration,  num_classes, size, r['Accuracy'], r['Balanced Accuracy'], r['Precision'], r['Recall'], \n",
    "                                  r['F1 Score Macro'], r['F1 Score Micro'])\n",
    "    else: \n",
    "        Results = namedtuple(\"Results\",\"user label n_epochs window_size duration num_classes size RMSE R2\")\n",
    "        collated_results = Results(user, label, n_epochs, window_size_samples, duration, num_classes, size, r['RMSE'], r['R2'])\n",
    "    return collated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, file,  normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure()\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(clf):\n",
    "    \n",
    "    # Extract loss and accuracy values for plotting from history object\n",
    "    results_columns = ['train_loss', 'valid_loss', 'train_accuracy', 'valid_accuracy']\n",
    "    df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,\n",
    "                      index=clf.history[:, 'epoch'])\n",
    "\n",
    "    # get percent of misclass for better visual comparison to loss\n",
    "    df = df.assign(train_misclass=100 * df.train_accuracy,\n",
    "                   valid_misclass=100 * df.valid_accuracy)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "    df.loc[:, ['train_loss', 'valid_loss']].plot(\n",
    "        ax=ax1, style=['-', ':'], color='tab:blue', legend=False, fontsize=14)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\n",
    "    ax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    df.loc[:, ['train_misclass', 'valid_misclass']].plot(\n",
    "        ax=ax2, style=['-', ':'], color='tab:red', legend=False)\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\n",
    "    ax2.set_ylabel(\"Accuracy [%]\", color='tab:red', fontsize=14)\n",
    "    ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\n",
    "    ax1.set_xlabel(\"Epoch\", fontsize=14)\n",
    "\n",
    "    # where some data has already been plotted to ax\n",
    "    handles = []\n",
    "    handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\n",
    "    handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\n",
    "    plt.legend(handles, [h.get_label() for h in handles], fontsize=14)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(y, y_hat, user, label, file ,c='black'):\n",
    "    # Create a dictionary to pass to matplotlib\n",
    "    # These settings make the plots readable on slides, feel free to change\n",
    "    # This is an easy way to set many parameters at once\n",
    "    plt.figure()\n",
    "\n",
    "    fontsize = \"30\";\n",
    "    params = {'figure.autolayout':True,\n",
    "              'legend.fontsize': fontsize,\n",
    "              'figure.figsize': (12, 8),\n",
    "             'axes.labelsize': fontsize,\n",
    "             'axes.titlesize': fontsize,\n",
    "             'xtick.labelsize':fontsize,\n",
    "             'ytick.labelsize':fontsize}\n",
    "    plt.rcParams.update(params)\n",
    "    \n",
    "    # Create a new figure and an axes objects for the subplot\n",
    "    # We only have one plot here, but it's helpful to be consistent\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Draw a scatter plot of the first column of x vs second column.\n",
    "    ax.scatter(y,y_hat, color = c)\n",
    "    ax.set_xlabel(\"Observed {0}\".format(label))\n",
    "    ax.set_ylabel(\"Predicted {0}\".format(label))\n",
    "    ax.grid(color='lightgray', linestyle='-', linewidth=1)\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    m, b = np.polyfit(y, y_hat, 1)\n",
    "    ax.plot(y, m*y + b, color='red')\n",
    "    plt.savefig(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    \"\"\"\n",
    "    Method for loading files based on a given path\n",
    "    \"\"\"\n",
    "    with open(path, 'rb') as handle:\n",
    "        file = pickle.load(handle)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(path, file):\n",
    "    with open(path, 'wb') as handle:            \n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

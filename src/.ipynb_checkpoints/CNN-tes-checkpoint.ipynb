{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import sys, io\n",
    "import pandas as pd \n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from braindecode.datasets.xy import create_from_X_y\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet , Deep4Net\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(X_train, X_valid):\n",
    "    # standardize per channel\n",
    "    means = X_train.mean(axis=(0,2), keepdims=True)\n",
    "    stds = X_train.std(axis=(0,2), keepdims=True)\n",
    "    X_train = (X_train - means) / (stds)\n",
    "    X_valid = (X_valid - means) / (stds)\n",
    "    return X_train, X_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_cnn (cnn, trainset, validset , n_classes , device, cuda , n_epochs):\n",
    "    # Extract number of chans and time steps from dataset\n",
    "    n_chans = trainset[0][0].shape[0]\n",
    "    input_window_samples = trainset[0][0].shape[1]\n",
    "\n",
    "    if cnn == 'shallow':\n",
    "        lr = 0.0625 * 0.01\n",
    "        weight_decay = 0\n",
    "        model =  ShallowFBCSPNet(n_chans, n_classes, input_window_samples=input_window_samples, final_conv_length=\"auto\")\n",
    "    else:\n",
    "        lr = 1 * 0.01\n",
    "        weight_decay = 0.5 * 0.001\n",
    "        \"\"\"\n",
    "        For 30 samples, filter time_length = 1\n",
    "        For 60 > samples, filter time length is left empty\n",
    "        for 15 samples, filter_time length = 1, filter_length_2 = 1, filter_length_3 = 1\n",
    "        \"\"\"\n",
    "        model =  Deep4Net(n_chans, n_classes, input_window_samples=input_window_samples,\n",
    "                  final_conv_length=\"auto\", pool_time_length=1, filter_time_length = 1,pool_time_stride=1)\n",
    "    if cuda:\n",
    "        model = model.cuda(0)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(validset),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(y_train, y_valid):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_valid = le.transform(y_valid)\n",
    "    return y_train, y_valid, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_slice_in_list(s,l):\n",
    "    len_s = len(s) #so we don't recompute length of s on every iteration\n",
    "    return any(s == l[i:len_s+i] for i in range(len(l) - len_s+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_predict (X,y, model_type, n_epochs):\n",
    "    kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "\n",
    "    if model_type == 'clf':\n",
    "        results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "              \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "    else:\n",
    "        results = {'RMSE':[], 'R2':[]}\n",
    "\n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    num_classes = 0\n",
    "    clf = None\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"Train: \", train_index, \"Validation: \", test_index)\n",
    "\n",
    "        #Train/test split\n",
    "        X_train, X_valid = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "        y_train, y_valid = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "        \n",
    "        y_valid_classes = list(set(y_valid))\n",
    "        y_train_classes = list(set(y_train))\n",
    "\n",
    "        if is_slice_in_list(y_valid_classes, y_train_classes) == False: continue\n",
    "        print(set(y_train))\n",
    "        print(set(y_valid))\n",
    "\n",
    "        size = len(X_train) + len(X_valid) #get dataset size\n",
    "\n",
    "        #standardise per channel\n",
    "        X_train, X_valid = standardise(X_train, X_valid)\n",
    "        \n",
    "        #label the categorical variables \n",
    "        y_train, y_valid, le = categorise(y_train, y_valid)\n",
    "\n",
    "        # Convert training and validation sets into a suitable format\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        trainset = create_from_X_y(X_train, y_train, drop_last_window=False)\n",
    "        validset = create_from_X_y(X_valid, y_valid, drop_last_window=False)\n",
    "        sys.stdout = save_stdout\n",
    "\n",
    "        # count the number of classes\n",
    "        if len(set(y_train)) > num_classes:\n",
    "            num_classes = len(set(y_train))\n",
    "\n",
    "        # commence the training process\n",
    "        time_start = time.time()\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        clf = choose_cnn ('deep', trainset, validset , num_classes , device, cuda, n_epochs).fit(trainset, y=None, epochs=n_epochs)\n",
    "        sys.stdout = save_stdout\n",
    "        print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = le.inverse_transform(clf.predict(X_valid))\n",
    "        y_true = le.inverse_transform(y_valid)\n",
    "        total_predictions.append(y_pred)\n",
    "        total_true.append(y_true) \n",
    "        r = get_results(y_true, y_pred, model_type)\n",
    "\n",
    "        for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "            results[key].append(r[key])\n",
    "\n",
    "    for key in results: # finallly average out the results \n",
    "        results[key] = average(results[key])\n",
    "    return results, np.concatenate(total_predictions), np.concatenate(total_true), num_classes, size , clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on user 1\n",
      "Train:  [ 0  1  2  4  5  8  9 10 11 12 13 14] Validation:  [3 6 7]\n",
      "{1, 2, 3, 4, 5}\n",
      "{2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 373.5415756702423 seconds\n",
      "Train:  [ 0  1  3  5  6  7  8  9 11 12 13 14] Validation:  [ 2  4 10]\n",
      "Train:  [ 2  3  4  5  6  7  8  9 10 11 12 14] Validation:  [ 0  1 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 369.445809841156 seconds\n",
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13] Validation:  [ 8  9 14]\n",
      "{1, 2, 3, 4, 5}\n",
      "{2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 379.29090452194214 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 366.39006066322327 seconds\n",
      "Normalized confusion matrix\n",
      "[[0.         0.27777778 0.65555556 0.06666667]\n",
      " [0.12140575 0.18530351 0.34185304 0.3514377 ]\n",
      " [0.24038462 0.25801282 0.12339744 0.37820513]\n",
      " [0.33038869 0.28798587 0.28268551 0.09893993]]\n",
      "Finished analysis on User 1_attention\n",
      "Train:  [ 0  1  2  4  5  8  9 10 11 12 13 14] Validation:  [3 6 7]\n",
      "Train:  [ 0  1  3  5  6  7  8  9 11 12 13 14] Validation:  [ 2  4 10]\n",
      "{1, 2, 3, 4, 5}\n",
      "{2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 379.50436568260193 seconds\n",
      "Train:  [ 2  3  4  5  6  7  8  9 10 11 12 14] Validation:  [ 0  1 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 364.8521659374237 seconds\n",
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13] Validation:  [ 8  9 14]\n",
      "{1, 2, 3, 4, 5}\n",
      "{2, 3, 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 376.5019791126251 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 367.76851534843445 seconds\n",
      "Normalized confusion matrix\n",
      "[[       nan        nan        nan        nan        nan]\n",
      " [0.         0.02836879 0.62056738 0.35106383 0.        ]\n",
      " [0.11111111 0.34747475 0.2        0.34141414 0.        ]\n",
      " [0.04338624 0.0962963  0.13227513 0.63597884 0.09206349]\n",
      " [0.40540541 0.09355509 0.27650728 0.22453222 0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "ipynb.fs.full.evaluation:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished analysis on User 1_interest\n",
      "Train:  [ 0  1  2  4  5  8  9 10 11 12 13 14] Validation:  [3 6 7]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "time_original = time.time()\n",
    "\n",
    "results = []\n",
    "labels = ['attention','interest','effort']\n",
    "window_size_samples = 30\n",
    "\n",
    "saved_file = \"/cs/home/ybk1/Dissertation/data/all_users_sampled_with_individual_tests_30_window_annotated_EEG.pickle\"\n",
    "all_tests = load_file(saved_file)\n",
    "users = all_tests.keys()\n",
    "n_epochs  = 200\n",
    "model_type = 'clf'\n",
    "for user in users:\n",
    "    print(\"Working on user {0}\".format(user))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for label in labels:\n",
    "        time_start = time.time()\n",
    "        dt = all_tests[user] # dictionary of all the individual tests per user\n",
    "\n",
    "        X = np.array([np.array(x).transpose(0,2,1).astype(np.float32) for x in dt['inputs']])     \n",
    "        y = np.array([np.array(x) for x in dt[label]]) #Convert the categories into labels\n",
    "\n",
    "        # train and make predictions\n",
    "        r, y_pred, y_true, num_classes, size, clf = kfold_predict(X,y, model_type, n_epochs)\n",
    "\n",
    "         # get results\n",
    "        Results = namedtuple(\"Results\",\"user label n_epochs window_size time num_classes size accuracy bal_acc precision recall f1_score_macro f1_score_micro\")\n",
    "        results.append(Results(user, label, n_epochs, window_size_samples, time.time()-time_start,  num_classes,size, r['Accuracy'], r['Balanced Accuracy'], r['Precision'], r['Recall'], \n",
    "                              r['F1 Score Macro'], r['F1 Score Micro']))\n",
    "\n",
    "        # plot confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        saved_file = \"results/CNN/confusion/k fold/User_{0}_{1}.png\".format(user,label)\n",
    "        plot_confusion_matrix(cm, set(y_true), saved_file ,normalize=True)\n",
    "        \n",
    "        #plot loss curve\n",
    "        plot_loss_curve(clf)\n",
    "        plt.savefig(\"results/CNN/loss curves/k fold/User_{0}_{1}.png\".format(user,label))\n",
    "        print(\"Finished analysis on User {0}_{1}\".format(user,label))\n",
    "    print(\"Finished analysis on User {0}\".format(user))\n",
    "results  = pd.DataFrame(results).to_csv(\"results/CNN/tabulated/k fold/DeepCNN_Valid_performance_window_size_{0}_{1}_withclasses.csv\".format(window_size_samples,label), index=False )\n",
    "final_duration = time.time()- time_original\n",
    "print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model \n",
    "# saved_file = \"models/attention_user_1_with_fi.pickle\"\n",
    "# with open(saved_file, 'wb') as handle:            \n",
    "#     pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

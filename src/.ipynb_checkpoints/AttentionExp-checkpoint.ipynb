{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import sys, io\n",
    "\n",
    "def salute(name):\n",
    "    \"\"\"Says hi to someone.\"\"\"\n",
    "    print('Hi, {}!'.format(name))\n",
    "\n",
    "save_stdout = sys.stdout\n",
    "sys.stdout = open('trash', 'w')\n",
    "print(\"bye\")\n",
    "sys.stdout = save_stdout\n",
    "print(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85991, 14)\n",
      "(85863, 8, 128)\n",
      "(85863,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "saved_file = \"data/all_tests_EEG.pickle\"\n",
    "with open(saved_file, 'rb') as handle:\n",
    "    all_tests = pickle.load(handle)\n",
    "\n",
    "data = all_tests[1]\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "window_size_samples = 128\n",
    "\n",
    "X = [np.array(data.iloc[i:i+window_size_samples,:-6]) \n",
    "     for i in range(data.shape[0] - window_size_samples)]\n",
    "X = np.array(X).transpose(0,2,1).astype(np.float32)\n",
    "y = np.array(data.iloc[window_size_samples:,-3]).astype(np.int64) - 1\n",
    "\n",
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created! Time elapsed: 301.4848983287811 seconds\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.xy import create_from_X_y\n",
    "import time\n",
    "time_start = time.time()\n",
    "train_X, X_test, train_y, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.20, random_state=42, stratify=train_y)\n",
    "\n",
    "\n",
    "means = train_X.mean(axis=(0,2), keepdims=True)\n",
    "stds = train_X.std(axis=(0,2), keepdims=True)\n",
    " \n",
    "# standardize per channel\n",
    "train_X = (train_X - means) / (stds)\n",
    "valid_X = (valid_X - means) / (stds)\n",
    "\n",
    "save_stdout = sys.stdout\n",
    "sys.stdout = open('trash', 'w')\n",
    "train_set = create_from_X_y(train_X, train_y, drop_last_window=False)\n",
    "valid_set = create_from_X_y(valid_X, valid_y, drop_last_window=False)\n",
    "sys.stdout = save_stdout\n",
    "\n",
    "print('Datasets created! Time elapsed: {} seconds'.format(time.time()-time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1 events and 128 original time points ...\n",
      "Loading data for 1 events and 128 original time points ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes=5\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    ")\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "time_start = time.time()\n",
    "from braindecode import EEGClassifier\n",
    "# These values we found good for shallow network:\n",
    "lr = 0.0625 * 0.01\n",
    "weight_decay = 0\n",
    "\n",
    "# For deep4 they should be:\n",
    "# lr = 1 * 0.01\n",
    "# weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 40\n",
    "\n",
    "sys.stdout = open('trash', 'w')\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "sys.stdout = save_stdout\n",
    "print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

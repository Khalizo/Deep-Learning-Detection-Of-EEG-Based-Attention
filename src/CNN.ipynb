{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import sys, io\n",
    "import pandas as pd \n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from braindecode.datasets.xy import create_from_X_y\n",
    "from braindecode.training.losses import CroppedLoss\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet , Deep4Net \n",
    "from skorch.callbacks import LRScheduler, EarlyStopping\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier , EEGRegressor\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(X_train, X_valid):\n",
    "    # standardize per channel\n",
    "    means = X_train.mean(axis=(0,2), keepdims=True)\n",
    "    stds = X_train.std(axis=(0,2), keepdims=True)\n",
    "    X_train = (X_train - means) / (stds)\n",
    "    X_valid = (X_valid - means) / (stds)\n",
    "    return X_train, X_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_cnn (model_depth, model_type, trainset, validset , n_classes , device, cuda , n_epochs):\n",
    "    # Extract number of chans and time steps from dataset\n",
    "    n_chans = trainset[0][0].shape[0]\n",
    "    input_window_samples = trainset[0][0].shape[1]\n",
    "\n",
    "    if model_depth == 'shallow':\n",
    "        lr = 0.0625 * 0.01\n",
    "        weight_decay = 0\n",
    "        model =  ShallowFBCSPNet(n_chans, n_classes, input_window_samples=input_window_samples, final_conv_length=\"auto\")\n",
    "    else:\n",
    "        lr = 1 * 0.01\n",
    "        weight_decay = 0.5 * 0.001\n",
    "        \"\"\"\n",
    "        For 30 samples, filter time_length = 1\n",
    "        For 60 > samples, filter time length is left empty\n",
    "        for 15 samples, filter_time length = 1, filter_length_2 = 1, filter_length_3 = 1\n",
    "        \"\"\"\n",
    "        model =  Deep4Net(n_chans, n_classes, input_window_samples=input_window_samples,\n",
    "                  final_conv_length='auto', pool_time_length=1, filter_time_length = 1,pool_time_stride=1)\n",
    "    if cuda:\n",
    "        model = model.cuda(0)\n",
    "\n",
    "    batch_size = 32\n",
    "    \n",
    "    if model_type == 'clf':\n",
    "        clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(validset),  # using valid_set for validation\n",
    "        optimizer__lr=lr,\n",
    "        optimizer__weight_decay=weight_decay,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"accuracy\", \n",
    "            (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)), \n",
    "           (\"EarlyStopping\", EarlyStopping(monitor = 'valid_loss', threshold = 0.00001)),\n",
    "        ],\n",
    "        device=device,)\n",
    "        return clf\n",
    "    else:\n",
    "        \n",
    "        # remove softmax\n",
    "        new_model = torch.nn.Sequential()\n",
    "        for name, module_ in model.named_children():\n",
    "            if \"softmax\" in name:\n",
    "                continue\n",
    "            new_model.add_module(name, module_)\n",
    "            \n",
    "        model = new_model\n",
    "\n",
    "        regressor = EEGRegressor(\n",
    "        model,\n",
    "        cropped = False,\n",
    "        criterion=CroppedLoss,\n",
    "        criterion__loss_function=torch.nn.functional.mse_loss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(validset),\n",
    "        optimizer__lr=lr,\n",
    "        optimizer__weight_decay=weight_decay,\n",
    "        iterator_train__shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"neg_root_mean_squared_error\",\n",
    "            # seems n_epochs -1 leads to desired behavior of lr=0 after end of training?\n",
    "            (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)), \n",
    "           (\"EarlyStopping\", EarlyStopping(monitor = 'valid_loss', threshold = 0.00001)),\n",
    "        ],\n",
    "        device=device)\n",
    "        return regressor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(y_train, y_valid):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_valid = le.transform(y_valid)\n",
    "    return y_train, y_valid, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_slice_in_list(s,l):\n",
    "    \"\"\"\n",
    "    Function for checking whether a slice is in a list. Mainly used for checking whether the \n",
    "    \"\"\"\n",
    "    len_s = len(s) #so we don't recompute length of s on every iteration\n",
    "    return any(s == l[i:len_s+i] for i in range(len(l) - len_s+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_predict (X,y, model_type, n_epochs, model_depth):\n",
    "    kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "\n",
    "    if model_type == 'clf':\n",
    "        results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "              \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "    else:\n",
    "        results = {'RMSE':[], 'R2':[]}\n",
    "\n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    num_classes = 0\n",
    "    clf = None\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"Train: \", train_index, \"Validation: \", test_index)\n",
    "\n",
    "        #Train/test split\n",
    "        X_train, X_valid = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "        y_train, y_valid = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "        \n",
    "        # check the the classes in the validation set\n",
    "        y_valid_classes = list(set(y_valid))\n",
    "        y_train_classes = list(set(y_train))\n",
    "        if is_slice_in_list(y_valid_classes, y_train_classes) == False: continue\n",
    "        print(set(y_train))\n",
    "        print(set(y_valid))\n",
    "\n",
    "        size = len(X_train) + len(X_valid) #get dataset size\n",
    "\n",
    "        #standardise per channel\n",
    "        X_train, X_valid = standardise(X_train, X_valid)\n",
    "        \n",
    "        #label the categorical variables\n",
    "        if model_type == 'clf':\n",
    "            y_train, y_valid, le = categorise(y_train, y_valid)\n",
    "            \n",
    "        # Convert training and validation sets into a suitable format\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        trainset = create_from_X_y(X_train, y_train, drop_last_window=False)\n",
    "        validset = create_from_X_y(X_valid, y_valid, drop_last_window=False)\n",
    "        sys.stdout = save_stdout\n",
    "\n",
    "        # count the number of classes\n",
    "        if len(set(y_train)) > num_classes:\n",
    "            num_classes = len(set(y_train))\n",
    "\n",
    "        # commence the training process\n",
    "        time_start = time.time()\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        cnn = choose_cnn (model_depth, model_type, trainset, validset , num_classes , device, cuda, n_epochs).fit(trainset, y=None, epochs=n_epochs)\n",
    "        \n",
    "        sys.stdout = save_stdout\n",
    "        print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "        # make predictions\n",
    "        if model_type == 'clf':\n",
    "            y_pred = le.inverse_transform(cnn.predict(X_valid))\n",
    "            y_true = le.inverse_transform(y_valid)\n",
    "        else:\n",
    "            y_pred = cnn.predict(X_valid)\n",
    "            y_true = y_valid\n",
    "            \n",
    "        total_predictions.append(y_pred)\n",
    "        total_true.append(y_true) \n",
    "        r = get_results(y_true, y_pred, model_type)\n",
    "\n",
    "        for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "            results[key].append(r[key])\n",
    "        \n",
    "\n",
    "    for key in results: # finallly average out the results \n",
    "        results[key] = average(results[key])\n",
    "   \n",
    "    return results, np.concatenate(total_predictions), np.concatenate(total_true), num_classes, size, cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn):\n",
    "    if model_type == 'clf':\n",
    "        # plot confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        saved_file = \"results/CNN/{5}/confusion/k fold/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type)\n",
    "        plot_confusion_matrix(cm, set(y_true), saved_file ,normalize=True)\n",
    "\n",
    "    #plot loss curve\n",
    "    plot_loss_curve(cnn)\n",
    "    plt.savefig(\"results/CNN/{5}/loss curves/k fold/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type))\n",
    "\n",
    "    if model_type == 'reg':\n",
    "        saved_file = \"results/CNN/{5}/y vs y_pred/{2}/per user/User_{0}_Label_{1}_bandpass_{3}_window_{4}.png\".format(user, label, model_depth, bandpass, window_size_samples, model_type)\n",
    "        plot_model(y_true, y_pred, user, label,file=saved_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_per_user_sd(model_type, bandpass):\n",
    "    \"\"\"\n",
    "    Method for running the CNN per user\n",
    "    \"\"\"\n",
    "    model_depths = ['shallow', 'deep']\n",
    "    results = []\n",
    "    for model_depth in model_depths:\n",
    "        \n",
    "        print (\"Starting the {0} CNN Model...\".format(model_depth))\n",
    "        time_original = time.time()\n",
    "\n",
    "        \n",
    "        labels = ['attention','interest','effort']\n",
    "        window_size_samples = 120\n",
    "        n_epochs = 100\n",
    "    #     saved_file = \"/cs/home/ybk1/Dissertation/data/all_users_sampled_with_individual_tests_30_window_annotated_EEG.pickle\"\n",
    "        saved_file = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_users_sampled_{0}_window_annotated_EEG_no_agg_bandpass_{1}_slider_{0}.pickle\".format(window_size_samples, bandpass)\n",
    "        all_tests = load_file(saved_file)\n",
    "        users = all_tests.keys()\n",
    "\n",
    "        for user in users:\n",
    "            print(\"Working on user {0}\".format(user))\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "\n",
    "            for label in labels:\n",
    "                time_start = time.time()\n",
    "                dt = all_tests[user] # dictionary of all the individual tests per user\n",
    "\n",
    "                X = np.array([np.array(x).transpose(0,2,1).astype(np.float32) for x in dt['inputs']])     \n",
    "                y = np.array([np.array(x) for x in dt[label]]) #Convert the categories into labels\n",
    "\n",
    "                # train and make predictions\n",
    "                r, y_pred, y_true, num_classes, size, cnn = kfold_predict(X,y, model_type, n_epochs, model_depth)\n",
    "                print(r['Accuracy'])\n",
    "\n",
    "                 # get results\n",
    "                duration = time.time() - time_start\n",
    "                results.append(collate_results(r, user, label, duration, num_classes, size, model_type, n_epochs, window_size_samples, model_depth))\n",
    "\n",
    "                save_plots(y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn)\n",
    "\n",
    "                print(\"Finished analysis on User {0}_{1}\".format(user,label))\n",
    "            print(\"Finished analysis on User {0}\".format(user))\n",
    "        results  = pd.DataFrame(results)\n",
    "        results.to_csv(\"results/CNN/{3}/tabulated/k fold/{2}/{2}performance_window_size_{0}_{1}_per_user_bandpass_{4}.csv\".format(window_size_samples, n_epochs, model_depth , model_type, bandpass), index=False )\n",
    "        final_duration = time.time()- time_original\n",
    "        print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_user_sd(model_type, bandpass):\n",
    "    \n",
    "    model_depths = ['shallow', 'deep']\n",
    "    for model_depth in model_depths:\n",
    "\n",
    "        print (\"Starting the {0} CNN Model...\".format(model_depth))\n",
    "\n",
    "        time_original = time.time()\n",
    "\n",
    "        window_size_samples = 120\n",
    "\n",
    "        n_epochs = 100\n",
    "        results = []\n",
    "        labels = ['attention','interest','effort']\n",
    "\n",
    "        saved_file = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_users_sampled_{0}_window_annotated_EEG_agg_bandpass_{1}_slider_{0}.pickle\".format(window_size_samples, bandpass)\n",
    "        all_tests_agg = load_file(saved_file)\n",
    "        users = all_tests_agg.keys()\n",
    "        user ='all'\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        for label in labels:\n",
    "            print(\"Working on label {0}\".format(label))\n",
    "            time_start = time.time()\n",
    "\n",
    "\n",
    "            # convert the inputs  into #samples, channels, #timepoints format\n",
    "            X = np.array([all_tests_agg[user]['inputs'].transpose(0,2,1).astype(np.float32) for user in all_tests_agg])\n",
    "            y = np.array([all_tests_agg[user][label] for user in all_tests_agg])  \n",
    "\n",
    "            # train and make predictions\n",
    "            r, y_pred, y_true, num_classes, size, cnn = kfold_predict(X,y, model_type, n_epochs, model_depth)\n",
    "\n",
    "             # get results\n",
    "            duration = time.time() - time_start\n",
    "            results.append(collate_results(r, user, label, duration, num_classes, size, model_type, n_epochs, window_size_samples, model_depth))\n",
    "\n",
    "            #save plots\n",
    "            save_plots(y_true, y_pred, user, label, model_depth, bandpass, window_size_samples, model_type, cnn)\n",
    "\n",
    "\n",
    "            print(\"Finished analysis on label {0}\".format(label))\n",
    "        print(\"Finished analysis on User {0}\".format(user))\n",
    "        results  = pd.DataFrame(results)\n",
    "        results.to_csv(\"results/CNN/{3}/tabulated/k fold/{1}/{1}CNN_Valid_performance_window_size_{0}_cross_user_bandpass_{2}.csv\".format(window_size_samples , model_depth,bandpass, model_type), index=False )\n",
    "        final_duration = time.time()- time_original\n",
    "        print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the shallow CNN Model...\n",
      "Working on label attention\n",
      "Train:  [ 0  1  4  5  7  8  9 10 11 12 14 15 16 17] Validation:  [ 2  3  6 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 95.04976654052734 seconds\n",
      "Train:  [ 0  1  2  3  5  6  8  9 10 11 12 13 16 17] Validation:  [ 4  7 14 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 170.90883898735046 seconds\n",
      "Train:  [ 2  3  4  5  6  7  8  9 11 12 13 14 15 16] Validation:  [ 0  1 10 17]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 121.47887706756592 seconds\n",
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 17] Validation:  [ 8  9 16]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 92.82455325126648 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14 15 16 17] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 75.56693887710571 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "Finished analysis on label attention\n",
      "Working on label interest\n",
      "Train:  [ 0  1  4  5  7  8  9 10 11 12 14 15 16 17] Validation:  [ 2  3  6 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 106.76610398292542 seconds\n",
      "Train:  [ 0  1  2  3  5  6  8  9 10 11 12 13 16 17] Validation:  [ 4  7 14 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 122.2304253578186 seconds\n",
      "Train:  [ 2  3  4  5  6  7  8  9 11 12 13 14 15 16] Validation:  [ 0  1 10 17]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 146.38795375823975 seconds\n",
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 17] Validation:  [ 8  9 16]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 199.3344419002533 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14 15 16 17] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 100.88968181610107 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "Finished analysis on label interest\n",
      "Working on label effort\n",
      "Train:  [ 0  1  4  5  7  8  9 10 11 12 14 15 16 17] Validation:  [ 2  3  6 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 118.53725957870483 seconds\n",
      "Train:  [ 0  1  2  3  5  6  8  9 10 11 12 13 16 17] Validation:  [ 4  7 14 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 145.90101385116577 seconds\n",
      "Train:  [ 2  3  4  5  6  7  8  9 11 12 13 14 15 16] Validation:  [ 0  1 10 17]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 121.33935284614563 seconds\n",
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 17] Validation:  [ 8  9 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 213.0158953666687 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14 15 16 17] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 126.09628534317017 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "Finished analysis on label effort\n",
      "Finished analysis on User all\n",
      "All analyses are complete! Time elapsed: 3319.7265923023224\n",
      "Starting the deep CNN Model...\n",
      "Working on label attention\n",
      "Train:  [ 0  1  4  5  7  8  9 10 11 12 14 15 16 17] Validation:  [ 2  3  6 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 86.4786148071289 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [ 0  1  2  3  5  6  8  9 10 11 12 13 16 17] Validation:  [ 4  7 14 15]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 132.73220133781433 seconds\n",
      "Train:  [ 2  3  4  5  6  7  8  9 11 12 13 14 15 16] Validation:  [ 0  1 10 17]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 88.26750135421753 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 17] Validation:  [ 8  9 16]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 129.5188810825348 seconds\n",
      "Train:  [ 0  1  2  3  4  6  7  8  9 10 13 14 15 16 17] Validation:  [ 5 11 12]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 183.23779797554016 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "Finished analysis on label attention\n",
      "Working on label interest\n",
      "Train:  [ 0  1  4  5  7  8  9 10 11 12 14 15 16 17] Validation:  [ 2  3  6 13]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed created! Time elapsed: 85.5858302116394 seconds\n",
      "Train:  [ 0  1  2  3  5  6  8  9 10 11 12 13 16 17] Validation:  [ 4  7 14 15]\n",
      "{1, 2, 3, 4, 5}\n",
      "{1, 2, 3, 4, 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_shallow_deep(model_type, bandpass, eval_type='cross user'):\n",
    "    if eval_type == 'per user':\n",
    "        run_per_user_sd(model_type, bandpass)\n",
    "    elif eval_type == 'cross user':\n",
    "        run_cross_user_sd(model_type, bandpass)\n",
    "    elif eval_type == 'both':\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        cross_results = run_cross_user_sd(model_type, bandpass)\n",
    "        per_results = run_per_user_sd(model_type, bandpass)\n",
    "        \n",
    "        results.append(run_cross_user_sd(model_type, bandpass))\n",
    "        results.append(run_per_user_sd(model_type, bandpass))\n",
    "        \n",
    "        results = pd.concat(results)\n",
    "        file = \"results/CNN/{0}/tabulated/k fold/shallowDeep/shallowDeep_evaltype_{1}_bandpass_{2}\".format(model_type, eval_type, bandpass)\n",
    "        save_file(file)\n",
    "        return results\n",
    "\n",
    "        \n",
    "\n",
    "results = run_shallow_deep('clf',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

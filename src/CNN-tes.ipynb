{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import sys, io\n",
    "import pandas as pd \n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from braindecode.datasets.xy import create_from_X_y\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet , Deep4Net\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "from braindecode import EEGClassifier\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 20200220  # random seed to make results reproducible\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(X_train, X_valid):\n",
    "    # standardize per channel\n",
    "    means = X_train.mean(axis=(0,2), keepdims=True)\n",
    "    stds = X_train.std(axis=(0,2), keepdims=True)\n",
    "    X_train = (X_train - means) / (stds)\n",
    "    X_valid = (X_valid - means) / (stds)\n",
    "    return X_train, X_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_cnn (cnn, trainset, validset , n_classes , device, cuda , n_epochs):\n",
    "    # Extract number of chans and time steps from dataset\n",
    "    n_chans = trainset[0][0].shape[0]\n",
    "    input_window_samples = trainset[0][0].shape[1]\n",
    "\n",
    "    if cnn == 'shallow':\n",
    "        lr = 0.0625 * 0.01\n",
    "        weight_decay = 0\n",
    "        model =  ShallowFBCSPNet(n_chans, n_classes, input_window_samples=input_window_samples, final_conv_length=\"auto\")\n",
    "    else:\n",
    "        lr = 1 * 0.01\n",
    "        weight_decay = 0.5 * 0.001\n",
    "        \"\"\"\n",
    "        For 30 samples, filter time_length = 1\n",
    "        For 60 > samples, filter time length is left empty\n",
    "        for 15 samples, filter_time length = 1, filter_length_2 = 1, filter_length_3 = 1\n",
    "        \"\"\"\n",
    "        model =  Deep4Net(n_chans, n_classes, input_window_samples=input_window_samples,\n",
    "                  final_conv_length=\"auto\", pool_time_length=1, filter_time_length = 1,pool_time_stride=1)\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    print(next(model.parameters()).device)\n",
    "    batch_size = 32\n",
    "\n",
    "    clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(validset),  # using valid_set for validation\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(y_train, y_valid):\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_valid = le.transform(y_valid)\n",
    "    return y_train, y_valid, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_slice_in_list(s,l):\n",
    "    len_s = len(s) #so we don't recompute length of s on every iteration\n",
    "    return any(s == l[i:len_s+i] for i in range(len(l) - len_s+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_predict (X,y, model_type, n_epochs):\n",
    "    kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "\n",
    "    if model_type == 'clf':\n",
    "        results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "              \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "    else:\n",
    "        results = {'RMSE':[], 'R2':[]}\n",
    "\n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    num_classes = 0\n",
    "    clf = None\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(\"Train: \", train_index, \"Validation: \", test_index)\n",
    "\n",
    "        #Train/test split\n",
    "        X_train, X_valid = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "        y_train, y_valid = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "        \n",
    "        y_valid_classes = list(set(y_valid))\n",
    "        y_train_classes = list(set(y_train))\n",
    "\n",
    "        if is_slice_in_list(y_valid_classes, y_train_classes) == False: continue\n",
    "        print(set(y_train))\n",
    "        print(set(y_valid))\n",
    "\n",
    "        size = len(X_train) + len(X_valid) #get dataset size\n",
    "\n",
    "        #standardise per channel\n",
    "        X_train, X_valid = standardise(X_train, X_valid)\n",
    "        \n",
    "        #label the categorical variables \n",
    "        y_train, y_valid, le = categorise(y_train, y_valid)\n",
    "\n",
    "        # Convert training and validation sets into a suitable format\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        trainset = create_from_X_y(X_train, y_train, drop_last_window=False)\n",
    "        validset = create_from_X_y(X_valid, y_valid, drop_last_window=False)\n",
    "        sys.stdout = save_stdout\n",
    "\n",
    "        # count the number of classes\n",
    "        if len(set(y_train)) > num_classes:\n",
    "            num_classes = len(set(y_train))\n",
    "\n",
    "        # commence the training process\n",
    "        time_start = time.time()\n",
    "        save_stdout = sys.stdout\n",
    "        sys.stdout = open('/cs/tmp/ybk1/trash', 'w')\n",
    "        clf = choose_cnn ('deep', trainset, validset , num_classes , device, cuda, n_epochs).fit(trainset, y=None, epochs=n_epochs)\n",
    "        sys.stdout = save_stdout\n",
    "        print('Training completed created! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = le.inverse_transform(clf.predict(X_valid))\n",
    "        y_true = le.inverse_transform(y_valid)\n",
    "        total_predictions.append(y_pred)\n",
    "        total_true.append(y_true) \n",
    "        r = get_results(y_true, y_pred, model_type)\n",
    "\n",
    "        for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "            results[key].append(r[key])\n",
    "\n",
    "    for key in results: # finallly average out the results \n",
    "        results[key] = average(results[key])\n",
    "    return results, np.concatenate(total_predictions), np.concatenate(total_true), num_classes, size , clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f3545962fab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# train and make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m          \u001b[0;31m# get results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ded60d0c1041>\u001b[0m in \u001b[0;36mkfold_predict\u001b[0;34m(X, y, model_type, n_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0msave_stdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cs/tmp/ybk1/trash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_cnn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'deep'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidset\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training completed created! Time elapsed: {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    731\u001b[0m                                       step_fn=self.validation_step, **fit_params)\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mon_epoch_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mnotify\u001b[0;34m(self, method_name, **cb_kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcb_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcb_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/skorch/callbacks/lr_scheduler.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, net, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_get_closed_form_lr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_closed_form_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m_get_closed_form_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m         return [self.eta_min + (base_lr - self.eta_min) *\n\u001b[1;32m    500\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 for base_lr in self.base_lrs]\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    499\u001b[0m         return [self.eta_min + (base_lr - self.eta_min) *\n\u001b[1;32m    500\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 for base_lr in self.base_lrs]\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "time_original = time.time()\n",
    "\n",
    "results = []\n",
    "labels = ['attention','interest','effort']\n",
    "window_size_samples = 30\n",
    "\n",
    "saved_file = \"/cs/home/ybk1/Dissertation/data/all_users_sampled_with_individual_tests_30_window_annotated_EEG.pickle\"\n",
    "all_tests = load_file(saved_file)\n",
    "users = all_tests.keys()\n",
    "n_epochs  = 1\n",
    "model_type = 'clf'\n",
    "for user in users:\n",
    "    print(\"Working on user {0}\".format(user))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for label in labels:\n",
    "        time_start = time.time()\n",
    "        dt = all_tests[user] # dictionary of all the individual tests per user\n",
    "\n",
    "        X = np.array([np.array(x).transpose(0,2,1).astype(np.float32) for x in dt['inputs']])     \n",
    "        y = np.array([np.array(x) for x in dt[label]]) #Convert the categories into labels\n",
    "\n",
    "        # train and make predictions\n",
    "        r, y_pred, y_true, num_classes, size, clf = kfold_predict(X,y, model_type, n_epochs)\n",
    "\n",
    "         # get results\n",
    "        Results = namedtuple(\"Results\",\"user label n_epochs window_size time num_classes size accuracy bal_acc precision recall f1_score_macro f1_score_micro\")\n",
    "        results.append(Results(user, label, n_epochs, window_size_samples, time.time()-time_start,  num_classes,size, r['Accuracy'], r['Balanced Accuracy'], r['Precision'], r['Recall'], \n",
    "                              r['F1 Score Macro'], r['F1 Score Micro']))\n",
    "\n",
    "        # plot confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        saved_file = \"results/CNN/confusion/k fold/User_{0}_{1}.png\".format(user,label)\n",
    "        plot_confusion_matrix(cm, set(y_true), saved_file ,normalize=True)\n",
    "        \n",
    "        #plot loss curve\n",
    "        plot_loss_curve(clf)\n",
    "        plt.savefig(\"results/CNN/loss curves/k fold/User_{0}_{1}.png\".format(user,label))\n",
    "        print(\"Finished analysis on User {0}_{1}\".format(user,label))\n",
    "    print(\"Finished analysis on User {0}\".format(user))\n",
    "results  = pd.DataFrame(results).to_csv(\"results/CNN/tabulated/k fold/DeepCNN_Valid_performance_window_size_{0}_{1}_withclasses.csv\".format(window_size_samples,label), index=False )\n",
    "final_duration = time.time()- time_original\n",
    "print(\"All analyses are complete! Time elapsed: {0}\".format(final_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model \n",
    "# saved_file = \"models/attention_user_1_with_fi.pickle\"\n",
    "# with open(saved_file, 'wb') as handle:            \n",
    "#     pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from sklearn import preprocessing\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "torch.set_printoptions(linewidth=120) #Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default\n",
    "torch.manual_seed(0)\n",
    "from torch_lr_finder import LRFinder\n",
    "import pickle\n",
    "import torch.utils.data as data_utils\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 8), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*4, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = x.float()\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.view(-1, 4*2*4)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    # for 60 timepoints = 4* 10 * 8 or 4*24\n",
    "    # 120 timepoints = 4* 2* 7 and -1\n",
    "    # https://discuss.pytorch.org/t/runtimeerror-shape-1-400-is-invalid-for-input-of-size/33354\n",
    "    # https://discuss.pytorch.org/t/valueerror-expected-input-batch-size-324-to-match-target-batch-size-4/24498/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 8), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*4, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = x.float()\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.view(-1, 4*2*4)\n",
    "#         x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combine, self).__init__()\n",
    "        self.cnn = CNN()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=32, \n",
    "            hidden_size=16, \n",
    "            num_layers=1,\n",
    "            batch_first=True)\n",
    "        self.linear = nn.Linear(16 ,5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, timepoints, channels = x.size()\n",
    "        c_in = x\n",
    "        c_out = self.cnn(c_in)\n",
    "        r_in = c_out.view(batch_size, -1 , c_out.shape[1])\n",
    "        r_out, (h_n, h_c) = self.rnn(r_in)\n",
    "        r_out2 = self.linear(r_out[:, -1, :])\n",
    "        \n",
    "        return F.log_softmax(r_out2, dim=1)\n",
    "# X.shape - (#batch size, 1, #timepoints, #channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate function returns values of different criteria like accuracy, precision etc.**\n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(X)//batch_size):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted , multi_class=\"ovr\"))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted), average='macro'))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted) , average='macro'))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted) , average='macro')\n",
    "            recall = recall_score(Y, np.round(predicted) , average='macro')\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate random data**\n",
    "    \n",
    "*Data format:*\n",
    "\n",
    "Datatype - float32 (both X and Y)\n",
    "\n",
    "X.shape - (#samples, 1, #timepoints, #channels)\n",
    "\n",
    "Y.shape - (#samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "  return preds.argmax(dim=1).eq(labels).sum().item()### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_finder():\n",
    "    model = EEGNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "    lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "    lr_finder.range_test(train_loader, end_lr=100, num_iter=100, step_mode=\"exp\")\n",
    "    lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(train_loader, test_loader, dataset_type, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        if dataset_type == \"test\":\n",
    "            loader = test_loader\n",
    "        elif dataset_type == \"train\":\n",
    "            loader = train_loader\n",
    "        for data in loader:\n",
    "            inputs = data[0].cuda(0)\n",
    "            labels = data[1].cuda(0)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = (correct/total * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(X_train, train_loader,  model_type , verbose=False,):\n",
    "    \n",
    "    if model_type == 'CNN':\n",
    "        net = EEGNet().cuda(0)\n",
    "    else: \n",
    "        net = Combine().cuda(0)\n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "    preds_list = []\n",
    "    labels_list = []\n",
    "    for epoch in range(500):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "        #Get Batch\n",
    "\n",
    "            inputs = batch[0].cuda(0)\n",
    "            labels = batch[1].cuda(0)\n",
    "\n",
    "\n",
    "            preds = net(inputs) #Pass batch\n",
    "        #     criterion=nn.BCEWithLogitsLoss()\n",
    "            loss = F.cross_entropy(preds, labels.long()) #calculate loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  #calculate gradients\n",
    "            optimizer.step() #update weights\n",
    "\n",
    "\n",
    "            preds_list.append(preds)\n",
    "            labels_list.append(labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "            \n",
    "        if verbose == True:             \n",
    "    #     Validation accuracy\n",
    "    #     params = [\"acc\", \"fmeasure\"]\n",
    "    #     print (params)\n",
    "    #     print (\"Train - \", evaluate(net, X_train, y_train_new, params))\n",
    "            print(\"epoch: {0}, Accuracy {1}, loss: {2}\".format(epoch, total_correct/len(X_train), loss))\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipynb.fs.full.evaluation import *\n",
    "data = load_file(\"examples/User_1_sampled_annotated_EEG.pickle\")\n",
    "data['inputs'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Accuracy 0.35094001790510293, loss: 1.4480037689208984\n",
      "epoch: 1, Accuracy 0.36705461056401073, loss: 1.5189579725265503\n",
      "epoch: 2, Accuracy 0.36615935541629363, loss: 1.4226410388946533\n",
      "epoch: 3, Accuracy 0.37242614145031333, loss: 1.40126633644104\n",
      "epoch: 4, Accuracy 0.40555058191584603, loss: 1.3762263059616089\n",
      "epoch: 5, Accuracy 0.4297224709042077, loss: 1.1519502401351929\n",
      "epoch: 6, Accuracy 0.4744852282900627, loss: 1.1013457775115967\n",
      "epoch: 7, Accuracy 0.4726947179946285, loss: 1.3084444999694824\n",
      "epoch: 8, Accuracy 0.4870188003581021, loss: 1.190678596496582\n",
      "epoch: 9, Accuracy 0.5058191584601611, loss: 1.1995295286178589\n",
      "epoch: 10, Accuracy 0.4986571172784244, loss: 1.1557328701019287\n",
      "epoch: 11, Accuracy 0.4932855863921218, loss: 0.9991579651832581\n",
      "epoch: 12, Accuracy 0.5040286481647269, loss: 1.0435608625411987\n",
      "epoch: 13, Accuracy 0.5129811996418979, loss: 1.1422083377838135\n",
      "epoch: 14, Accuracy 0.5058191584601611, loss: 1.0455299615859985\n",
      "epoch: 15, Accuracy 0.5102954341987467, loss: 1.1648204326629639\n",
      "epoch: 16, Accuracy 0.5058191584601611, loss: 0.8137280941009521\n",
      "epoch: 17, Accuracy 0.5076096687555953, loss: 1.01651132106781\n",
      "epoch: 18, Accuracy 0.5219337511190689, loss: 1.0077862739562988\n",
      "epoch: 19, Accuracy 0.5156669650850493, loss: 1.1240243911743164\n",
      "epoch: 20, Accuracy 0.5076096687555953, loss: 1.3209576606750488\n",
      "epoch: 21, Accuracy 0.5013428827215757, loss: 0.9828274846076965\n",
      "epoch: 22, Accuracy 0.5094001790510295, loss: 1.04385244846344\n",
      "epoch: 23, Accuracy 0.5120859444941809, loss: 0.9619435667991638\n",
      "epoch: 24, Accuracy 0.5210384959713519, loss: 0.9687895178794861\n",
      "epoch: 25, Accuracy 0.5138764547896151, loss: 0.8813077807426453\n",
      "epoch: 26, Accuracy 0.5156669650850493, loss: 1.1703304052352905\n",
      "epoch: 27, Accuracy 0.5273052820053715, loss: 0.9967997074127197\n",
      "epoch: 28, Accuracy 0.5094001790510295, loss: 0.9069151878356934\n",
      "epoch: 29, Accuracy 0.5308863025962399, loss: 0.9649366736412048\n",
      "epoch: 30, Accuracy 0.5237242614145031, loss: 1.2062734365463257\n",
      "epoch: 31, Accuracy 0.5353625783348255, loss: 1.1345603466033936\n",
      "epoch: 32, Accuracy 0.5282005371530887, loss: 0.9772534370422363\n",
      "epoch: 33, Accuracy 0.5174574753804835, loss: 1.2901407480239868\n",
      "epoch: 34, Accuracy 0.5264100268576545, loss: 1.1037495136260986\n",
      "epoch: 35, Accuracy 0.5058191584601611, loss: 0.8742900490760803\n",
      "epoch: 36, Accuracy 0.5246195165622203, loss: 1.0615020990371704\n",
      "epoch: 37, Accuracy 0.5308863025962399, loss: 1.0391138792037964\n",
      "epoch: 38, Accuracy 0.5362578334825425, loss: 1.023066520690918\n",
      "epoch: 39, Accuracy 0.5335720680393913, loss: 1.3080530166625977\n",
      "epoch: 40, Accuracy 0.5273052820053715, loss: 0.832231879234314\n",
      "epoch: 41, Accuracy 0.5210384959713519, loss: 0.9475088715553284\n",
      "epoch: 42, Accuracy 0.5362578334825425, loss: 0.9515910148620605\n",
      "epoch: 43, Accuracy 0.5362578334825425, loss: 1.2504209280014038\n",
      "epoch: 44, Accuracy 0.5219337511190689, loss: 0.9654986262321472\n",
      "epoch: 45, Accuracy 0.5478961504028648, loss: 0.9574980139732361\n",
      "epoch: 46, Accuracy 0.5353625783348255, loss: 1.108933448791504\n",
      "epoch: 47, Accuracy 0.5380483437779767, loss: 1.0910297632217407\n",
      "epoch: 48, Accuracy 0.5389435989256938, loss: 1.083752989768982\n",
      "epoch: 49, Accuracy 0.5335720680393913, loss: 0.8943952918052673\n",
      "epoch: 50, Accuracy 0.5380483437779767, loss: 1.0842323303222656\n",
      "epoch: 51, Accuracy 0.5228290062667861, loss: 0.8070740699768066\n",
      "epoch: 52, Accuracy 0.5282005371530887, loss: 1.0326688289642334\n",
      "epoch: 53, Accuracy 0.549686660698299, loss: 0.7732887268066406\n",
      "epoch: 54, Accuracy 0.5362578334825425, loss: 0.9032635688781738\n",
      "epoch: 55, Accuracy 0.5317815577439571, loss: 0.8279510736465454\n",
      "epoch: 56, Accuracy 0.5237242614145031, loss: 1.0983026027679443\n",
      "epoch: 57, Accuracy 0.5514771709937332, loss: 0.7472785711288452\n",
      "epoch: 58, Accuracy 0.5434198746642793, loss: 0.8809057474136353\n",
      "epoch: 59, Accuracy 0.5478961504028648, loss: 1.179943323135376\n",
      "epoch: 60, Accuracy 0.5478961504028648, loss: 0.8822774291038513\n",
      "epoch: 61, Accuracy 0.5541629364368845, loss: 0.8974780440330505\n",
      "epoch: 62, Accuracy 0.5505819158460161, loss: 1.154894232749939\n",
      "epoch: 63, Accuracy 0.5192479856759177, loss: 1.317883849143982\n",
      "epoch: 64, Accuracy 0.5371530886302597, loss: 0.9279899597167969\n",
      "epoch: 65, Accuracy 0.5353625783348255, loss: 1.0001667737960815\n",
      "epoch: 66, Accuracy 0.5541629364368845, loss: 1.0803191661834717\n",
      "epoch: 67, Accuracy 0.5461056401074306, loss: 1.448704719543457\n",
      "epoch: 68, Accuracy 0.5532676812891674, loss: 1.2820895910263062\n",
      "epoch: 69, Accuracy 0.5640107430617726, loss: 0.8865624070167542\n",
      "epoch: 70, Accuracy 0.5568487018800358, loss: 0.7045407295227051\n",
      "epoch: 71, Accuracy 0.5631154879140555, loss: 0.8014512062072754\n",
      "epoch: 72, Accuracy 0.5478961504028648, loss: 1.0283937454223633\n",
      "epoch: 73, Accuracy 0.5514771709937332, loss: 1.056848168373108\n",
      "epoch: 74, Accuracy 0.5514771709937332, loss: 0.9236945509910583\n",
      "epoch: 75, Accuracy 0.5470008952551477, loss: 1.0450383424758911\n",
      "epoch: 76, Accuracy 0.549686660698299, loss: 1.0206490755081177\n",
      "epoch: 77, Accuracy 0.540734109221128, loss: 0.8033298850059509\n",
      "epoch: 78, Accuracy 0.5622202327663384, loss: 0.7547861933708191\n",
      "epoch: 79, Accuracy 0.5523724261414503, loss: 1.1619234085083008\n",
      "epoch: 80, Accuracy 0.5577439570277529, loss: 0.917512059211731\n",
      "epoch: 81, Accuracy 0.5353625783348255, loss: 0.8551530838012695\n",
      "epoch: 82, Accuracy 0.5523724261414503, loss: 0.9485069513320923\n",
      "epoch: 83, Accuracy 0.5443151298119964, loss: 1.0195257663726807\n",
      "epoch: 84, Accuracy 0.5452103849597135, loss: 1.3979740142822266\n",
      "epoch: 85, Accuracy 0.5389435989256938, loss: 0.9249998927116394\n",
      "epoch: 86, Accuracy 0.5326768128916741, loss: 0.8464131355285645\n",
      "epoch: 87, Accuracy 0.5550581915846016, loss: 1.2923786640167236\n",
      "epoch: 88, Accuracy 0.5380483437779767, loss: 1.1627548933029175\n",
      "epoch: 89, Accuracy 0.5541629364368845, loss: 0.9414148926734924\n",
      "epoch: 90, Accuracy 0.5622202327663384, loss: 1.142152190208435\n",
      "epoch: 91, Accuracy 0.5640107430617726, loss: 0.8446530103683472\n",
      "epoch: 92, Accuracy 0.540734109221128, loss: 1.115842342376709\n",
      "epoch: 93, Accuracy 0.5443151298119964, loss: 0.7318432927131653\n",
      "epoch: 94, Accuracy 0.5478961504028648, loss: 1.489053726196289\n",
      "epoch: 95, Accuracy 0.5434198746642793, loss: 0.9016425013542175\n",
      "epoch: 96, Accuracy 0.5541629364368845, loss: 0.9388755559921265\n",
      "epoch: 97, Accuracy 0.5649059982094897, loss: 0.716724693775177\n",
      "epoch: 98, Accuracy 0.5640107430617726, loss: 1.0634939670562744\n",
      "epoch: 99, Accuracy 0.5613249776186213, loss: 1.2401564121246338\n",
      "epoch: 100, Accuracy 0.5702775290957923, loss: 0.8010306358337402\n",
      "epoch: 101, Accuracy 0.5443151298119964, loss: 0.6933701634407043\n",
      "epoch: 102, Accuracy 0.5613249776186213, loss: 0.7695775032043457\n",
      "epoch: 103, Accuracy 0.5487914055505819, loss: 0.7215918898582458\n",
      "epoch: 104, Accuracy 0.5398388540734109, loss: 0.9208258986473083\n",
      "epoch: 105, Accuracy 0.5434198746642793, loss: 1.252379298210144\n",
      "epoch: 106, Accuracy 0.540734109221128, loss: 0.9714744687080383\n",
      "epoch: 107, Accuracy 0.5568487018800358, loss: 1.05095636844635\n",
      "epoch: 108, Accuracy 0.5640107430617726, loss: 1.016445517539978\n",
      "epoch: 109, Accuracy 0.5505819158460161, loss: 0.9958638548851013\n",
      "epoch: 110, Accuracy 0.5720680393912265, loss: 0.7384154200553894\n",
      "epoch: 111, Accuracy 0.5613249776186213, loss: 1.1942692995071411\n",
      "epoch: 112, Accuracy 0.5711727842435094, loss: 0.756249189376831\n",
      "epoch: 113, Accuracy 0.5783348254252462, loss: 0.9470940828323364\n",
      "epoch: 114, Accuracy 0.5729632945389436, loss: 0.8084170818328857\n",
      "epoch: 115, Accuracy 0.5550581915846016, loss: 1.0507901906967163\n",
      "epoch: 116, Accuracy 0.5631154879140555, loss: 1.0608015060424805\n",
      "epoch: 117, Accuracy 0.5559534467323187, loss: 0.8638553619384766\n",
      "epoch: 118, Accuracy 0.5425246195165622, loss: 1.000704288482666\n",
      "epoch: 119, Accuracy 0.5783348254252462, loss: 1.450247883796692\n",
      "epoch: 120, Accuracy 0.5666965085049239, loss: 0.8655898571014404\n",
      "epoch: 121, Accuracy 0.5541629364368845, loss: 1.1403387784957886\n",
      "epoch: 122, Accuracy 0.5622202327663384, loss: 0.9700067043304443\n",
      "epoch: 123, Accuracy 0.5550581915846016, loss: 1.0743649005889893\n",
      "epoch: 124, Accuracy 0.5729632945389436, loss: 0.8169795870780945\n",
      "epoch: 125, Accuracy 0.5720680393912265, loss: 0.8231765031814575\n",
      "epoch: 126, Accuracy 0.5711727842435094, loss: 1.362878680229187\n",
      "epoch: 127, Accuracy 0.5711727842435094, loss: 0.8245065212249756\n",
      "epoch: 128, Accuracy 0.5461056401074306, loss: 1.0793070793151855\n",
      "epoch: 129, Accuracy 0.5550581915846016, loss: 1.0736360549926758\n",
      "epoch: 130, Accuracy 0.5568487018800358, loss: 0.8897644877433777\n",
      "epoch: 131, Accuracy 0.5658012533572068, loss: 1.0845659971237183\n",
      "epoch: 132, Accuracy 0.5658012533572068, loss: 0.947573721408844\n",
      "epoch: 133, Accuracy 0.567591763652641, loss: 0.6808835864067078\n",
      "epoch: 134, Accuracy 0.55863921217547, loss: 0.9178946018218994\n",
      "epoch: 135, Accuracy 0.549686660698299, loss: 0.9627410769462585\n",
      "epoch: 136, Accuracy 0.5658012533572068, loss: 0.7031726241111755\n",
      "epoch: 137, Accuracy 0.5640107430617726, loss: 0.7200929522514343\n",
      "epoch: 138, Accuracy 0.5568487018800358, loss: 0.8109951019287109\n",
      "epoch: 139, Accuracy 0.5550581915846016, loss: 0.8852372169494629\n",
      "epoch: 140, Accuracy 0.5649059982094897, loss: 0.7707826495170593\n",
      "epoch: 141, Accuracy 0.5649059982094897, loss: 0.9794630408287048\n",
      "epoch: 142, Accuracy 0.5729632945389436, loss: 0.9233852624893188\n",
      "epoch: 143, Accuracy 0.5416293643688451, loss: 0.7760570645332336\n",
      "epoch: 144, Accuracy 0.5738585496866607, loss: 0.8211372494697571\n",
      "epoch: 145, Accuracy 0.5568487018800358, loss: 1.1219375133514404\n",
      "epoch: 146, Accuracy 0.5702775290957923, loss: 0.7481374740600586\n",
      "epoch: 147, Accuracy 0.5801253357206804, loss: 0.8294165134429932\n",
      "epoch: 148, Accuracy 0.5658012533572068, loss: 0.936824381351471\n",
      "epoch: 149, Accuracy 0.5470008952551477, loss: 1.3366291522979736\n",
      "epoch: 150, Accuracy 0.5478961504028648, loss: 0.9461773037910461\n",
      "epoch: 151, Accuracy 0.5649059982094897, loss: 0.9067175388336182\n",
      "epoch: 152, Accuracy 0.5613249776186213, loss: 0.835639238357544\n",
      "epoch: 153, Accuracy 0.5649059982094897, loss: 1.0916072130203247\n",
      "epoch: 154, Accuracy 0.5756490599820949, loss: 1.0323185920715332\n",
      "epoch: 155, Accuracy 0.5711727842435094, loss: 0.7304191589355469\n",
      "epoch: 156, Accuracy 0.5729632945389436, loss: 0.9151759147644043\n",
      "epoch: 157, Accuracy 0.5478961504028648, loss: 1.005212664604187\n",
      "epoch: 158, Accuracy 0.5747538048343778, loss: 0.7694222927093506\n",
      "epoch: 159, Accuracy 0.55863921217547, loss: 1.2286183834075928\n",
      "epoch: 160, Accuracy 0.5666965085049239, loss: 0.9515752196311951\n",
      "epoch: 161, Accuracy 0.5711727842435094, loss: 1.133452296257019\n",
      "epoch: 162, Accuracy 0.5666965085049239, loss: 0.7529969215393066\n",
      "epoch: 163, Accuracy 0.5684870188003581, loss: 0.6978808045387268\n",
      "epoch: 164, Accuracy 0.5631154879140555, loss: 0.9656457304954529\n",
      "epoch: 165, Accuracy 0.5881826320501343, loss: 0.6560722589492798\n",
      "epoch: 166, Accuracy 0.576544315129812, loss: 1.1585001945495605\n",
      "epoch: 167, Accuracy 0.5666965085049239, loss: 0.9718339443206787\n",
      "epoch: 168, Accuracy 0.5738585496866607, loss: 0.9117433428764343\n",
      "epoch: 169, Accuracy 0.5738585496866607, loss: 0.7932705879211426\n",
      "epoch: 170, Accuracy 0.5702775290957923, loss: 1.0241212844848633\n",
      "epoch: 171, Accuracy 0.5604297224709042, loss: 1.2310853004455566\n",
      "epoch: 172, Accuracy 0.567591763652641, loss: 0.9188116788864136\n",
      "epoch: 173, Accuracy 0.5577439570277529, loss: 0.7886291146278381\n",
      "epoch: 174, Accuracy 0.5872873769024172, loss: 0.9001554846763611\n",
      "epoch: 175, Accuracy 0.55863921217547, loss: 0.6985675096511841\n",
      "epoch: 176, Accuracy 0.567591763652641, loss: 0.7269535064697266\n",
      "epoch: 177, Accuracy 0.5756490599820949, loss: 1.3387651443481445\n",
      "epoch: 178, Accuracy 0.5595344673231871, loss: 1.0427864789962769\n",
      "epoch: 179, Accuracy 0.5523724261414503, loss: 0.9032687544822693\n",
      "epoch: 180, Accuracy 0.5693822739480752, loss: 0.975915789604187\n",
      "epoch: 181, Accuracy 0.5738585496866607, loss: 0.8275538682937622\n",
      "epoch: 182, Accuracy 0.5631154879140555, loss: 0.6988075375556946\n",
      "epoch: 183, Accuracy 0.5810205908683975, loss: 0.7249781489372253\n",
      "epoch: 184, Accuracy 0.5783348254252462, loss: 0.5697993040084839\n",
      "epoch: 185, Accuracy 0.5666965085049239, loss: 1.1365267038345337\n",
      "epoch: 186, Accuracy 0.5595344673231871, loss: 0.8695690035820007\n",
      "epoch: 187, Accuracy 0.55863921217547, loss: 1.0592684745788574\n",
      "epoch: 188, Accuracy 0.5559534467323187, loss: 0.8610183596611023\n",
      "epoch: 189, Accuracy 0.5738585496866607, loss: 1.1261316537857056\n",
      "epoch: 190, Accuracy 0.5810205908683975, loss: 0.8287831544876099\n",
      "epoch: 191, Accuracy 0.5702775290957923, loss: 0.9773553013801575\n",
      "epoch: 192, Accuracy 0.5622202327663384, loss: 1.213310718536377\n",
      "epoch: 193, Accuracy 0.5899731423455685, loss: 0.7219661474227905\n",
      "epoch: 194, Accuracy 0.5658012533572068, loss: 1.034328818321228\n",
      "epoch: 195, Accuracy 0.5478961504028648, loss: 1.064515233039856\n",
      "epoch: 196, Accuracy 0.5613249776186213, loss: 0.9347099661827087\n",
      "epoch: 197, Accuracy 0.5559534467323187, loss: 1.2138017416000366\n",
      "epoch: 198, Accuracy 0.5622202327663384, loss: 0.8539680242538452\n",
      "epoch: 199, Accuracy 0.5774395702775291, loss: 0.8637458682060242\n",
      "epoch: 200, Accuracy 0.567591763652641, loss: 1.200060486793518\n",
      "epoch: 201, Accuracy 0.5837063563115488, loss: 1.0392178297042847\n",
      "epoch: 202, Accuracy 0.5801253357206804, loss: 0.8189347982406616\n",
      "epoch: 203, Accuracy 0.5541629364368845, loss: 0.9321510791778564\n",
      "epoch: 204, Accuracy 0.5568487018800358, loss: 0.7973436117172241\n",
      "epoch: 205, Accuracy 0.5747538048343778, loss: 1.121341347694397\n",
      "epoch: 206, Accuracy 0.5693822739480752, loss: 0.8028170466423035\n",
      "epoch: 207, Accuracy 0.5631154879140555, loss: 0.980798065662384\n",
      "epoch: 208, Accuracy 0.5729632945389436, loss: 0.7073383927345276\n",
      "epoch: 209, Accuracy 0.5523724261414503, loss: 0.9505607485771179\n",
      "epoch: 210, Accuracy 0.5666965085049239, loss: 0.7360450625419617\n",
      "epoch: 211, Accuracy 0.5631154879140555, loss: 0.6851983666419983\n",
      "epoch: 212, Accuracy 0.5720680393912265, loss: 0.8399577736854553\n",
      "epoch: 213, Accuracy 0.5756490599820949, loss: 0.8688167333602905\n",
      "epoch: 214, Accuracy 0.5953446732318711, loss: 0.528069257736206\n",
      "epoch: 215, Accuracy 0.5774395702775291, loss: 0.8602582216262817\n",
      "epoch: 216, Accuracy 0.576544315129812, loss: 0.8564441800117493\n",
      "epoch: 217, Accuracy 0.567591763652641, loss: 0.7646243572235107\n",
      "epoch: 218, Accuracy 0.5658012533572068, loss: 0.6959107518196106\n",
      "epoch: 219, Accuracy 0.5756490599820949, loss: 0.9112613201141357\n",
      "epoch: 220, Accuracy 0.5783348254252462, loss: 0.8324504494667053\n",
      "epoch: 221, Accuracy 0.5550581915846016, loss: 0.8373227715492249\n",
      "epoch: 222, Accuracy 0.5935541629364369, loss: 0.8693737983703613\n",
      "epoch: 223, Accuracy 0.5810205908683975, loss: 0.6576871871948242\n",
      "epoch: 224, Accuracy 0.5604297224709042, loss: 0.9208622574806213\n",
      "epoch: 225, Accuracy 0.5774395702775291, loss: 0.7774196267127991\n",
      "epoch: 226, Accuracy 0.576544315129812, loss: 0.7853894829750061\n",
      "epoch: 227, Accuracy 0.5711727842435094, loss: 0.6598649621009827\n",
      "epoch: 228, Accuracy 0.5452103849597135, loss: 1.0120023488998413\n",
      "epoch: 229, Accuracy 0.5684870188003581, loss: 1.1137837171554565\n",
      "epoch: 230, Accuracy 0.5828111011638317, loss: 1.026566505432129\n",
      "epoch: 231, Accuracy 0.5792300805729633, loss: 0.8575142025947571\n",
      "epoch: 232, Accuracy 0.5810205908683975, loss: 0.8583928942680359\n",
      "epoch: 233, Accuracy 0.5810205908683975, loss: 1.0222374200820923\n",
      "epoch: 234, Accuracy 0.5613249776186213, loss: 0.8594921231269836\n",
      "epoch: 235, Accuracy 0.5720680393912265, loss: 1.168848991394043\n",
      "epoch: 236, Accuracy 0.5702775290957923, loss: 0.8359424471855164\n",
      "epoch: 237, Accuracy 0.576544315129812, loss: 0.7150441408157349\n",
      "epoch: 238, Accuracy 0.5729632945389436, loss: 0.8425347805023193\n",
      "epoch: 239, Accuracy 0.5810205908683975, loss: 0.9053354859352112\n",
      "epoch: 240, Accuracy 0.5720680393912265, loss: 0.7325326204299927\n",
      "epoch: 241, Accuracy 0.5792300805729633, loss: 0.8369205594062805\n",
      "epoch: 242, Accuracy 0.5801253357206804, loss: 0.9991778135299683\n",
      "epoch: 243, Accuracy 0.5756490599820949, loss: 0.7623330354690552\n",
      "epoch: 244, Accuracy 0.5711727842435094, loss: 1.0698602199554443\n",
      "epoch: 245, Accuracy 0.5640107430617726, loss: 0.9050467610359192\n",
      "epoch: 246, Accuracy 0.5792300805729633, loss: 0.9380668997764587\n",
      "epoch: 247, Accuracy 0.55863921217547, loss: 0.99696946144104\n",
      "epoch: 248, Accuracy 0.585496866606983, loss: 0.8920772671699524\n",
      "epoch: 249, Accuracy 0.5801253357206804, loss: 0.76336669921875\n",
      "epoch: 250, Accuracy 0.5890778871978514, loss: 0.616095781326294\n",
      "epoch: 251, Accuracy 0.5684870188003581, loss: 0.8589733839035034\n",
      "epoch: 252, Accuracy 0.5863921217547001, loss: 1.0296555757522583\n",
      "epoch: 253, Accuracy 0.6016114592658908, loss: 0.9304983615875244\n",
      "epoch: 254, Accuracy 0.5658012533572068, loss: 0.8928078413009644\n",
      "epoch: 255, Accuracy 0.5828111011638317, loss: 0.7998360991477966\n",
      "epoch: 256, Accuracy 0.5684870188003581, loss: 0.7520000338554382\n",
      "epoch: 257, Accuracy 0.5702775290957923, loss: 1.1088156700134277\n",
      "epoch: 258, Accuracy 0.5810205908683975, loss: 0.5778746604919434\n",
      "epoch: 259, Accuracy 0.5837063563115488, loss: 0.9065883755683899\n",
      "epoch: 260, Accuracy 0.5702775290957923, loss: 0.8492316007614136\n",
      "epoch: 261, Accuracy 0.5559534467323187, loss: 0.8377178907394409\n",
      "epoch: 262, Accuracy 0.5801253357206804, loss: 0.7454380393028259\n",
      "epoch: 263, Accuracy 0.5908683974932856, loss: 0.993313193321228\n",
      "epoch: 264, Accuracy 0.5899731423455685, loss: 1.222718358039856\n",
      "epoch: 265, Accuracy 0.5953446732318711, loss: 0.6547530293464661\n",
      "epoch: 266, Accuracy 0.5908683974932856, loss: 0.9725541472434998\n",
      "epoch: 267, Accuracy 0.5989256938227395, loss: 0.886442244052887\n",
      "epoch: 268, Accuracy 0.5890778871978514, loss: 0.8825992941856384\n",
      "epoch: 269, Accuracy 0.5738585496866607, loss: 1.2119455337524414\n",
      "epoch: 270, Accuracy 0.5613249776186213, loss: 0.7428932785987854\n",
      "epoch: 271, Accuracy 0.5872873769024172, loss: 0.729667603969574\n",
      "epoch: 272, Accuracy 0.5801253357206804, loss: 0.8403058648109436\n",
      "epoch: 273, Accuracy 0.6016114592658908, loss: 0.8591193556785583\n",
      "epoch: 274, Accuracy 0.5828111011638317, loss: 0.8105597496032715\n",
      "epoch: 275, Accuracy 0.5899731423455685, loss: 0.6276718378067017\n",
      "epoch: 276, Accuracy 0.5774395702775291, loss: 0.730106770992279\n",
      "epoch: 277, Accuracy 0.567591763652641, loss: 0.7857869863510132\n",
      "epoch: 278, Accuracy 0.5863921217547001, loss: 1.1392205953598022\n",
      "epoch: 279, Accuracy 0.5747538048343778, loss: 1.2510766983032227\n",
      "epoch: 280, Accuracy 0.5863921217547001, loss: 1.1533160209655762\n",
      "epoch: 281, Accuracy 0.5863921217547001, loss: 0.9088922739028931\n",
      "epoch: 282, Accuracy 0.5828111011638317, loss: 1.0553289651870728\n",
      "epoch: 283, Accuracy 0.5666965085049239, loss: 0.7626509666442871\n",
      "epoch: 284, Accuracy 0.6025067144136079, loss: 0.8717196583747864\n",
      "epoch: 285, Accuracy 0.5801253357206804, loss: 1.6015419960021973\n",
      "epoch: 286, Accuracy 0.5899731423455685, loss: 1.0167663097381592\n",
      "epoch: 287, Accuracy 0.5711727842435094, loss: 0.6158549785614014\n",
      "epoch: 288, Accuracy 0.5935541629364369, loss: 0.8643096685409546\n",
      "epoch: 289, Accuracy 0.5783348254252462, loss: 0.49437573552131653\n",
      "epoch: 290, Accuracy 0.6016114592658908, loss: 1.0243520736694336\n",
      "epoch: 291, Accuracy 0.5783348254252462, loss: 0.624420166015625\n",
      "epoch: 292, Accuracy 0.594449418084154, loss: 0.910740077495575\n",
      "epoch: 293, Accuracy 0.5881826320501343, loss: 1.1269707679748535\n",
      "epoch: 294, Accuracy 0.5783348254252462, loss: 1.0886449813842773\n",
      "epoch: 295, Accuracy 0.5532676812891674, loss: 0.684834897518158\n",
      "epoch: 296, Accuracy 0.5971351835273053, loss: 0.5671284198760986\n",
      "epoch: 297, Accuracy 0.6060877350044763, loss: 0.5477265119552612\n",
      "epoch: 298, Accuracy 0.5872873769024172, loss: 0.8490439653396606\n",
      "epoch: 299, Accuracy 0.5792300805729633, loss: 0.5942481756210327\n",
      "epoch: 300, Accuracy 0.5863921217547001, loss: 0.7668881416320801\n",
      "epoch: 301, Accuracy 0.5917636526410027, loss: 0.8369678258895874\n",
      "epoch: 302, Accuracy 0.594449418084154, loss: 1.0055253505706787\n",
      "epoch: 303, Accuracy 0.6069829901521934, loss: 0.9723620414733887\n",
      "epoch: 304, Accuracy 0.5863921217547001, loss: 0.848635196685791\n",
      "epoch: 305, Accuracy 0.5917636526410027, loss: 0.7982583045959473\n",
      "epoch: 306, Accuracy 0.5801253357206804, loss: 0.8455808162689209\n",
      "epoch: 307, Accuracy 0.6078782452999105, loss: 0.726503849029541\n",
      "epoch: 308, Accuracy 0.6051924798567592, loss: 0.7102376818656921\n",
      "epoch: 309, Accuracy 0.5837063563115488, loss: 0.8210656642913818\n",
      "epoch: 310, Accuracy 0.5953446732318711, loss: 0.819778561592102\n",
      "epoch: 311, Accuracy 0.5962399283795882, loss: 0.9398285746574402\n",
      "epoch: 312, Accuracy 0.5926589077887198, loss: 0.9879313111305237\n",
      "epoch: 313, Accuracy 0.5908683974932856, loss: 0.9616472721099854\n",
      "epoch: 314, Accuracy 0.5720680393912265, loss: 1.0536795854568481\n",
      "epoch: 315, Accuracy 0.5935541629364369, loss: 0.9031209349632263\n",
      "epoch: 316, Accuracy 0.5801253357206804, loss: 0.8641200661659241\n",
      "epoch: 317, Accuracy 0.612354521038496, loss: 0.9234708547592163\n",
      "epoch: 318, Accuracy 0.5899731423455685, loss: 0.8229274749755859\n",
      "epoch: 319, Accuracy 0.5819158460161146, loss: 0.5809687972068787\n",
      "epoch: 320, Accuracy 0.5881826320501343, loss: 1.1156108379364014\n",
      "epoch: 321, Accuracy 0.5738585496866607, loss: 0.8947251439094543\n",
      "epoch: 322, Accuracy 0.5962399283795882, loss: 0.9156002998352051\n",
      "epoch: 323, Accuracy 0.5819158460161146, loss: 1.2745206356048584\n",
      "epoch: 324, Accuracy 0.5837063563115488, loss: 0.7838755249977112\n",
      "epoch: 325, Accuracy 0.5828111011638317, loss: 0.823688805103302\n",
      "epoch: 326, Accuracy 0.5792300805729633, loss: 0.7730907201766968\n",
      "epoch: 327, Accuracy 0.5953446732318711, loss: 0.9112620949745178\n",
      "epoch: 328, Accuracy 0.6114592658907789, loss: 1.0101772546768188\n",
      "epoch: 329, Accuracy 0.5729632945389436, loss: 0.7879863381385803\n",
      "epoch: 330, Accuracy 0.5846016114592659, loss: 0.9223649501800537\n",
      "epoch: 331, Accuracy 0.594449418084154, loss: 1.2709234952926636\n",
      "epoch: 332, Accuracy 0.5980304386750224, loss: 1.0897220373153687\n",
      "epoch: 333, Accuracy 0.5899731423455685, loss: 0.6869192123413086\n",
      "epoch: 334, Accuracy 0.5926589077887198, loss: 0.6528145670890808\n",
      "epoch: 335, Accuracy 0.5747538048343778, loss: 0.7099438905715942\n",
      "epoch: 336, Accuracy 0.5837063563115488, loss: 0.9564291834831238\n",
      "epoch: 337, Accuracy 0.5962399283795882, loss: 0.9392378330230713\n",
      "epoch: 338, Accuracy 0.5828111011638317, loss: 1.3165279626846313\n",
      "epoch: 339, Accuracy 0.5971351835273053, loss: 0.6533027291297913\n",
      "epoch: 340, Accuracy 0.5783348254252462, loss: 1.023537039756775\n",
      "epoch: 341, Accuracy 0.5971351835273053, loss: 0.9803910851478577\n",
      "epoch: 342, Accuracy 0.594449418084154, loss: 1.106590986251831\n",
      "epoch: 343, Accuracy 0.5872873769024172, loss: 1.043557047843933\n",
      "epoch: 344, Accuracy 0.5881826320501343, loss: 1.0476330518722534\n",
      "epoch: 345, Accuracy 0.5828111011638317, loss: 1.2724350690841675\n",
      "epoch: 346, Accuracy 0.6132497761862131, loss: 1.0021284818649292\n",
      "epoch: 347, Accuracy 0.5819158460161146, loss: 0.816435694694519\n",
      "epoch: 348, Accuracy 0.5980304386750224, loss: 1.0322582721710205\n",
      "epoch: 349, Accuracy 0.5989256938227395, loss: 0.664192795753479\n",
      "epoch: 350, Accuracy 0.6096687555953447, loss: 1.1808799505233765\n",
      "epoch: 351, Accuracy 0.5890778871978514, loss: 1.4856228828430176\n",
      "epoch: 352, Accuracy 0.5604297224709042, loss: 1.0025880336761475\n",
      "epoch: 353, Accuracy 0.5819158460161146, loss: 0.6972670555114746\n",
      "epoch: 354, Accuracy 0.5846016114592659, loss: 0.9637519717216492\n",
      "epoch: 355, Accuracy 0.6016114592658908, loss: 0.9477173089981079\n",
      "epoch: 356, Accuracy 0.6248880931065354, loss: 0.9345470070838928\n",
      "epoch: 357, Accuracy 0.5917636526410027, loss: 0.9208632111549377\n",
      "epoch: 358, Accuracy 0.5819158460161146, loss: 0.9902687072753906\n",
      "epoch: 359, Accuracy 0.5917636526410027, loss: 0.8600227236747742\n",
      "epoch: 360, Accuracy 0.6078782452999105, loss: 0.7637125849723816\n",
      "epoch: 361, Accuracy 0.5926589077887198, loss: 0.8307738304138184\n",
      "epoch: 362, Accuracy 0.5998209489704566, loss: 1.073912501335144\n",
      "epoch: 363, Accuracy 0.5908683974932856, loss: 0.7448195815086365\n",
      "epoch: 364, Accuracy 0.6114592658907789, loss: 0.9437503814697266\n",
      "epoch: 365, Accuracy 0.5962399283795882, loss: 1.2646434307098389\n",
      "epoch: 366, Accuracy 0.6051924798567592, loss: 0.7054296135902405\n",
      "epoch: 367, Accuracy 0.5890778871978514, loss: 1.0264242887496948\n",
      "epoch: 368, Accuracy 0.5783348254252462, loss: 1.1769254207611084\n",
      "epoch: 369, Accuracy 0.6025067144136079, loss: 0.7486330270767212\n",
      "epoch: 370, Accuracy 0.6114592658907789, loss: 0.825825572013855\n",
      "epoch: 371, Accuracy 0.5863921217547001, loss: 0.7702221870422363\n",
      "epoch: 372, Accuracy 0.6025067144136079, loss: 0.7554774880409241\n",
      "epoch: 373, Accuracy 0.5774395702775291, loss: 0.9247215390205383\n",
      "epoch: 374, Accuracy 0.5935541629364369, loss: 0.8770871162414551\n",
      "epoch: 375, Accuracy 0.5792300805729633, loss: 0.7783246040344238\n",
      "epoch: 376, Accuracy 0.5863921217547001, loss: 1.418163776397705\n",
      "epoch: 377, Accuracy 0.6141450313339302, loss: 0.8439651727676392\n",
      "epoch: 378, Accuracy 0.5890778871978514, loss: 0.7863212823867798\n",
      "epoch: 379, Accuracy 0.5998209489704566, loss: 0.937463104724884\n",
      "epoch: 380, Accuracy 0.6042972247090421, loss: 0.7914965152740479\n",
      "epoch: 381, Accuracy 0.6007162041181737, loss: 0.8617605566978455\n",
      "epoch: 382, Accuracy 0.6051924798567592, loss: 0.7199132442474365\n",
      "epoch: 383, Accuracy 0.5819158460161146, loss: 0.6861178874969482\n",
      "epoch: 384, Accuracy 0.594449418084154, loss: 0.8380186557769775\n",
      "epoch: 385, Accuracy 0.5801253357206804, loss: 1.122059941291809\n",
      "epoch: 386, Accuracy 0.5953446732318711, loss: 1.409204125404358\n",
      "epoch: 387, Accuracy 0.5998209489704566, loss: 0.7360411286354065\n",
      "epoch: 388, Accuracy 0.5890778871978514, loss: 1.0075209140777588\n",
      "epoch: 389, Accuracy 0.5711727842435094, loss: 0.6477384567260742\n",
      "epoch: 390, Accuracy 0.6060877350044763, loss: 0.5259513854980469\n",
      "epoch: 391, Accuracy 0.6007162041181737, loss: 0.7852841019630432\n",
      "epoch: 392, Accuracy 0.5989256938227395, loss: 1.2768059968948364\n",
      "epoch: 393, Accuracy 0.594449418084154, loss: 0.7998392581939697\n",
      "epoch: 394, Accuracy 0.5998209489704566, loss: 0.7736579775810242\n",
      "epoch: 395, Accuracy 0.5962399283795882, loss: 1.165870189666748\n",
      "epoch: 396, Accuracy 0.6060877350044763, loss: 0.8805153965950012\n",
      "epoch: 397, Accuracy 0.5989256938227395, loss: 0.7490689158439636\n",
      "epoch: 398, Accuracy 0.5890778871978514, loss: 0.7558379173278809\n",
      "epoch: 399, Accuracy 0.6096687555953447, loss: 0.6711889505386353\n",
      "epoch: 400, Accuracy 0.5962399283795882, loss: 1.0447113513946533\n",
      "epoch: 401, Accuracy 0.5846016114592659, loss: 0.9338324666023254\n",
      "epoch: 402, Accuracy 0.5774395702775291, loss: 0.7285760045051575\n",
      "epoch: 403, Accuracy 0.5738585496866607, loss: 0.6803892254829407\n",
      "epoch: 404, Accuracy 0.5917636526410027, loss: 0.6901067495346069\n",
      "epoch: 405, Accuracy 0.6025067144136079, loss: 1.1160112619400024\n",
      "epoch: 406, Accuracy 0.5881826320501343, loss: 0.8752281665802002\n",
      "epoch: 407, Accuracy 0.5863921217547001, loss: 1.011704444885254\n",
      "epoch: 408, Accuracy 0.6007162041181737, loss: 0.8972257375717163\n",
      "epoch: 409, Accuracy 0.6159355416293644, loss: 0.8588806390762329\n",
      "epoch: 410, Accuracy 0.6132497761862131, loss: 0.9225282669067383\n",
      "epoch: 411, Accuracy 0.5971351835273053, loss: 0.9301038384437561\n",
      "epoch: 412, Accuracy 0.6007162041181737, loss: 1.0001227855682373\n",
      "epoch: 413, Accuracy 0.6087735004476276, loss: 0.6523410081863403\n",
      "epoch: 414, Accuracy 0.6078782452999105, loss: 0.8379650712013245\n",
      "epoch: 415, Accuracy 0.6096687555953447, loss: 0.8034830689430237\n",
      "epoch: 416, Accuracy 0.6087735004476276, loss: 0.7600410580635071\n",
      "epoch: 417, Accuracy 0.6078782452999105, loss: 0.7688130736351013\n",
      "epoch: 418, Accuracy 0.6159355416293644, loss: 0.843498706817627\n",
      "epoch: 419, Accuracy 0.6114592658907789, loss: 0.7381188273429871\n",
      "epoch: 420, Accuracy 0.6078782452999105, loss: 0.6566708087921143\n",
      "epoch: 421, Accuracy 0.6150402864816473, loss: 0.8359156847000122\n",
      "epoch: 422, Accuracy 0.6105640107430618, loss: 1.0658708810806274\n",
      "epoch: 423, Accuracy 0.5926589077887198, loss: 1.0630592107772827\n",
      "epoch: 424, Accuracy 0.5917636526410027, loss: 1.098253607749939\n",
      "epoch: 425, Accuracy 0.594449418084154, loss: 0.9138103723526001\n",
      "epoch: 426, Accuracy 0.5792300805729633, loss: 1.011512279510498\n",
      "epoch: 427, Accuracy 0.6051924798567592, loss: 1.0200978517532349\n",
      "epoch: 428, Accuracy 0.5863921217547001, loss: 1.0533937215805054\n",
      "epoch: 429, Accuracy 0.5837063563115488, loss: 0.6617754101753235\n",
      "epoch: 430, Accuracy 0.6132497761862131, loss: 1.1809877157211304\n",
      "epoch: 431, Accuracy 0.6087735004476276, loss: 0.7942807078361511\n",
      "epoch: 432, Accuracy 0.5980304386750224, loss: 0.9760202765464783\n",
      "epoch: 433, Accuracy 0.603401969561325, loss: 0.7809014320373535\n",
      "epoch: 434, Accuracy 0.5962399283795882, loss: 1.0537220239639282\n",
      "epoch: 435, Accuracy 0.5917636526410027, loss: 0.6185221076011658\n",
      "epoch: 436, Accuracy 0.6168307967770814, loss: 0.9556634426116943\n",
      "epoch: 437, Accuracy 0.6168307967770814, loss: 0.9827456474304199\n",
      "epoch: 438, Accuracy 0.6042972247090421, loss: 1.1868656873703003\n",
      "epoch: 439, Accuracy 0.6007162041181737, loss: 0.6995940208435059\n",
      "epoch: 440, Accuracy 0.6042972247090421, loss: 0.9367669224739075\n",
      "epoch: 441, Accuracy 0.5998209489704566, loss: 0.8848967552185059\n",
      "epoch: 442, Accuracy 0.621307072515667, loss: 0.8491427898406982\n",
      "epoch: 443, Accuracy 0.6007162041181737, loss: 0.9830939173698425\n",
      "epoch: 444, Accuracy 0.5935541629364369, loss: 0.8978091478347778\n",
      "epoch: 445, Accuracy 0.5908683974932856, loss: 1.0747497081756592\n",
      "epoch: 446, Accuracy 0.5971351835273053, loss: 0.9848285913467407\n",
      "epoch: 447, Accuracy 0.6257833482542524, loss: 0.6571717858314514\n",
      "epoch: 448, Accuracy 0.5890778871978514, loss: 0.8542325496673584\n",
      "epoch: 449, Accuracy 0.5783348254252462, loss: 0.7517920136451721\n",
      "epoch: 450, Accuracy 0.5863921217547001, loss: 0.6516563296318054\n",
      "epoch: 451, Accuracy 0.6105640107430618, loss: 0.9077531099319458\n",
      "epoch: 452, Accuracy 0.5872873769024172, loss: 0.9755319952964783\n",
      "epoch: 453, Accuracy 0.6025067144136079, loss: 1.050552248954773\n",
      "epoch: 454, Accuracy 0.5953446732318711, loss: 1.0257444381713867\n",
      "epoch: 455, Accuracy 0.594449418084154, loss: 0.6854727864265442\n",
      "epoch: 456, Accuracy 0.6060877350044763, loss: 0.8517268300056458\n",
      "epoch: 457, Accuracy 0.603401969561325, loss: 0.7682023048400879\n",
      "epoch: 458, Accuracy 0.6087735004476276, loss: 0.9727588891983032\n",
      "epoch: 459, Accuracy 0.5989256938227395, loss: 0.8779987096786499\n",
      "epoch: 460, Accuracy 0.6204118173679498, loss: 1.1164230108261108\n",
      "epoch: 461, Accuracy 0.603401969561325, loss: 0.665825366973877\n",
      "epoch: 462, Accuracy 0.5989256938227395, loss: 0.9443708062171936\n",
      "epoch: 463, Accuracy 0.5935541629364369, loss: 1.3682160377502441\n",
      "epoch: 464, Accuracy 0.6016114592658908, loss: 0.9669663906097412\n",
      "epoch: 465, Accuracy 0.6042972247090421, loss: 1.141000509262085\n",
      "epoch: 466, Accuracy 0.5917636526410027, loss: 0.7540382146835327\n",
      "epoch: 467, Accuracy 0.5908683974932856, loss: 1.0235410928726196\n",
      "epoch: 468, Accuracy 0.5828111011638317, loss: 1.0718806982040405\n",
      "epoch: 469, Accuracy 0.6096687555953447, loss: 1.1983281373977661\n",
      "epoch: 470, Accuracy 0.5953446732318711, loss: 0.7177830338478088\n",
      "epoch: 471, Accuracy 0.5980304386750224, loss: 1.1351667642593384\n",
      "epoch: 472, Accuracy 0.603401969561325, loss: 0.842578113079071\n",
      "epoch: 473, Accuracy 0.5908683974932856, loss: 0.6713921427726746\n",
      "epoch: 474, Accuracy 0.612354521038496, loss: 0.8654923439025879\n",
      "epoch: 475, Accuracy 0.6078782452999105, loss: 0.872873067855835\n",
      "epoch: 476, Accuracy 0.6159355416293644, loss: 0.7869513630867004\n",
      "epoch: 477, Accuracy 0.6069829901521934, loss: 1.0975561141967773\n",
      "epoch: 478, Accuracy 0.6293643688451208, loss: 0.9284074902534485\n",
      "epoch: 479, Accuracy 0.6266786034019696, loss: 0.9209290742874146\n",
      "epoch: 480, Accuracy 0.6338406445837064, loss: 0.76658034324646\n",
      "epoch: 481, Accuracy 0.6293643688451208, loss: 1.017411231994629\n",
      "epoch: 482, Accuracy 0.5908683974932856, loss: 0.6766818761825562\n",
      "epoch: 483, Accuracy 0.6078782452999105, loss: 0.6663774251937866\n",
      "epoch: 484, Accuracy 0.6060877350044763, loss: 0.7134609818458557\n",
      "epoch: 485, Accuracy 0.6266786034019696, loss: 0.7755880355834961\n",
      "epoch: 486, Accuracy 0.6141450313339302, loss: 0.6578117609024048\n",
      "epoch: 487, Accuracy 0.5881826320501343, loss: 0.9103966355323792\n",
      "epoch: 488, Accuracy 0.6177260519247986, loss: 1.1456345319747925\n",
      "epoch: 489, Accuracy 0.5810205908683975, loss: 1.371848702430725\n",
      "epoch: 490, Accuracy 0.5666965085049239, loss: 0.732468843460083\n",
      "epoch: 491, Accuracy 0.6051924798567592, loss: 1.1824190616607666\n",
      "epoch: 492, Accuracy 0.6168307967770814, loss: 1.0214581489562988\n",
      "epoch: 493, Accuracy 0.5872873769024172, loss: 0.7985234260559082\n",
      "epoch: 494, Accuracy 0.6114592658907789, loss: 0.8179156184196472\n",
      "epoch: 495, Accuracy 0.6239928379588182, loss: 0.7870238423347473\n",
      "epoch: 496, Accuracy 0.6177260519247986, loss: 0.7195048332214355\n",
      "epoch: 497, Accuracy 0.603401969561325, loss: 0.9313605427742004\n",
      "epoch: 498, Accuracy 0.6141450313339302, loss: 0.808506429195404\n",
      "epoch: 499, Accuracy 0.6025067144136079, loss: 0.8804017901420593\n",
      "attention results on User 1\n",
      "train_acc: 61.145926589077895\tsample_size: 1117\n",
      "test_acc: 67.5\tsample_size: 280\n",
      "\n",
      "epoch: 0, Accuracy 0.35899731423455683, loss: 1.4307739734649658\n",
      "epoch: 1, Accuracy 0.4583706356311549, loss: 1.4575186967849731\n",
      "epoch: 2, Accuracy 0.4834377797672337, loss: 1.454053521156311\n",
      "epoch: 3, Accuracy 0.5076096687555953, loss: 1.1576043367385864\n",
      "epoch: 4, Accuracy 0.5255147717099373, loss: 1.2861123085021973\n",
      "epoch: 5, Accuracy 0.5138764547896151, loss: 1.0082546472549438\n",
      "epoch: 6, Accuracy 0.5344673231871083, loss: 1.1350038051605225\n",
      "epoch: 7, Accuracy 0.5058191584601611, loss: 1.2204798460006714\n",
      "epoch: 8, Accuracy 0.5317815577439571, loss: 1.094152808189392\n",
      "epoch: 9, Accuracy 0.5326768128916741, loss: 1.379542350769043\n",
      "epoch: 10, Accuracy 0.5219337511190689, loss: 1.08175790309906\n",
      "epoch: 11, Accuracy 0.5282005371530887, loss: 1.0465680360794067\n",
      "epoch: 12, Accuracy 0.5335720680393913, loss: 1.0594635009765625\n",
      "epoch: 13, Accuracy 0.5353625783348255, loss: 1.237099051475525\n",
      "epoch: 14, Accuracy 0.5461056401074306, loss: 1.106777310371399\n",
      "epoch: 15, Accuracy 0.5470008952551477, loss: 0.9760909080505371\n",
      "epoch: 16, Accuracy 0.5290957923008057, loss: 1.0136245489120483\n",
      "epoch: 17, Accuracy 0.5425246195165622, loss: 1.0217540264129639\n",
      "epoch: 18, Accuracy 0.540734109221128, loss: 1.2237797975540161\n",
      "epoch: 19, Accuracy 0.5532676812891674, loss: 0.8763749599456787\n",
      "epoch: 20, Accuracy 0.5461056401074306, loss: 0.7574363946914673\n",
      "epoch: 21, Accuracy 0.5613249776186213, loss: 1.0641013383865356\n",
      "epoch: 22, Accuracy 0.5434198746642793, loss: 1.2390211820602417\n",
      "epoch: 23, Accuracy 0.5595344673231871, loss: 1.1726272106170654\n",
      "epoch: 24, Accuracy 0.5577439570277529, loss: 0.7711356282234192\n",
      "epoch: 25, Accuracy 0.5604297224709042, loss: 0.9607357978820801\n",
      "epoch: 26, Accuracy 0.6060877350044763, loss: 1.0181958675384521\n",
      "epoch: 27, Accuracy 0.585496866606983, loss: 0.9238715171813965\n",
      "epoch: 28, Accuracy 0.5738585496866607, loss: 0.7098658680915833\n",
      "epoch: 29, Accuracy 0.6007162041181737, loss: 1.235678791999817\n",
      "epoch: 30, Accuracy 0.6087735004476276, loss: 1.068622350692749\n",
      "epoch: 31, Accuracy 0.5917636526410027, loss: 1.0188844203948975\n",
      "epoch: 32, Accuracy 0.6177260519247986, loss: 1.0096842050552368\n",
      "epoch: 33, Accuracy 0.6204118173679498, loss: 0.8525475859642029\n",
      "epoch: 34, Accuracy 0.6042972247090421, loss: 1.1129710674285889\n",
      "epoch: 35, Accuracy 0.6275738585496866, loss: 0.7405213117599487\n",
      "epoch: 36, Accuracy 0.6248880931065354, loss: 0.7911641597747803\n",
      "epoch: 37, Accuracy 0.6141450313339302, loss: 1.2446832656860352\n",
      "epoch: 38, Accuracy 0.6078782452999105, loss: 0.6826344728469849\n",
      "epoch: 39, Accuracy 0.6159355416293644, loss: 0.635734498500824\n",
      "epoch: 40, Accuracy 0.6168307967770814, loss: 1.2560185194015503\n",
      "epoch: 41, Accuracy 0.6293643688451208, loss: 1.195189118385315\n",
      "epoch: 42, Accuracy 0.6195165622202328, loss: 0.8652082085609436\n",
      "epoch: 43, Accuracy 0.6186213070725156, loss: 1.0486676692962646\n",
      "epoch: 44, Accuracy 0.6177260519247986, loss: 1.375122308731079\n",
      "epoch: 45, Accuracy 0.631154879140555, loss: 1.2473440170288086\n",
      "epoch: 46, Accuracy 0.6410026857654432, loss: 1.0381035804748535\n",
      "epoch: 47, Accuracy 0.6248880931065354, loss: 0.9824513792991638\n",
      "epoch: 48, Accuracy 0.621307072515667, loss: 0.7222506999969482\n",
      "epoch: 49, Accuracy 0.6445837063563116, loss: 0.8493125438690186\n",
      "epoch: 50, Accuracy 0.6374216651745748, loss: 0.6780880093574524\n",
      "epoch: 51, Accuracy 0.6248880931065354, loss: 0.7961164116859436\n",
      "epoch: 52, Accuracy 0.6114592658907789, loss: 1.000619649887085\n",
      "epoch: 53, Accuracy 0.6239928379588182, loss: 1.0739554166793823\n",
      "epoch: 54, Accuracy 0.6275738585496866, loss: 0.9519963264465332\n",
      "epoch: 55, Accuracy 0.6338406445837064, loss: 0.9409275650978088\n",
      "epoch: 56, Accuracy 0.6320501342882722, loss: 0.5851008892059326\n",
      "epoch: 57, Accuracy 0.621307072515667, loss: 0.6088443994522095\n",
      "epoch: 58, Accuracy 0.6374216651745748, loss: 0.8054232597351074\n",
      "epoch: 59, Accuracy 0.6436884512085944, loss: 0.9433760643005371\n",
      "epoch: 60, Accuracy 0.6544315129811996, loss: 1.32596755027771\n",
      "epoch: 61, Accuracy 0.6356311548791406, loss: 0.5818471312522888\n",
      "epoch: 62, Accuracy 0.6454789615040286, loss: 1.0760462284088135\n",
      "epoch: 63, Accuracy 0.6186213070725156, loss: 1.4245296716690063\n",
      "epoch: 64, Accuracy 0.6195165622202328, loss: 0.975265383720398\n",
      "epoch: 65, Accuracy 0.6177260519247986, loss: 0.844774067401886\n",
      "epoch: 66, Accuracy 0.6204118173679498, loss: 0.7154936194419861\n",
      "epoch: 67, Accuracy 0.621307072515667, loss: 0.8263293504714966\n",
      "epoch: 68, Accuracy 0.6356311548791406, loss: 0.8645896911621094\n",
      "epoch: 69, Accuracy 0.6329453894359892, loss: 0.642508327960968\n",
      "epoch: 70, Accuracy 0.6239928379588182, loss: 1.3410781621932983\n",
      "epoch: 71, Accuracy 0.6177260519247986, loss: 0.7540202140808105\n",
      "epoch: 72, Accuracy 0.6436884512085944, loss: 0.8130112886428833\n",
      "epoch: 73, Accuracy 0.6293643688451208, loss: 0.9066052436828613\n",
      "epoch: 74, Accuracy 0.6454789615040286, loss: 0.6786055564880371\n",
      "epoch: 75, Accuracy 0.6338406445837064, loss: 0.8869391679763794\n",
      "epoch: 76, Accuracy 0.6418979409131602, loss: 0.84685218334198\n",
      "epoch: 77, Accuracy 0.640107430617726, loss: 0.8955740332603455\n",
      "epoch: 78, Accuracy 0.622202327663384, loss: 1.078445553779602\n",
      "epoch: 79, Accuracy 0.640107430617726, loss: 0.7308211326599121\n",
      "epoch: 80, Accuracy 0.640107430617726, loss: 0.7469692826271057\n",
      "epoch: 81, Accuracy 0.6338406445837064, loss: 0.8745355010032654\n",
      "epoch: 82, Accuracy 0.6383169203222918, loss: 0.7798413634300232\n",
      "epoch: 83, Accuracy 0.6284691136974038, loss: 0.6743065714836121\n",
      "epoch: 84, Accuracy 0.649059982094897, loss: 0.7939577698707581\n",
      "epoch: 85, Accuracy 0.6410026857654432, loss: 0.6687120795249939\n",
      "epoch: 86, Accuracy 0.6472694717994628, loss: 0.4190613925457001\n",
      "epoch: 87, Accuracy 0.6427931960608774, loss: 0.7534856796264648\n",
      "epoch: 88, Accuracy 0.6329453894359892, loss: 0.6669549942016602\n",
      "epoch: 89, Accuracy 0.6383169203222918, loss: 0.6598294377326965\n",
      "epoch: 90, Accuracy 0.6383169203222918, loss: 0.6180803775787354\n",
      "epoch: 91, Accuracy 0.6248880931065354, loss: 0.8555098176002502\n",
      "epoch: 92, Accuracy 0.6410026857654432, loss: 0.8072481155395508\n",
      "epoch: 93, Accuracy 0.6436884512085944, loss: 0.9446691870689392\n",
      "epoch: 94, Accuracy 0.622202327663384, loss: 1.0838518142700195\n",
      "epoch: 95, Accuracy 0.6427931960608774, loss: 0.7857586145401001\n",
      "epoch: 96, Accuracy 0.6445837063563116, loss: 0.97395920753479\n",
      "epoch: 97, Accuracy 0.6356311548791406, loss: 1.0500537157058716\n",
      "epoch: 98, Accuracy 0.6347358997314234, loss: 0.9010004997253418\n",
      "epoch: 99, Accuracy 0.6463742166517458, loss: 0.6186137795448303\n",
      "epoch: 100, Accuracy 0.6418979409131602, loss: 1.1096330881118774\n",
      "epoch: 101, Accuracy 0.657117278424351, loss: 0.7846724987030029\n",
      "epoch: 102, Accuracy 0.6383169203222918, loss: 0.9355900287628174\n",
      "epoch: 103, Accuracy 0.640107430617726, loss: 0.5621901154518127\n",
      "epoch: 104, Accuracy 0.6499552372426142, loss: 0.5179967284202576\n",
      "epoch: 105, Accuracy 0.6427931960608774, loss: 0.7133536338806152\n",
      "epoch: 106, Accuracy 0.6463742166517458, loss: 0.7517771124839783\n",
      "epoch: 107, Accuracy 0.649059982094897, loss: 0.667436420917511\n",
      "epoch: 108, Accuracy 0.6320501342882722, loss: 0.8969130516052246\n",
      "epoch: 109, Accuracy 0.64816472694718, loss: 0.7928112149238586\n",
      "epoch: 110, Accuracy 0.6436884512085944, loss: 0.36382296681404114\n",
      "epoch: 111, Accuracy 0.6374216651745748, loss: 0.8437005281448364\n",
      "epoch: 112, Accuracy 0.6598030438675022, loss: 0.6087956428527832\n",
      "epoch: 113, Accuracy 0.639212175470009, loss: 0.6144051551818848\n",
      "epoch: 114, Accuracy 0.649059982094897, loss: 1.0133880376815796\n",
      "epoch: 115, Accuracy 0.6410026857654432, loss: 0.9140738248825073\n",
      "epoch: 116, Accuracy 0.6508504923903312, loss: 0.8943323493003845\n",
      "epoch: 117, Accuracy 0.6356311548791406, loss: 0.7356804013252258\n",
      "epoch: 118, Accuracy 0.6535362578334826, loss: 0.5178488492965698\n",
      "epoch: 119, Accuracy 0.6454789615040286, loss: 0.5438233613967896\n",
      "epoch: 120, Accuracy 0.6293643688451208, loss: 0.8845361471176147\n",
      "epoch: 121, Accuracy 0.6436884512085944, loss: 0.6698412299156189\n",
      "epoch: 122, Accuracy 0.6499552372426142, loss: 0.8213754296302795\n",
      "epoch: 123, Accuracy 0.6320501342882722, loss: 0.7893890142440796\n",
      "epoch: 124, Accuracy 0.6472694717994628, loss: 0.6272018551826477\n",
      "epoch: 125, Accuracy 0.6329453894359892, loss: 0.8479883670806885\n",
      "epoch: 126, Accuracy 0.6320501342882722, loss: 0.7807605862617493\n",
      "epoch: 127, Accuracy 0.6463742166517458, loss: 0.8795403242111206\n",
      "epoch: 128, Accuracy 0.6275738585496866, loss: 1.0476927757263184\n",
      "epoch: 129, Accuracy 0.6383169203222918, loss: 0.8966860175132751\n",
      "epoch: 130, Accuracy 0.6454789615040286, loss: 0.8851402401924133\n",
      "epoch: 131, Accuracy 0.6508504923903312, loss: 1.0205421447753906\n",
      "epoch: 132, Accuracy 0.6410026857654432, loss: 0.941454291343689\n",
      "epoch: 133, Accuracy 0.6517457475380484, loss: 0.5920495390892029\n",
      "epoch: 134, Accuracy 0.649059982094897, loss: 0.7408259510993958\n",
      "epoch: 135, Accuracy 0.64816472694718, loss: 0.9675998687744141\n",
      "epoch: 136, Accuracy 0.639212175470009, loss: 0.8925360441207886\n",
      "epoch: 137, Accuracy 0.6374216651745748, loss: 0.6612641215324402\n",
      "epoch: 138, Accuracy 0.6517457475380484, loss: 1.0121058225631714\n",
      "epoch: 139, Accuracy 0.64816472694718, loss: 0.8765419125556946\n",
      "epoch: 140, Accuracy 0.6275738585496866, loss: 0.7031685709953308\n",
      "epoch: 141, Accuracy 0.6347358997314234, loss: 0.548687219619751\n",
      "epoch: 142, Accuracy 0.6454789615040286, loss: 0.8417012095451355\n",
      "epoch: 143, Accuracy 0.6427931960608774, loss: 0.7185516357421875\n",
      "epoch: 144, Accuracy 0.64816472694718, loss: 0.7535181641578674\n",
      "epoch: 145, Accuracy 0.6454789615040286, loss: 0.6416715383529663\n",
      "epoch: 146, Accuracy 0.6365264100268576, loss: 0.9052295684814453\n",
      "epoch: 147, Accuracy 0.6463742166517458, loss: 0.8542639017105103\n",
      "epoch: 148, Accuracy 0.6472694717994628, loss: 1.7070581912994385\n",
      "epoch: 149, Accuracy 0.6383169203222918, loss: 0.8715248703956604\n",
      "epoch: 150, Accuracy 0.621307072515667, loss: 0.891282856464386\n",
      "epoch: 151, Accuracy 0.6436884512085944, loss: 0.6945882439613342\n",
      "epoch: 152, Accuracy 0.6463742166517458, loss: 0.9205918908119202\n",
      "epoch: 153, Accuracy 0.658012533572068, loss: 0.7698240876197815\n",
      "epoch: 154, Accuracy 0.6499552372426142, loss: 0.892669141292572\n",
      "epoch: 155, Accuracy 0.6463742166517458, loss: 0.6595646739006042\n",
      "epoch: 156, Accuracy 0.6598030438675022, loss: 0.8744782209396362\n",
      "epoch: 157, Accuracy 0.6418979409131602, loss: 0.5681685209274292\n",
      "epoch: 158, Accuracy 0.6436884512085944, loss: 0.5993931889533997\n",
      "epoch: 159, Accuracy 0.6499552372426142, loss: 0.7608345150947571\n",
      "epoch: 160, Accuracy 0.621307072515667, loss: 0.9041798114776611\n",
      "epoch: 161, Accuracy 0.6463742166517458, loss: 1.048728346824646\n",
      "epoch: 162, Accuracy 0.6418979409131602, loss: 0.5603799223899841\n",
      "epoch: 163, Accuracy 0.6624888093106536, loss: 1.052469253540039\n",
      "epoch: 164, Accuracy 0.6499552372426142, loss: 1.1011074781417847\n",
      "epoch: 165, Accuracy 0.6553267681289168, loss: 0.9113972187042236\n",
      "epoch: 166, Accuracy 0.6544315129811996, loss: 0.6486415863037109\n",
      "epoch: 167, Accuracy 0.639212175470009, loss: 0.5854594707489014\n",
      "epoch: 168, Accuracy 0.6374216651745748, loss: 1.0039118528366089\n",
      "epoch: 169, Accuracy 0.640107430617726, loss: 0.7327197194099426\n",
      "epoch: 170, Accuracy 0.6410026857654432, loss: 0.46702489256858826\n",
      "epoch: 171, Accuracy 0.6454789615040286, loss: 0.9795033931732178\n",
      "epoch: 172, Accuracy 0.639212175470009, loss: 1.3394098281860352\n",
      "epoch: 173, Accuracy 0.6436884512085944, loss: 0.8818327784538269\n",
      "epoch: 174, Accuracy 0.6544315129811996, loss: 0.6546712517738342\n",
      "epoch: 175, Accuracy 0.658012533572068, loss: 0.7379323244094849\n",
      "epoch: 176, Accuracy 0.6472694717994628, loss: 0.6772788166999817\n",
      "epoch: 177, Accuracy 0.6418979409131602, loss: 0.8855542540550232\n",
      "epoch: 178, Accuracy 0.6356311548791406, loss: 0.9324489831924438\n",
      "epoch: 179, Accuracy 0.6436884512085944, loss: 0.7934152483940125\n",
      "epoch: 180, Accuracy 0.6589077887197852, loss: 0.6841531991958618\n",
      "epoch: 181, Accuracy 0.6356311548791406, loss: 1.0505822896957397\n",
      "epoch: 182, Accuracy 0.6598030438675022, loss: 0.9033887386322021\n",
      "epoch: 183, Accuracy 0.6678603401969562, loss: 0.9312063455581665\n",
      "epoch: 184, Accuracy 0.6383169203222918, loss: 0.8461636900901794\n",
      "epoch: 185, Accuracy 0.6436884512085944, loss: 0.833314061164856\n",
      "epoch: 186, Accuracy 0.6562220232766338, loss: 0.7540570497512817\n",
      "epoch: 187, Accuracy 0.666965085049239, loss: 0.6961431503295898\n",
      "epoch: 188, Accuracy 0.6454789615040286, loss: 0.733192503452301\n",
      "epoch: 189, Accuracy 0.6526410026857654, loss: 0.9703835844993591\n",
      "epoch: 190, Accuracy 0.6356311548791406, loss: 0.9490156769752502\n",
      "epoch: 191, Accuracy 0.6383169203222918, loss: 0.684063732624054\n",
      "epoch: 192, Accuracy 0.6517457475380484, loss: 0.7791954278945923\n",
      "epoch: 193, Accuracy 0.6553267681289168, loss: 0.7443451881408691\n",
      "epoch: 194, Accuracy 0.6606982990152194, loss: 0.6610798835754395\n",
      "epoch: 195, Accuracy 0.6517457475380484, loss: 0.7367429733276367\n",
      "epoch: 196, Accuracy 0.6248880931065354, loss: 0.7936317324638367\n",
      "epoch: 197, Accuracy 0.6356311548791406, loss: 1.1558582782745361\n",
      "epoch: 198, Accuracy 0.6499552372426142, loss: 0.7387812733650208\n",
      "epoch: 199, Accuracy 0.6562220232766338, loss: 0.7154309153556824\n",
      "epoch: 200, Accuracy 0.6454789615040286, loss: 0.6518165469169617\n",
      "epoch: 201, Accuracy 0.6589077887197852, loss: 0.5228073000907898\n",
      "epoch: 202, Accuracy 0.6463742166517458, loss: 0.9241280555725098\n",
      "epoch: 203, Accuracy 0.6526410026857654, loss: 0.6011519432067871\n",
      "epoch: 204, Accuracy 0.6418979409131602, loss: 0.6778082847595215\n",
      "epoch: 205, Accuracy 0.639212175470009, loss: 0.8111146688461304\n",
      "epoch: 206, Accuracy 0.6427931960608774, loss: 0.7951446175575256\n",
      "epoch: 207, Accuracy 0.6383169203222918, loss: 0.5968576669692993\n",
      "epoch: 208, Accuracy 0.6517457475380484, loss: 0.735811710357666\n",
      "epoch: 209, Accuracy 0.64816472694718, loss: 0.5353171825408936\n",
      "epoch: 210, Accuracy 0.6463742166517458, loss: 0.6729292869567871\n",
      "epoch: 211, Accuracy 0.6589077887197852, loss: 0.7918795347213745\n",
      "epoch: 212, Accuracy 0.6410026857654432, loss: 0.9699311852455139\n",
      "epoch: 213, Accuracy 0.6454789615040286, loss: 0.5628743171691895\n",
      "epoch: 214, Accuracy 0.6472694717994628, loss: 0.42325472831726074\n",
      "epoch: 215, Accuracy 0.6472694717994628, loss: 0.905295193195343\n",
      "epoch: 216, Accuracy 0.6535362578334826, loss: 0.8190190196037292\n",
      "epoch: 217, Accuracy 0.6410026857654432, loss: 0.7430703639984131\n",
      "epoch: 218, Accuracy 0.640107430617726, loss: 0.9265165328979492\n",
      "epoch: 219, Accuracy 0.6508504923903312, loss: 0.5856052041053772\n",
      "epoch: 220, Accuracy 0.649059982094897, loss: 0.9138951301574707\n",
      "epoch: 221, Accuracy 0.658012533572068, loss: 1.1169395446777344\n",
      "epoch: 222, Accuracy 0.6445837063563116, loss: 0.5679457187652588\n",
      "epoch: 223, Accuracy 0.6374216651745748, loss: 0.835016667842865\n",
      "epoch: 224, Accuracy 0.6436884512085944, loss: 0.9504721164703369\n",
      "epoch: 225, Accuracy 0.64816472694718, loss: 0.9007524847984314\n",
      "epoch: 226, Accuracy 0.6598030438675022, loss: 0.7229553461074829\n",
      "epoch: 227, Accuracy 0.6562220232766338, loss: 0.8256678581237793\n",
      "epoch: 228, Accuracy 0.658012533572068, loss: 0.7402691841125488\n",
      "epoch: 229, Accuracy 0.657117278424351, loss: 0.6924499273300171\n",
      "epoch: 230, Accuracy 0.6535362578334826, loss: 0.7208937406539917\n",
      "epoch: 231, Accuracy 0.6642793196060878, loss: 0.935115396976471\n",
      "epoch: 232, Accuracy 0.64816472694718, loss: 0.7601754069328308\n",
      "epoch: 233, Accuracy 0.6517457475380484, loss: 0.6462901830673218\n",
      "epoch: 234, Accuracy 0.6633840644583706, loss: 0.8830716013908386\n",
      "epoch: 235, Accuracy 0.6526410026857654, loss: 0.66694176197052\n",
      "epoch: 236, Accuracy 0.6436884512085944, loss: 0.9125515222549438\n",
      "epoch: 237, Accuracy 0.6553267681289168, loss: 0.5752557516098022\n",
      "epoch: 238, Accuracy 0.6517457475380484, loss: 0.8987919688224792\n",
      "epoch: 239, Accuracy 0.6615935541629364, loss: 1.001945972442627\n",
      "epoch: 240, Accuracy 0.649059982094897, loss: 0.9250397682189941\n",
      "epoch: 241, Accuracy 0.6418979409131602, loss: 1.0366663932800293\n",
      "epoch: 242, Accuracy 0.6526410026857654, loss: 0.6137071847915649\n",
      "epoch: 243, Accuracy 0.6374216651745748, loss: 0.5207211971282959\n",
      "epoch: 244, Accuracy 0.6562220232766338, loss: 0.6957194209098816\n",
      "epoch: 245, Accuracy 0.657117278424351, loss: 0.632918119430542\n",
      "epoch: 246, Accuracy 0.649059982094897, loss: 0.6230748295783997\n",
      "epoch: 247, Accuracy 0.6615935541629364, loss: 0.8079816102981567\n",
      "epoch: 248, Accuracy 0.64816472694718, loss: 0.8950449824333191\n",
      "epoch: 249, Accuracy 0.6410026857654432, loss: 0.6620832085609436\n",
      "epoch: 250, Accuracy 0.6589077887197852, loss: 0.8572034239768982\n",
      "epoch: 251, Accuracy 0.6266786034019696, loss: 0.7015183568000793\n",
      "epoch: 252, Accuracy 0.6589077887197852, loss: 0.8504641652107239\n",
      "epoch: 253, Accuracy 0.6678603401969562, loss: 0.9218862056732178\n",
      "epoch: 254, Accuracy 0.64816472694718, loss: 1.4443382024765015\n",
      "epoch: 255, Accuracy 0.6248880931065354, loss: 0.645753026008606\n",
      "epoch: 256, Accuracy 0.6248880931065354, loss: 1.3820338249206543\n",
      "epoch: 257, Accuracy 0.6651745747538048, loss: 0.8097974061965942\n",
      "epoch: 258, Accuracy 0.6338406445837064, loss: 0.7195155024528503\n",
      "epoch: 259, Accuracy 0.6589077887197852, loss: 1.1749489307403564\n",
      "epoch: 260, Accuracy 0.6633840644583706, loss: 0.8010205030441284\n",
      "epoch: 261, Accuracy 0.6517457475380484, loss: 0.9627499580383301\n",
      "epoch: 262, Accuracy 0.649059982094897, loss: 0.8276427984237671\n",
      "epoch: 263, Accuracy 0.6239928379588182, loss: 0.6912181377410889\n",
      "epoch: 264, Accuracy 0.6248880931065354, loss: 0.7282330989837646\n",
      "epoch: 265, Accuracy 0.6535362578334826, loss: 1.1607322692871094\n",
      "epoch: 266, Accuracy 0.6454789615040286, loss: 0.7163845300674438\n",
      "epoch: 267, Accuracy 0.640107430617726, loss: 0.6402401328086853\n",
      "epoch: 268, Accuracy 0.649059982094897, loss: 0.692649781703949\n",
      "epoch: 269, Accuracy 0.6696508504923904, loss: 0.8724202513694763\n",
      "epoch: 270, Accuracy 0.6598030438675022, loss: 0.6669020056724548\n",
      "epoch: 271, Accuracy 0.649059982094897, loss: 1.0018281936645508\n",
      "epoch: 272, Accuracy 0.6410026857654432, loss: 0.638431966304779\n",
      "epoch: 273, Accuracy 0.6508504923903312, loss: 0.6011372804641724\n",
      "epoch: 274, Accuracy 0.6589077887197852, loss: 0.7326433658599854\n",
      "epoch: 275, Accuracy 0.6517457475380484, loss: 0.5615392327308655\n",
      "epoch: 276, Accuracy 0.6633840644583706, loss: 0.6892810463905334\n",
      "epoch: 277, Accuracy 0.639212175470009, loss: 0.6139315366744995\n",
      "epoch: 278, Accuracy 0.658012533572068, loss: 0.6625683903694153\n",
      "epoch: 279, Accuracy 0.6606982990152194, loss: 0.6894727349281311\n",
      "epoch: 280, Accuracy 0.658012533572068, loss: 0.6679392457008362\n",
      "epoch: 281, Accuracy 0.657117278424351, loss: 0.9834083318710327\n",
      "epoch: 282, Accuracy 0.67591763652641, loss: 0.5270824432373047\n",
      "epoch: 283, Accuracy 0.6615935541629364, loss: 0.7915636301040649\n",
      "epoch: 284, Accuracy 0.6517457475380484, loss: 0.7710577249526978\n",
      "epoch: 285, Accuracy 0.6642793196060878, loss: 1.115548849105835\n",
      "epoch: 286, Accuracy 0.6427931960608774, loss: 0.5265865325927734\n",
      "epoch: 287, Accuracy 0.657117278424351, loss: 0.8172707557678223\n",
      "epoch: 288, Accuracy 0.658012533572068, loss: 0.7147300243377686\n",
      "epoch: 289, Accuracy 0.6472694717994628, loss: 0.5321994423866272\n",
      "epoch: 290, Accuracy 0.6606982990152194, loss: 0.7244576811790466\n",
      "epoch: 291, Accuracy 0.6606982990152194, loss: 0.6077516078948975\n",
      "epoch: 292, Accuracy 0.6562220232766338, loss: 0.8398154377937317\n",
      "epoch: 293, Accuracy 0.6606982990152194, loss: 0.7481170296669006\n",
      "epoch: 294, Accuracy 0.6427931960608774, loss: 0.8150840997695923\n",
      "epoch: 295, Accuracy 0.6499552372426142, loss: 0.854158878326416\n",
      "epoch: 296, Accuracy 0.666965085049239, loss: 1.0946736335754395\n",
      "epoch: 297, Accuracy 0.6589077887197852, loss: 0.7578163146972656\n",
      "epoch: 298, Accuracy 0.6562220232766338, loss: 0.7175599336624146\n",
      "epoch: 299, Accuracy 0.6687555953446732, loss: 0.5923341512680054\n",
      "epoch: 300, Accuracy 0.6454789615040286, loss: 0.6447528004646301\n",
      "epoch: 301, Accuracy 0.6517457475380484, loss: 0.6251668930053711\n",
      "epoch: 302, Accuracy 0.649059982094897, loss: 0.8950291275978088\n",
      "epoch: 303, Accuracy 0.6562220232766338, loss: 0.7266172170639038\n",
      "epoch: 304, Accuracy 0.6615935541629364, loss: 1.0392450094223022\n",
      "epoch: 305, Accuracy 0.6338406445837064, loss: 0.8664312958717346\n",
      "epoch: 306, Accuracy 0.6374216651745748, loss: 1.7996915578842163\n",
      "epoch: 307, Accuracy 0.6499552372426142, loss: 0.8242039680480957\n",
      "epoch: 308, Accuracy 0.6445837063563116, loss: 0.8568987250328064\n",
      "epoch: 309, Accuracy 0.649059982094897, loss: 1.3707948923110962\n",
      "epoch: 310, Accuracy 0.6633840644583706, loss: 0.6130757331848145\n",
      "epoch: 311, Accuracy 0.6732318710832588, loss: 0.6475348472595215\n",
      "epoch: 312, Accuracy 0.6544315129811996, loss: 0.6077547073364258\n",
      "epoch: 313, Accuracy 0.640107430617726, loss: 0.9417998194694519\n",
      "epoch: 314, Accuracy 0.6535362578334826, loss: 0.589252233505249\n",
      "epoch: 315, Accuracy 0.6445837063563116, loss: 0.5923922657966614\n",
      "epoch: 316, Accuracy 0.657117278424351, loss: 0.9070145487785339\n",
      "epoch: 317, Accuracy 0.6544315129811996, loss: 0.7030667066574097\n",
      "epoch: 318, Accuracy 0.6526410026857654, loss: 0.9400840997695923\n",
      "epoch: 319, Accuracy 0.6589077887197852, loss: 0.8120176196098328\n",
      "epoch: 320, Accuracy 0.658012533572068, loss: 0.7708284854888916\n",
      "epoch: 321, Accuracy 0.6606982990152194, loss: 1.0036875009536743\n",
      "epoch: 322, Accuracy 0.6544315129811996, loss: 0.47297000885009766\n",
      "epoch: 323, Accuracy 0.649059982094897, loss: 0.55827397108078\n",
      "epoch: 324, Accuracy 0.6562220232766338, loss: 0.7472180724143982\n",
      "epoch: 325, Accuracy 0.6598030438675022, loss: 0.6603690981864929\n",
      "epoch: 326, Accuracy 0.657117278424351, loss: 0.8362945318222046\n",
      "epoch: 327, Accuracy 0.6562220232766338, loss: 0.9412287473678589\n",
      "epoch: 328, Accuracy 0.6544315129811996, loss: 0.6451749801635742\n",
      "epoch: 329, Accuracy 0.6517457475380484, loss: 0.4720597565174103\n",
      "epoch: 330, Accuracy 0.64816472694718, loss: 1.0252097845077515\n",
      "epoch: 331, Accuracy 0.6410026857654432, loss: 0.545835018157959\n",
      "epoch: 332, Accuracy 0.6329453894359892, loss: 0.8268241882324219\n",
      "epoch: 333, Accuracy 0.6499552372426142, loss: 0.6343544721603394\n",
      "epoch: 334, Accuracy 0.6535362578334826, loss: 1.3014572858810425\n",
      "epoch: 335, Accuracy 0.6248880931065354, loss: 1.0137927532196045\n",
      "epoch: 336, Accuracy 0.6517457475380484, loss: 0.7873914837837219\n",
      "epoch: 337, Accuracy 0.6624888093106536, loss: 0.7653377652168274\n",
      "epoch: 338, Accuracy 0.6508504923903312, loss: 0.827674925327301\n",
      "epoch: 339, Accuracy 0.666965085049239, loss: 0.7043856382369995\n",
      "epoch: 340, Accuracy 0.658012533572068, loss: 0.9119361639022827\n",
      "epoch: 341, Accuracy 0.6624888093106536, loss: 0.9421324133872986\n",
      "epoch: 342, Accuracy 0.6508504923903312, loss: 0.658581554889679\n",
      "epoch: 343, Accuracy 0.6410026857654432, loss: 0.6091164350509644\n",
      "epoch: 344, Accuracy 0.6463742166517458, loss: 0.607175350189209\n",
      "epoch: 345, Accuracy 0.666965085049239, loss: 0.5945833325386047\n",
      "epoch: 346, Accuracy 0.666965085049239, loss: 0.78581702709198\n",
      "epoch: 347, Accuracy 0.6651745747538048, loss: 0.7243551015853882\n",
      "epoch: 348, Accuracy 0.6463742166517458, loss: 0.6515594124794006\n",
      "epoch: 349, Accuracy 0.6687555953446732, loss: 0.8767184615135193\n",
      "epoch: 350, Accuracy 0.6472694717994628, loss: 0.5793411135673523\n",
      "epoch: 351, Accuracy 0.6562220232766338, loss: 0.8251000642776489\n",
      "epoch: 352, Accuracy 0.6633840644583706, loss: 0.5176685452461243\n",
      "epoch: 353, Accuracy 0.6463742166517458, loss: 0.8682610392570496\n",
      "epoch: 354, Accuracy 0.6526410026857654, loss: 0.6725127100944519\n",
      "epoch: 355, Accuracy 0.6794986571172784, loss: 0.9865425229072571\n",
      "epoch: 356, Accuracy 0.6651745747538048, loss: 0.6581547856330872\n",
      "epoch: 357, Accuracy 0.6499552372426142, loss: 0.5244235396385193\n",
      "epoch: 358, Accuracy 0.6651745747538048, loss: 0.46328824758529663\n",
      "epoch: 359, Accuracy 0.675022381378693, loss: 0.8638780117034912\n",
      "epoch: 360, Accuracy 0.6526410026857654, loss: 0.6303038597106934\n",
      "epoch: 361, Accuracy 0.657117278424351, loss: 0.6229759454727173\n",
      "epoch: 362, Accuracy 0.6624888093106536, loss: 0.8020885586738586\n",
      "epoch: 363, Accuracy 0.6508504923903312, loss: 0.4030502438545227\n",
      "epoch: 364, Accuracy 0.6410026857654432, loss: 0.552158772945404\n",
      "epoch: 365, Accuracy 0.6696508504923904, loss: 0.6443508267402649\n",
      "epoch: 366, Accuracy 0.6642793196060878, loss: 0.8600513339042664\n",
      "epoch: 367, Accuracy 0.6768128916741272, loss: 0.6295570135116577\n",
      "epoch: 368, Accuracy 0.6741271262309758, loss: 0.6711434721946716\n",
      "epoch: 369, Accuracy 0.6544315129811996, loss: 0.5853529572486877\n",
      "epoch: 370, Accuracy 0.6678603401969562, loss: 0.5181796550750732\n",
      "epoch: 371, Accuracy 0.67591763652641, loss: 0.7430973649024963\n",
      "epoch: 372, Accuracy 0.6696508504923904, loss: 0.5870093107223511\n",
      "epoch: 373, Accuracy 0.6651745747538048, loss: 0.6203740835189819\n",
      "epoch: 374, Accuracy 0.6624888093106536, loss: 0.8879578113555908\n",
      "epoch: 375, Accuracy 0.658012533572068, loss: 0.8838310241699219\n",
      "epoch: 376, Accuracy 0.67591763652641, loss: 0.7181992530822754\n",
      "epoch: 377, Accuracy 0.6651745747538048, loss: 0.8023033738136292\n",
      "epoch: 378, Accuracy 0.6741271262309758, loss: 0.7387270927429199\n",
      "epoch: 379, Accuracy 0.6642793196060878, loss: 0.960178017616272\n",
      "epoch: 380, Accuracy 0.6777081468218442, loss: 0.6461498737335205\n",
      "epoch: 381, Accuracy 0.6705461056401074, loss: 0.6440911293029785\n",
      "epoch: 382, Accuracy 0.6687555953446732, loss: 0.6842357516288757\n",
      "epoch: 383, Accuracy 0.6562220232766338, loss: 0.6645204424858093\n",
      "epoch: 384, Accuracy 0.6562220232766338, loss: 0.8589174747467041\n",
      "epoch: 385, Accuracy 0.6615935541629364, loss: 0.6547017693519592\n",
      "epoch: 386, Accuracy 0.6696508504923904, loss: 0.7138276100158691\n",
      "epoch: 387, Accuracy 0.6678603401969562, loss: 0.5095714330673218\n",
      "epoch: 388, Accuracy 0.6642793196060878, loss: 0.826473593711853\n",
      "epoch: 389, Accuracy 0.6714413607878246, loss: 0.5127900242805481\n",
      "epoch: 390, Accuracy 0.6633840644583706, loss: 0.6914504170417786\n",
      "epoch: 391, Accuracy 0.6687555953446732, loss: 1.1402443647384644\n",
      "epoch: 392, Accuracy 0.6624888093106536, loss: 0.6005681753158569\n",
      "epoch: 393, Accuracy 0.6723366159355416, loss: 0.5518087148666382\n",
      "epoch: 394, Accuracy 0.6678603401969562, loss: 1.6969044208526611\n",
      "epoch: 395, Accuracy 0.6544315129811996, loss: 0.6619745492935181\n",
      "epoch: 396, Accuracy 0.6642793196060878, loss: 0.695351243019104\n",
      "epoch: 397, Accuracy 0.6589077887197852, loss: 0.8495998382568359\n",
      "epoch: 398, Accuracy 0.67591763652641, loss: 0.7329375147819519\n",
      "epoch: 399, Accuracy 0.6741271262309758, loss: 1.1036646366119385\n",
      "epoch: 400, Accuracy 0.6606982990152194, loss: 1.5881586074829102\n",
      "epoch: 401, Accuracy 0.675022381378693, loss: 0.8123403191566467\n",
      "epoch: 402, Accuracy 0.6544315129811996, loss: 0.6606566309928894\n",
      "epoch: 403, Accuracy 0.6589077887197852, loss: 0.7916139364242554\n",
      "epoch: 404, Accuracy 0.6562220232766338, loss: 0.6932017803192139\n",
      "epoch: 405, Accuracy 0.6436884512085944, loss: 0.5559441447257996\n",
      "epoch: 406, Accuracy 0.658012533572068, loss: 0.6014454960823059\n",
      "epoch: 407, Accuracy 0.6598030438675022, loss: 0.886556088924408\n",
      "epoch: 408, Accuracy 0.6517457475380484, loss: 0.5713461637496948\n",
      "epoch: 409, Accuracy 0.666069829901522, loss: 0.8555853962898254\n",
      "epoch: 410, Accuracy 0.666965085049239, loss: 0.9054726958274841\n",
      "epoch: 411, Accuracy 0.6696508504923904, loss: 0.7096535563468933\n",
      "epoch: 412, Accuracy 0.6794986571172784, loss: 0.7047261595726013\n",
      "epoch: 413, Accuracy 0.6732318710832588, loss: 0.4186444580554962\n",
      "epoch: 414, Accuracy 0.6741271262309758, loss: 1.0613985061645508\n",
      "epoch: 415, Accuracy 0.666965085049239, loss: 0.7954071760177612\n",
      "epoch: 416, Accuracy 0.657117278424351, loss: 0.8196256160736084\n",
      "epoch: 417, Accuracy 0.666965085049239, loss: 0.6818804740905762\n",
      "epoch: 418, Accuracy 0.6777081468218442, loss: 0.8993659019470215\n",
      "epoch: 419, Accuracy 0.6598030438675022, loss: 0.6386876106262207\n",
      "epoch: 420, Accuracy 0.6544315129811996, loss: 0.634840190410614\n",
      "epoch: 421, Accuracy 0.6786034019695614, loss: 0.7271518707275391\n",
      "epoch: 422, Accuracy 0.675022381378693, loss: 0.5714635848999023\n",
      "epoch: 423, Accuracy 0.6553267681289168, loss: 0.5825096964836121\n",
      "epoch: 424, Accuracy 0.658012533572068, loss: 0.6151667237281799\n",
      "epoch: 425, Accuracy 0.6633840644583706, loss: 0.9335970878601074\n",
      "epoch: 426, Accuracy 0.6723366159355416, loss: 0.5972833633422852\n",
      "epoch: 427, Accuracy 0.666069829901522, loss: 1.4148656129837036\n",
      "epoch: 428, Accuracy 0.649059982094897, loss: 0.6460784673690796\n",
      "epoch: 429, Accuracy 0.6732318710832588, loss: 0.8153579831123352\n",
      "epoch: 430, Accuracy 0.658012533572068, loss: 1.0287635326385498\n",
      "epoch: 431, Accuracy 0.6786034019695614, loss: 0.38497182726860046\n",
      "epoch: 432, Accuracy 0.6642793196060878, loss: 0.7148821353912354\n",
      "epoch: 433, Accuracy 0.6589077887197852, loss: 0.9923505187034607\n",
      "epoch: 434, Accuracy 0.6651745747538048, loss: 0.842065155506134\n",
      "epoch: 435, Accuracy 0.6508504923903312, loss: 0.7994741797447205\n",
      "epoch: 436, Accuracy 0.6678603401969562, loss: 0.43118512630462646\n",
      "epoch: 437, Accuracy 0.6678603401969562, loss: 0.878634512424469\n",
      "epoch: 438, Accuracy 0.6624888093106536, loss: 0.7222477793693542\n",
      "epoch: 439, Accuracy 0.658012533572068, loss: 0.8605415225028992\n",
      "epoch: 440, Accuracy 0.6463742166517458, loss: 0.7096830010414124\n",
      "epoch: 441, Accuracy 0.6777081468218442, loss: 0.5391793251037598\n",
      "epoch: 442, Accuracy 0.6624888093106536, loss: 0.8394251465797424\n",
      "epoch: 443, Accuracy 0.666069829901522, loss: 0.7128404378890991\n",
      "epoch: 444, Accuracy 0.6687555953446732, loss: 0.6686736345291138\n",
      "epoch: 445, Accuracy 0.6723366159355416, loss: 0.7072100639343262\n",
      "epoch: 446, Accuracy 0.658012533572068, loss: 0.5476428270339966\n",
      "epoch: 447, Accuracy 0.6589077887197852, loss: 0.4149492084980011\n",
      "epoch: 448, Accuracy 0.675022381378693, loss: 0.5214679837226868\n",
      "epoch: 449, Accuracy 0.6821844225604298, loss: 0.4643761217594147\n",
      "epoch: 450, Accuracy 0.6651745747538048, loss: 0.7992699146270752\n",
      "epoch: 451, Accuracy 0.6633840644583706, loss: 0.8098529577255249\n",
      "epoch: 452, Accuracy 0.6696508504923904, loss: 0.4661529064178467\n",
      "epoch: 453, Accuracy 0.6642793196060878, loss: 0.7675700187683105\n",
      "epoch: 454, Accuracy 0.6544315129811996, loss: 0.689177930355072\n",
      "epoch: 455, Accuracy 0.6633840644583706, loss: 0.5975728034973145\n",
      "epoch: 456, Accuracy 0.6624888093106536, loss: 0.5499189496040344\n",
      "epoch: 457, Accuracy 0.6606982990152194, loss: 0.7205835580825806\n",
      "epoch: 458, Accuracy 0.6794986571172784, loss: 0.5609656572341919\n",
      "epoch: 459, Accuracy 0.6821844225604298, loss: 0.5630103349685669\n",
      "epoch: 460, Accuracy 0.6642793196060878, loss: 0.7749944925308228\n",
      "epoch: 461, Accuracy 0.666965085049239, loss: 0.5337787866592407\n",
      "epoch: 462, Accuracy 0.6821844225604298, loss: 0.5958008766174316\n",
      "epoch: 463, Accuracy 0.6723366159355416, loss: 0.7343041896820068\n",
      "epoch: 464, Accuracy 0.666069829901522, loss: 0.6774760484695435\n",
      "epoch: 465, Accuracy 0.6687555953446732, loss: 0.7772509455680847\n",
      "epoch: 466, Accuracy 0.6589077887197852, loss: 0.6836271286010742\n",
      "epoch: 467, Accuracy 0.6696508504923904, loss: 0.5450920462608337\n",
      "epoch: 468, Accuracy 0.6723366159355416, loss: 0.47809624671936035\n",
      "epoch: 469, Accuracy 0.6687555953446732, loss: 0.678132951259613\n",
      "epoch: 470, Accuracy 0.6526410026857654, loss: 0.6166260242462158\n",
      "epoch: 471, Accuracy 0.666965085049239, loss: 0.6323103904724121\n",
      "epoch: 472, Accuracy 0.6651745747538048, loss: 0.7123990654945374\n",
      "epoch: 473, Accuracy 0.6696508504923904, loss: 0.391244113445282\n",
      "epoch: 474, Accuracy 0.6884512085944494, loss: 0.6428145170211792\n",
      "epoch: 475, Accuracy 0.658012533572068, loss: 0.7496616244316101\n",
      "epoch: 476, Accuracy 0.6606982990152194, loss: 0.873028039932251\n",
      "epoch: 477, Accuracy 0.6651745747538048, loss: 0.7204412817955017\n",
      "epoch: 478, Accuracy 0.6606982990152194, loss: 0.7665108442306519\n",
      "epoch: 479, Accuracy 0.6633840644583706, loss: 0.8943440318107605\n",
      "epoch: 480, Accuracy 0.6830796777081468, loss: 0.43654125928878784\n",
      "epoch: 481, Accuracy 0.6705461056401074, loss: 0.4292565584182739\n",
      "epoch: 482, Accuracy 0.6589077887197852, loss: 0.700437068939209\n",
      "epoch: 483, Accuracy 0.6696508504923904, loss: 0.7476397156715393\n",
      "epoch: 484, Accuracy 0.6642793196060878, loss: 0.6047677993774414\n",
      "epoch: 485, Accuracy 0.666069829901522, loss: 0.6776928305625916\n",
      "epoch: 486, Accuracy 0.6651745747538048, loss: 0.9773693084716797\n",
      "epoch: 487, Accuracy 0.6642793196060878, loss: 0.8662463426589966\n",
      "epoch: 488, Accuracy 0.6410026857654432, loss: 0.6749979257583618\n",
      "epoch: 489, Accuracy 0.6741271262309758, loss: 0.4836997985839844\n",
      "epoch: 490, Accuracy 0.6517457475380484, loss: 0.8933364152908325\n",
      "epoch: 491, Accuracy 0.6714413607878246, loss: 0.9249488711357117\n",
      "epoch: 492, Accuracy 0.6705461056401074, loss: 0.5433021187782288\n",
      "epoch: 493, Accuracy 0.6598030438675022, loss: 0.5021109580993652\n",
      "epoch: 494, Accuracy 0.6956132497761862, loss: 0.8086715936660767\n",
      "epoch: 495, Accuracy 0.683974932855864, loss: 0.7384966611862183\n",
      "epoch: 496, Accuracy 0.67591763652641, loss: 0.6688442826271057\n",
      "epoch: 497, Accuracy 0.6687555953446732, loss: 0.8660240173339844\n",
      "epoch: 498, Accuracy 0.6553267681289168, loss: 0.7948205471038818\n",
      "epoch: 499, Accuracy 0.6857654431512982, loss: 0.6622539162635803\n",
      "interest results on User 1\n",
      "train_acc: 67.94986571172784\tsample_size: 1117\n",
      "test_acc: 65.0\tsample_size: 280\n",
      "\n",
      "epoch: 0, Accuracy 0.20322291853178157, loss: 1.4722168445587158\n",
      "epoch: 1, Accuracy 0.3294538943598926, loss: 1.3888680934906006\n",
      "epoch: 2, Accuracy 0.41181736794986573, loss: 1.4881170988082886\n",
      "epoch: 3, Accuracy 0.4341987466427932, loss: 1.3773272037506104\n",
      "epoch: 4, Accuracy 0.4315129811996419, loss: 1.2641311883926392\n",
      "epoch: 5, Accuracy 0.4547896150402865, loss: 1.25644052028656\n",
      "epoch: 6, Accuracy 0.4780662488809311, loss: 0.9979062080383301\n",
      "epoch: 7, Accuracy 0.4905998209489705, loss: 1.0019028186798096\n",
      "epoch: 8, Accuracy 0.4825425246195166, loss: 1.127213478088379\n",
      "epoch: 9, Accuracy 0.4959713518352731, loss: 1.035457730293274\n",
      "epoch: 10, Accuracy 0.4905998209489705, loss: 1.13072669506073\n",
      "epoch: 11, Accuracy 0.4977618621307073, loss: 1.0910999774932861\n",
      "epoch: 12, Accuracy 0.4977618621307073, loss: 1.0778648853302002\n",
      "epoch: 13, Accuracy 0.4744852282900627, loss: 1.2967450618743896\n",
      "epoch: 14, Accuracy 0.5067144136078783, loss: 1.3894537687301636\n",
      "epoch: 15, Accuracy 0.5076096687555953, loss: 1.225501298904419\n",
      "epoch: 16, Accuracy 0.4923903312444047, loss: 1.0722615718841553\n",
      "epoch: 17, Accuracy 0.5192479856759177, loss: 1.0360132455825806\n",
      "epoch: 18, Accuracy 0.5273052820053715, loss: 0.9908607602119446\n",
      "epoch: 19, Accuracy 0.5308863025962399, loss: 1.0569089651107788\n",
      "epoch: 20, Accuracy 0.5156669650850493, loss: 1.2570651769638062\n",
      "epoch: 21, Accuracy 0.5192479856759177, loss: 1.1570965051651\n",
      "epoch: 22, Accuracy 0.5219337511190689, loss: 0.9949151277542114\n",
      "epoch: 23, Accuracy 0.5452103849597135, loss: 1.1958584785461426\n",
      "epoch: 24, Accuracy 0.5398388540734109, loss: 1.1295366287231445\n",
      "epoch: 25, Accuracy 0.5228290062667861, loss: 1.170247197151184\n",
      "epoch: 26, Accuracy 0.5371530886302597, loss: 1.0205529928207397\n",
      "epoch: 27, Accuracy 0.5290957923008057, loss: 0.943462610244751\n",
      "epoch: 28, Accuracy 0.5147717099373321, loss: 1.0083887577056885\n",
      "epoch: 29, Accuracy 0.5452103849597135, loss: 0.8855180740356445\n",
      "epoch: 30, Accuracy 0.5192479856759177, loss: 0.8806307911872864\n",
      "epoch: 31, Accuracy 0.5317815577439571, loss: 0.9679017663002014\n",
      "epoch: 32, Accuracy 0.5192479856759177, loss: 1.4146583080291748\n",
      "epoch: 33, Accuracy 0.5398388540734109, loss: 1.5102612972259521\n",
      "epoch: 34, Accuracy 0.5237242614145031, loss: 1.3281843662261963\n",
      "epoch: 35, Accuracy 0.5201432408236347, loss: 1.0413248538970947\n",
      "epoch: 36, Accuracy 0.540734109221128, loss: 1.0085760354995728\n",
      "epoch: 37, Accuracy 0.5237242614145031, loss: 1.0568588972091675\n",
      "epoch: 38, Accuracy 0.5282005371530887, loss: 1.1490089893341064\n",
      "epoch: 39, Accuracy 0.5362578334825425, loss: 1.4596502780914307\n",
      "epoch: 40, Accuracy 0.5299910474485229, loss: 0.8927962183952332\n",
      "epoch: 41, Accuracy 0.5461056401074306, loss: 1.0271881818771362\n",
      "epoch: 42, Accuracy 0.5478961504028648, loss: 0.9168421030044556\n",
      "epoch: 43, Accuracy 0.5452103849597135, loss: 1.3130642175674438\n",
      "epoch: 44, Accuracy 0.5219337511190689, loss: 0.9747156500816345\n",
      "epoch: 45, Accuracy 0.5290957923008057, loss: 0.9093061089515686\n",
      "epoch: 46, Accuracy 0.5389435989256938, loss: 0.797292947769165\n",
      "epoch: 47, Accuracy 0.5398388540734109, loss: 1.0232678651809692\n",
      "epoch: 48, Accuracy 0.5505819158460161, loss: 1.0540519952774048\n",
      "epoch: 49, Accuracy 0.5487914055505819, loss: 0.9738478660583496\n",
      "epoch: 50, Accuracy 0.549686660698299, loss: 1.1579259634017944\n",
      "epoch: 51, Accuracy 0.5487914055505819, loss: 0.8246004581451416\n",
      "epoch: 52, Accuracy 0.5290957923008057, loss: 1.234617829322815\n",
      "epoch: 53, Accuracy 0.5550581915846016, loss: 1.0637251138687134\n",
      "epoch: 54, Accuracy 0.5568487018800358, loss: 1.052306056022644\n",
      "epoch: 55, Accuracy 0.540734109221128, loss: 0.9826128482818604\n",
      "epoch: 56, Accuracy 0.5738585496866607, loss: 0.814418613910675\n",
      "epoch: 57, Accuracy 0.5434198746642793, loss: 1.1514800786972046\n",
      "epoch: 58, Accuracy 0.5478961504028648, loss: 1.111778736114502\n",
      "epoch: 59, Accuracy 0.5649059982094897, loss: 1.060178279876709\n",
      "epoch: 60, Accuracy 0.567591763652641, loss: 0.8450697064399719\n",
      "epoch: 61, Accuracy 0.5577439570277529, loss: 1.2204453945159912\n",
      "epoch: 62, Accuracy 0.55863921217547, loss: 0.9314152002334595\n",
      "epoch: 63, Accuracy 0.5756490599820949, loss: 0.8387379050254822\n",
      "epoch: 64, Accuracy 0.5872873769024172, loss: 1.095975399017334\n",
      "epoch: 65, Accuracy 0.567591763652641, loss: 1.2835986614227295\n",
      "epoch: 66, Accuracy 0.6016114592658908, loss: 1.0545240640640259\n",
      "epoch: 67, Accuracy 0.576544315129812, loss: 0.9683090448379517\n",
      "epoch: 68, Accuracy 0.567591763652641, loss: 1.1157504320144653\n",
      "epoch: 69, Accuracy 0.5810205908683975, loss: 1.0952352285385132\n",
      "epoch: 70, Accuracy 0.5747538048343778, loss: 0.920017421245575\n",
      "epoch: 71, Accuracy 0.5899731423455685, loss: 0.9270889163017273\n",
      "epoch: 72, Accuracy 0.5720680393912265, loss: 1.262450098991394\n",
      "epoch: 73, Accuracy 0.5846016114592659, loss: 0.9510412812232971\n",
      "epoch: 74, Accuracy 0.5738585496866607, loss: 0.9226197600364685\n",
      "epoch: 75, Accuracy 0.5989256938227395, loss: 0.8381690382957458\n",
      "epoch: 76, Accuracy 0.5926589077887198, loss: 1.1452542543411255\n",
      "epoch: 77, Accuracy 0.5881826320501343, loss: 1.063538908958435\n",
      "epoch: 78, Accuracy 0.5908683974932856, loss: 0.9231365919113159\n",
      "epoch: 79, Accuracy 0.5971351835273053, loss: 1.124423861503601\n",
      "epoch: 80, Accuracy 0.5989256938227395, loss: 1.2465460300445557\n",
      "epoch: 81, Accuracy 0.5872873769024172, loss: 0.706945538520813\n",
      "epoch: 82, Accuracy 0.585496866606983, loss: 1.096907138824463\n",
      "epoch: 83, Accuracy 0.6114592658907789, loss: 0.9862043857574463\n",
      "epoch: 84, Accuracy 0.5872873769024172, loss: 0.968518853187561\n",
      "epoch: 85, Accuracy 0.5881826320501343, loss: 0.8568155169487\n",
      "epoch: 86, Accuracy 0.5783348254252462, loss: 0.751815915107727\n",
      "epoch: 87, Accuracy 0.5837063563115488, loss: 0.792171835899353\n",
      "epoch: 88, Accuracy 0.5998209489704566, loss: 0.9830004572868347\n",
      "epoch: 89, Accuracy 0.6025067144136079, loss: 0.7570946216583252\n",
      "epoch: 90, Accuracy 0.5890778871978514, loss: 0.9407994151115417\n",
      "epoch: 91, Accuracy 0.6007162041181737, loss: 0.9064081907272339\n",
      "epoch: 92, Accuracy 0.5953446732318711, loss: 0.9952683448791504\n",
      "epoch: 93, Accuracy 0.5926589077887198, loss: 0.9027324318885803\n",
      "epoch: 94, Accuracy 0.5837063563115488, loss: 1.5733261108398438\n",
      "epoch: 95, Accuracy 0.5998209489704566, loss: 1.3131163120269775\n",
      "epoch: 96, Accuracy 0.5935541629364369, loss: 1.1067091226577759\n",
      "epoch: 97, Accuracy 0.6150402864816473, loss: 0.8811360597610474\n",
      "epoch: 98, Accuracy 0.6016114592658908, loss: 1.1699398756027222\n",
      "epoch: 99, Accuracy 0.6016114592658908, loss: 1.3728585243225098\n",
      "epoch: 100, Accuracy 0.5962399283795882, loss: 0.8637828230857849\n",
      "epoch: 101, Accuracy 0.6051924798567592, loss: 1.0637353658676147\n",
      "epoch: 102, Accuracy 0.6042972247090421, loss: 0.8276182413101196\n",
      "epoch: 103, Accuracy 0.6025067144136079, loss: 0.9590900540351868\n",
      "epoch: 104, Accuracy 0.5971351835273053, loss: 1.1590964794158936\n",
      "epoch: 105, Accuracy 0.6051924798567592, loss: 1.0628029108047485\n",
      "epoch: 106, Accuracy 0.603401969561325, loss: 1.1385682821273804\n",
      "epoch: 107, Accuracy 0.6114592658907789, loss: 1.0978987216949463\n",
      "epoch: 108, Accuracy 0.6069829901521934, loss: 0.9148423075675964\n",
      "epoch: 109, Accuracy 0.5953446732318711, loss: 0.9018376469612122\n",
      "epoch: 110, Accuracy 0.5863921217547001, loss: 0.9915816187858582\n",
      "epoch: 111, Accuracy 0.5989256938227395, loss: 0.744805634021759\n",
      "epoch: 112, Accuracy 0.6105640107430618, loss: 0.8110692501068115\n",
      "epoch: 113, Accuracy 0.6007162041181737, loss: 1.1559604406356812\n",
      "epoch: 114, Accuracy 0.6096687555953447, loss: 0.8830485343933105\n",
      "epoch: 115, Accuracy 0.603401969561325, loss: 1.4447503089904785\n",
      "epoch: 116, Accuracy 0.6016114592658908, loss: 0.5560817122459412\n",
      "epoch: 117, Accuracy 0.6069829901521934, loss: 1.5630863904953003\n",
      "epoch: 118, Accuracy 0.6042972247090421, loss: 0.8544794321060181\n",
      "epoch: 119, Accuracy 0.6132497761862131, loss: 0.7742559313774109\n",
      "epoch: 120, Accuracy 0.6078782452999105, loss: 0.8197444677352905\n",
      "epoch: 121, Accuracy 0.6042972247090421, loss: 0.5271113514900208\n",
      "epoch: 122, Accuracy 0.6204118173679498, loss: 0.790764331817627\n",
      "epoch: 123, Accuracy 0.6096687555953447, loss: 1.171445608139038\n",
      "epoch: 124, Accuracy 0.6177260519247986, loss: 0.8424385786056519\n",
      "epoch: 125, Accuracy 0.5971351835273053, loss: 1.199110746383667\n",
      "epoch: 126, Accuracy 0.6078782452999105, loss: 1.1846513748168945\n",
      "epoch: 127, Accuracy 0.6016114592658908, loss: 0.8859715461730957\n",
      "epoch: 128, Accuracy 0.6150402864816473, loss: 0.7641097903251648\n",
      "epoch: 129, Accuracy 0.5980304386750224, loss: 0.917534351348877\n",
      "epoch: 130, Accuracy 0.5720680393912265, loss: 0.7328352332115173\n",
      "epoch: 131, Accuracy 0.603401969561325, loss: 1.2279013395309448\n",
      "epoch: 132, Accuracy 0.603401969561325, loss: 0.6411308646202087\n",
      "epoch: 133, Accuracy 0.6177260519247986, loss: 0.8089107871055603\n",
      "epoch: 134, Accuracy 0.6186213070725156, loss: 0.7606387138366699\n",
      "epoch: 135, Accuracy 0.612354521038496, loss: 0.7635940909385681\n",
      "epoch: 136, Accuracy 0.6025067144136079, loss: 0.7983664274215698\n",
      "epoch: 137, Accuracy 0.6168307967770814, loss: 1.239216923713684\n",
      "epoch: 138, Accuracy 0.6016114592658908, loss: 0.7608845829963684\n",
      "epoch: 139, Accuracy 0.6042972247090421, loss: 1.1904553174972534\n",
      "epoch: 140, Accuracy 0.6087735004476276, loss: 0.8059188723564148\n",
      "epoch: 141, Accuracy 0.6007162041181737, loss: 0.880351722240448\n",
      "epoch: 142, Accuracy 0.5890778871978514, loss: 0.9303181171417236\n",
      "epoch: 143, Accuracy 0.6016114592658908, loss: 0.8405992984771729\n",
      "epoch: 144, Accuracy 0.6141450313339302, loss: 0.7518035173416138\n",
      "epoch: 145, Accuracy 0.6042972247090421, loss: 0.9708340764045715\n",
      "epoch: 146, Accuracy 0.6105640107430618, loss: 0.8153373599052429\n",
      "epoch: 147, Accuracy 0.6096687555953447, loss: 0.7527166604995728\n",
      "epoch: 148, Accuracy 0.6159355416293644, loss: 0.6559270620346069\n",
      "epoch: 149, Accuracy 0.6105640107430618, loss: 0.7325281500816345\n",
      "epoch: 150, Accuracy 0.6051924798567592, loss: 0.7309114336967468\n",
      "epoch: 151, Accuracy 0.6257833482542524, loss: 1.0263837575912476\n",
      "epoch: 152, Accuracy 0.6177260519247986, loss: 0.9922662377357483\n",
      "epoch: 153, Accuracy 0.6257833482542524, loss: 1.0452029705047607\n",
      "epoch: 154, Accuracy 0.6141450313339302, loss: 0.8912061452865601\n",
      "epoch: 155, Accuracy 0.603401969561325, loss: 0.9113168716430664\n",
      "epoch: 156, Accuracy 0.6096687555953447, loss: 1.2589023113250732\n",
      "epoch: 157, Accuracy 0.6159355416293644, loss: 1.1683974266052246\n",
      "epoch: 158, Accuracy 0.6087735004476276, loss: 0.9009349942207336\n",
      "epoch: 159, Accuracy 0.6168307967770814, loss: 0.986351490020752\n",
      "epoch: 160, Accuracy 0.6159355416293644, loss: 1.23918616771698\n",
      "epoch: 161, Accuracy 0.6078782452999105, loss: 1.0221308469772339\n",
      "epoch: 162, Accuracy 0.6105640107430618, loss: 0.8907327651977539\n",
      "epoch: 163, Accuracy 0.6159355416293644, loss: 1.3619555234909058\n",
      "epoch: 164, Accuracy 0.6186213070725156, loss: 0.6295740604400635\n",
      "epoch: 165, Accuracy 0.6016114592658908, loss: 0.9922751188278198\n",
      "epoch: 166, Accuracy 0.5962399283795882, loss: 1.0941405296325684\n",
      "epoch: 167, Accuracy 0.6078782452999105, loss: 1.189934253692627\n",
      "epoch: 168, Accuracy 0.5917636526410027, loss: 0.7988152503967285\n",
      "epoch: 169, Accuracy 0.5953446732318711, loss: 0.8469759225845337\n",
      "epoch: 170, Accuracy 0.6230975828111012, loss: 0.680010199546814\n",
      "epoch: 171, Accuracy 0.6320501342882722, loss: 0.8983683586120605\n",
      "epoch: 172, Accuracy 0.6266786034019696, loss: 0.7522104978561401\n",
      "epoch: 173, Accuracy 0.6195165622202328, loss: 0.8616402745246887\n",
      "epoch: 174, Accuracy 0.5971351835273053, loss: 0.9624861478805542\n",
      "epoch: 175, Accuracy 0.6132497761862131, loss: 0.9096202850341797\n",
      "epoch: 176, Accuracy 0.6141450313339302, loss: 1.084877371788025\n",
      "epoch: 177, Accuracy 0.6141450313339302, loss: 0.9308215975761414\n",
      "epoch: 178, Accuracy 0.6168307967770814, loss: 0.9988492131233215\n",
      "epoch: 179, Accuracy 0.6275738585496866, loss: 0.5949912071228027\n",
      "epoch: 180, Accuracy 0.6051924798567592, loss: 0.9138550758361816\n",
      "epoch: 181, Accuracy 0.6168307967770814, loss: 0.8715276718139648\n",
      "epoch: 182, Accuracy 0.6051924798567592, loss: 0.8132922649383545\n",
      "epoch: 183, Accuracy 0.6186213070725156, loss: 0.6581071615219116\n",
      "epoch: 184, Accuracy 0.6078782452999105, loss: 1.1835088729858398\n",
      "epoch: 185, Accuracy 0.6069829901521934, loss: 1.4005125761032104\n",
      "epoch: 186, Accuracy 0.6266786034019696, loss: 1.0083836317062378\n",
      "epoch: 187, Accuracy 0.6266786034019696, loss: 1.0286606550216675\n",
      "epoch: 188, Accuracy 0.612354521038496, loss: 0.7103479504585266\n",
      "epoch: 189, Accuracy 0.6060877350044763, loss: 0.966926097869873\n",
      "epoch: 190, Accuracy 0.6078782452999105, loss: 0.9712269902229309\n",
      "epoch: 191, Accuracy 0.6141450313339302, loss: 0.9643791317939758\n",
      "epoch: 192, Accuracy 0.6275738585496866, loss: 0.7386019229888916\n",
      "epoch: 193, Accuracy 0.603401969561325, loss: 0.8167628049850464\n",
      "epoch: 194, Accuracy 0.6051924798567592, loss: 0.756681501865387\n",
      "epoch: 195, Accuracy 0.6042972247090421, loss: 0.972741425037384\n",
      "epoch: 196, Accuracy 0.6177260519247986, loss: 1.0316734313964844\n",
      "epoch: 197, Accuracy 0.6087735004476276, loss: 0.7198983430862427\n",
      "epoch: 198, Accuracy 0.6257833482542524, loss: 0.9099661707878113\n",
      "epoch: 199, Accuracy 0.6150402864816473, loss: 0.9961986541748047\n",
      "epoch: 200, Accuracy 0.6186213070725156, loss: 1.0070065259933472\n",
      "epoch: 201, Accuracy 0.6186213070725156, loss: 0.8587481379508972\n",
      "epoch: 202, Accuracy 0.6141450313339302, loss: 1.1464260816574097\n",
      "epoch: 203, Accuracy 0.6204118173679498, loss: 1.1760330200195312\n",
      "epoch: 204, Accuracy 0.6105640107430618, loss: 0.7405519485473633\n",
      "epoch: 205, Accuracy 0.6105640107430618, loss: 1.1426829099655151\n",
      "epoch: 206, Accuracy 0.5953446732318711, loss: 0.6255504488945007\n",
      "epoch: 207, Accuracy 0.612354521038496, loss: 1.013634204864502\n",
      "epoch: 208, Accuracy 0.6159355416293644, loss: 1.8436273336410522\n",
      "epoch: 209, Accuracy 0.567591763652641, loss: 1.1063930988311768\n",
      "epoch: 210, Accuracy 0.5693822739480752, loss: 0.9583280086517334\n",
      "epoch: 211, Accuracy 0.5729632945389436, loss: 1.1194862127304077\n",
      "epoch: 212, Accuracy 0.5702775290957923, loss: 1.1583294868469238\n",
      "epoch: 213, Accuracy 0.5747538048343778, loss: 0.8955351114273071\n",
      "epoch: 214, Accuracy 0.5729632945389436, loss: 1.0665080547332764\n",
      "epoch: 215, Accuracy 0.6087735004476276, loss: 0.8589242100715637\n",
      "epoch: 216, Accuracy 0.5774395702775291, loss: 1.2599103450775146\n",
      "epoch: 217, Accuracy 0.6051924798567592, loss: 0.8814167976379395\n",
      "epoch: 218, Accuracy 0.6096687555953447, loss: 0.7065092325210571\n",
      "epoch: 219, Accuracy 0.6042972247090421, loss: 0.7746845483779907\n",
      "epoch: 220, Accuracy 0.5935541629364369, loss: 1.0252981185913086\n",
      "epoch: 221, Accuracy 0.6069829901521934, loss: 1.080428957939148\n",
      "epoch: 222, Accuracy 0.6025067144136079, loss: 0.8354893326759338\n",
      "epoch: 223, Accuracy 0.6096687555953447, loss: 0.8934158682823181\n",
      "epoch: 224, Accuracy 0.6195165622202328, loss: 0.7683632373809814\n",
      "epoch: 225, Accuracy 0.6114592658907789, loss: 0.8998902440071106\n",
      "epoch: 226, Accuracy 0.6087735004476276, loss: 0.9199185371398926\n",
      "epoch: 227, Accuracy 0.6051924798567592, loss: 0.7961196899414062\n",
      "epoch: 228, Accuracy 0.630259623992838, loss: 1.0155929327011108\n",
      "epoch: 229, Accuracy 0.594449418084154, loss: 1.018338680267334\n",
      "epoch: 230, Accuracy 0.6105640107430618, loss: 0.6909663081169128\n",
      "epoch: 231, Accuracy 0.6007162041181737, loss: 0.6071099638938904\n",
      "epoch: 232, Accuracy 0.594449418084154, loss: 1.3849475383758545\n",
      "epoch: 233, Accuracy 0.6114592658907789, loss: 0.7309801578521729\n",
      "epoch: 234, Accuracy 0.5953446732318711, loss: 0.8076773285865784\n",
      "epoch: 235, Accuracy 0.6204118173679498, loss: 0.7071340680122375\n",
      "epoch: 236, Accuracy 0.6007162041181737, loss: 1.1812412738800049\n",
      "epoch: 237, Accuracy 0.622202327663384, loss: 1.0955226421356201\n",
      "epoch: 238, Accuracy 0.621307072515667, loss: 0.8931671977043152\n",
      "epoch: 239, Accuracy 0.6141450313339302, loss: 0.8029863238334656\n",
      "epoch: 240, Accuracy 0.6016114592658908, loss: 0.7693378925323486\n",
      "epoch: 241, Accuracy 0.6186213070725156, loss: 0.6448211669921875\n",
      "epoch: 242, Accuracy 0.6329453894359892, loss: 0.9771073460578918\n",
      "epoch: 243, Accuracy 0.6132497761862131, loss: 0.8274380564689636\n",
      "epoch: 244, Accuracy 0.6204118173679498, loss: 0.8821234107017517\n",
      "epoch: 245, Accuracy 0.6266786034019696, loss: 0.904194176197052\n",
      "epoch: 246, Accuracy 0.6168307967770814, loss: 1.0071907043457031\n",
      "epoch: 247, Accuracy 0.6383169203222918, loss: 0.6550975441932678\n",
      "epoch: 248, Accuracy 0.6320501342882722, loss: 0.8919433355331421\n",
      "epoch: 249, Accuracy 0.6248880931065354, loss: 0.7339033484458923\n",
      "epoch: 250, Accuracy 0.6051924798567592, loss: 0.7284182906150818\n",
      "epoch: 251, Accuracy 0.6060877350044763, loss: 0.9327837228775024\n",
      "epoch: 252, Accuracy 0.621307072515667, loss: 0.8552299737930298\n",
      "epoch: 253, Accuracy 0.6257833482542524, loss: 1.150294303894043\n",
      "epoch: 254, Accuracy 0.6284691136974038, loss: 0.8482294082641602\n",
      "epoch: 255, Accuracy 0.6284691136974038, loss: 0.8559216260910034\n",
      "epoch: 256, Accuracy 0.6338406445837064, loss: 0.8445406556129456\n",
      "epoch: 257, Accuracy 0.6275738585496866, loss: 0.9357371926307678\n",
      "epoch: 258, Accuracy 0.6257833482542524, loss: 0.798314094543457\n",
      "epoch: 259, Accuracy 0.639212175470009, loss: 1.0836598873138428\n",
      "epoch: 260, Accuracy 0.6239928379588182, loss: 0.8039199709892273\n",
      "epoch: 261, Accuracy 0.6204118173679498, loss: 0.8624910116195679\n",
      "epoch: 262, Accuracy 0.6248880931065354, loss: 0.8827313184738159\n",
      "epoch: 263, Accuracy 0.631154879140555, loss: 0.7348024249076843\n",
      "epoch: 264, Accuracy 0.6293643688451208, loss: 0.9573172330856323\n",
      "epoch: 265, Accuracy 0.6096687555953447, loss: 0.9251697063446045\n",
      "epoch: 266, Accuracy 0.6230975828111012, loss: 0.8928399682044983\n",
      "epoch: 267, Accuracy 0.6320501342882722, loss: 0.8707906603813171\n",
      "epoch: 268, Accuracy 0.6472694717994628, loss: 0.9794595241546631\n",
      "epoch: 269, Accuracy 0.6320501342882722, loss: 0.6859036684036255\n",
      "epoch: 270, Accuracy 0.621307072515667, loss: 0.7635306715965271\n",
      "epoch: 271, Accuracy 0.6356311548791406, loss: 1.0013500452041626\n",
      "epoch: 272, Accuracy 0.6293643688451208, loss: 0.7554813623428345\n",
      "epoch: 273, Accuracy 0.6338406445837064, loss: 0.9347179532051086\n",
      "epoch: 274, Accuracy 0.6347358997314234, loss: 1.272534728050232\n",
      "epoch: 275, Accuracy 0.6320501342882722, loss: 0.884580135345459\n",
      "epoch: 276, Accuracy 0.6239928379588182, loss: 1.027511477470398\n",
      "epoch: 277, Accuracy 0.6410026857654432, loss: 0.738887369632721\n",
      "epoch: 278, Accuracy 0.6275738585496866, loss: 0.9289537668228149\n",
      "epoch: 279, Accuracy 0.6499552372426142, loss: 0.5746147632598877\n",
      "epoch: 280, Accuracy 0.6329453894359892, loss: 0.6647414565086365\n",
      "epoch: 281, Accuracy 0.6418979409131602, loss: 0.9154131412506104\n",
      "epoch: 282, Accuracy 0.6427931960608774, loss: 1.2749048471450806\n",
      "epoch: 283, Accuracy 0.6454789615040286, loss: 0.7712472677230835\n",
      "epoch: 284, Accuracy 0.6383169203222918, loss: 0.8938291072845459\n",
      "epoch: 285, Accuracy 0.6320501342882722, loss: 1.056334376335144\n",
      "epoch: 286, Accuracy 0.6356311548791406, loss: 1.2612414360046387\n",
      "epoch: 287, Accuracy 0.630259623992838, loss: 0.8334974646568298\n",
      "epoch: 288, Accuracy 0.6239928379588182, loss: 0.7769935727119446\n",
      "epoch: 289, Accuracy 0.6087735004476276, loss: 0.9574305415153503\n",
      "epoch: 290, Accuracy 0.621307072515667, loss: 0.7092719674110413\n",
      "epoch: 291, Accuracy 0.6329453894359892, loss: 0.9535701870918274\n",
      "epoch: 292, Accuracy 0.6454789615040286, loss: 0.9700300693511963\n",
      "epoch: 293, Accuracy 0.6544315129811996, loss: 0.900632381439209\n",
      "epoch: 294, Accuracy 0.6374216651745748, loss: 0.7630269527435303\n",
      "epoch: 295, Accuracy 0.6436884512085944, loss: 0.9604522585868835\n",
      "epoch: 296, Accuracy 0.6472694717994628, loss: 0.644862174987793\n",
      "epoch: 297, Accuracy 0.631154879140555, loss: 0.833710789680481\n",
      "epoch: 298, Accuracy 0.6383169203222918, loss: 0.9936908483505249\n",
      "epoch: 299, Accuracy 0.6248880931065354, loss: 1.5003166198730469\n",
      "epoch: 300, Accuracy 0.6248880931065354, loss: 0.7564826011657715\n",
      "epoch: 301, Accuracy 0.622202327663384, loss: 0.9912303686141968\n",
      "epoch: 302, Accuracy 0.6383169203222918, loss: 0.8074373602867126\n",
      "epoch: 303, Accuracy 0.6365264100268576, loss: 1.3382446765899658\n",
      "epoch: 304, Accuracy 0.630259623992838, loss: 0.9157185554504395\n",
      "epoch: 305, Accuracy 0.6347358997314234, loss: 0.6760316491127014\n",
      "epoch: 306, Accuracy 0.6347358997314234, loss: 0.9015049934387207\n",
      "epoch: 307, Accuracy 0.6347358997314234, loss: 0.9020333290100098\n",
      "epoch: 308, Accuracy 0.6338406445837064, loss: 0.5770623683929443\n",
      "epoch: 309, Accuracy 0.6275738585496866, loss: 0.9874106049537659\n",
      "epoch: 310, Accuracy 0.657117278424351, loss: 0.8643103837966919\n",
      "epoch: 311, Accuracy 0.658012533572068, loss: 1.2404332160949707\n",
      "epoch: 312, Accuracy 0.657117278424351, loss: 0.856992244720459\n",
      "epoch: 313, Accuracy 0.657117278424351, loss: 0.6266211867332458\n",
      "epoch: 314, Accuracy 0.6410026857654432, loss: 0.8001649975776672\n",
      "epoch: 315, Accuracy 0.6436884512085944, loss: 0.6524569988250732\n",
      "epoch: 316, Accuracy 0.6329453894359892, loss: 0.6558305025100708\n",
      "epoch: 317, Accuracy 0.639212175470009, loss: 1.126623272895813\n",
      "epoch: 318, Accuracy 0.6589077887197852, loss: 0.6672025918960571\n",
      "epoch: 319, Accuracy 0.6418979409131602, loss: 1.422669768333435\n",
      "epoch: 320, Accuracy 0.6499552372426142, loss: 0.8077429533004761\n",
      "epoch: 321, Accuracy 0.64816472694718, loss: 1.179348349571228\n",
      "epoch: 322, Accuracy 0.631154879140555, loss: 1.2910327911376953\n",
      "epoch: 323, Accuracy 0.6651745747538048, loss: 0.8892401456832886\n",
      "epoch: 324, Accuracy 0.6651745747538048, loss: 0.8992869257926941\n",
      "epoch: 325, Accuracy 0.6454789615040286, loss: 0.974475622177124\n",
      "epoch: 326, Accuracy 0.6606982990152194, loss: 0.822878897190094\n",
      "epoch: 327, Accuracy 0.6544315129811996, loss: 0.7545475959777832\n",
      "epoch: 328, Accuracy 0.6329453894359892, loss: 0.6142715215682983\n",
      "epoch: 329, Accuracy 0.6454789615040286, loss: 0.6757007837295532\n",
      "epoch: 330, Accuracy 0.639212175470009, loss: 0.6221652626991272\n",
      "epoch: 331, Accuracy 0.6275738585496866, loss: 0.7151073217391968\n",
      "epoch: 332, Accuracy 0.6472694717994628, loss: 1.201130747795105\n",
      "epoch: 333, Accuracy 0.6463742166517458, loss: 0.9840971827507019\n",
      "epoch: 334, Accuracy 0.6598030438675022, loss: 1.2956167459487915\n",
      "epoch: 335, Accuracy 0.6427931960608774, loss: 1.0038244724273682\n",
      "epoch: 336, Accuracy 0.6508504923903312, loss: 0.7011701464653015\n",
      "epoch: 337, Accuracy 0.6589077887197852, loss: 1.1973636150360107\n",
      "epoch: 338, Accuracy 0.6338406445837064, loss: 0.7567890286445618\n",
      "epoch: 339, Accuracy 0.6723366159355416, loss: 0.9816397428512573\n",
      "epoch: 340, Accuracy 0.6553267681289168, loss: 0.6572165489196777\n",
      "epoch: 341, Accuracy 0.6553267681289168, loss: 0.7182089686393738\n",
      "epoch: 342, Accuracy 0.6374216651745748, loss: 0.6355544328689575\n",
      "epoch: 343, Accuracy 0.6633840644583706, loss: 0.9948650598526001\n",
      "epoch: 344, Accuracy 0.640107430617726, loss: 1.1210579872131348\n",
      "epoch: 345, Accuracy 0.6329453894359892, loss: 0.8846928477287292\n",
      "epoch: 346, Accuracy 0.6606982990152194, loss: 0.5812762379646301\n",
      "epoch: 347, Accuracy 0.6526410026857654, loss: 0.7834972739219666\n",
      "epoch: 348, Accuracy 0.6508504923903312, loss: 0.5168935656547546\n",
      "epoch: 349, Accuracy 0.6696508504923904, loss: 0.7905816435813904\n",
      "epoch: 350, Accuracy 0.666965085049239, loss: 0.6471163630485535\n",
      "epoch: 351, Accuracy 0.666965085049239, loss: 1.0786296129226685\n",
      "epoch: 352, Accuracy 0.6544315129811996, loss: 1.275249719619751\n",
      "epoch: 353, Accuracy 0.6562220232766338, loss: 0.7210690379142761\n",
      "epoch: 354, Accuracy 0.6329453894359892, loss: 0.7298302054405212\n",
      "epoch: 355, Accuracy 0.657117278424351, loss: 1.1797963380813599\n",
      "epoch: 356, Accuracy 0.6562220232766338, loss: 0.6142552495002747\n",
      "epoch: 357, Accuracy 0.649059982094897, loss: 0.703952431678772\n",
      "epoch: 358, Accuracy 0.666069829901522, loss: 0.4953296184539795\n",
      "epoch: 359, Accuracy 0.6329453894359892, loss: 0.6424626111984253\n",
      "epoch: 360, Accuracy 0.6615935541629364, loss: 0.9593021273612976\n",
      "epoch: 361, Accuracy 0.6598030438675022, loss: 0.962820291519165\n",
      "epoch: 362, Accuracy 0.6606982990152194, loss: 0.5519636273384094\n",
      "epoch: 363, Accuracy 0.6606982990152194, loss: 0.563273549079895\n",
      "epoch: 364, Accuracy 0.6732318710832588, loss: 0.6234962344169617\n",
      "epoch: 365, Accuracy 0.6526410026857654, loss: 0.94621342420578\n",
      "epoch: 366, Accuracy 0.6598030438675022, loss: 0.635187029838562\n",
      "epoch: 367, Accuracy 0.6696508504923904, loss: 0.9120523929595947\n",
      "epoch: 368, Accuracy 0.6544315129811996, loss: 0.7994266748428345\n",
      "epoch: 369, Accuracy 0.6651745747538048, loss: 1.0017868280410767\n",
      "epoch: 370, Accuracy 0.6517457475380484, loss: 0.6300816535949707\n",
      "epoch: 371, Accuracy 0.666965085049239, loss: 0.5998139381408691\n",
      "epoch: 372, Accuracy 0.649059982094897, loss: 0.7183985710144043\n",
      "epoch: 373, Accuracy 0.6651745747538048, loss: 1.4401164054870605\n",
      "epoch: 374, Accuracy 0.6499552372426142, loss: 0.9800851345062256\n",
      "epoch: 375, Accuracy 0.6857654431512982, loss: 1.0100059509277344\n",
      "epoch: 376, Accuracy 0.6651745747538048, loss: 0.8060928583145142\n",
      "epoch: 377, Accuracy 0.6589077887197852, loss: 0.8868292570114136\n",
      "epoch: 378, Accuracy 0.6562220232766338, loss: 0.8707167506217957\n",
      "epoch: 379, Accuracy 0.6562220232766338, loss: 0.6028580069541931\n",
      "epoch: 380, Accuracy 0.666965085049239, loss: 0.8560007810592651\n",
      "epoch: 381, Accuracy 0.6526410026857654, loss: 0.8171575665473938\n",
      "epoch: 382, Accuracy 0.6589077887197852, loss: 0.7525308132171631\n",
      "epoch: 383, Accuracy 0.6624888093106536, loss: 0.7136173844337463\n",
      "epoch: 384, Accuracy 0.6365264100268576, loss: 1.2225487232208252\n",
      "epoch: 385, Accuracy 0.657117278424351, loss: 0.7196011543273926\n",
      "epoch: 386, Accuracy 0.658012533572068, loss: 0.5250539779663086\n",
      "epoch: 387, Accuracy 0.6624888093106536, loss: 1.150062084197998\n",
      "epoch: 388, Accuracy 0.6723366159355416, loss: 0.9012033939361572\n",
      "epoch: 389, Accuracy 0.657117278424351, loss: 0.9672577977180481\n",
      "epoch: 390, Accuracy 0.6499552372426142, loss: 2.2966175079345703\n",
      "epoch: 391, Accuracy 0.6624888093106536, loss: 0.7191341519355774\n",
      "epoch: 392, Accuracy 0.666965085049239, loss: 0.7630361914634705\n",
      "epoch: 393, Accuracy 0.6768128916741272, loss: 0.698845624923706\n",
      "epoch: 394, Accuracy 0.6687555953446732, loss: 0.7773461937904358\n",
      "epoch: 395, Accuracy 0.666965085049239, loss: 1.2923121452331543\n",
      "epoch: 396, Accuracy 0.657117278424351, loss: 0.942945122718811\n",
      "epoch: 397, Accuracy 0.6544315129811996, loss: 1.0211801528930664\n",
      "epoch: 398, Accuracy 0.6830796777081468, loss: 0.7948887348175049\n",
      "epoch: 399, Accuracy 0.6821844225604298, loss: 0.6072834134101868\n",
      "epoch: 400, Accuracy 0.6589077887197852, loss: 0.4912666976451874\n",
      "epoch: 401, Accuracy 0.6678603401969562, loss: 0.7596392631530762\n",
      "epoch: 402, Accuracy 0.658012533572068, loss: 0.7965414524078369\n",
      "epoch: 403, Accuracy 0.6642793196060878, loss: 0.7766517400741577\n",
      "epoch: 404, Accuracy 0.6687555953446732, loss: 0.6506828665733337\n",
      "epoch: 405, Accuracy 0.657117278424351, loss: 0.8075258731842041\n",
      "epoch: 406, Accuracy 0.6714413607878246, loss: 0.8344467878341675\n",
      "epoch: 407, Accuracy 0.666069829901522, loss: 1.5030263662338257\n",
      "epoch: 408, Accuracy 0.6723366159355416, loss: 0.6329616904258728\n",
      "epoch: 409, Accuracy 0.6803939122649956, loss: 0.6936530470848083\n",
      "epoch: 410, Accuracy 0.6508504923903312, loss: 0.7359825968742371\n",
      "epoch: 411, Accuracy 0.6624888093106536, loss: 0.6903238296508789\n",
      "epoch: 412, Accuracy 0.6678603401969562, loss: 0.4344128966331482\n",
      "epoch: 413, Accuracy 0.6732318710832588, loss: 0.7109175324440002\n",
      "epoch: 414, Accuracy 0.6768128916741272, loss: 1.2301510572433472\n",
      "epoch: 415, Accuracy 0.666965085049239, loss: 0.4457487165927887\n",
      "epoch: 416, Accuracy 0.6589077887197852, loss: 0.7012801766395569\n",
      "epoch: 417, Accuracy 0.6615935541629364, loss: 0.749635636806488\n",
      "epoch: 418, Accuracy 0.6732318710832588, loss: 1.0410776138305664\n",
      "epoch: 419, Accuracy 0.6606982990152194, loss: 0.8211546540260315\n",
      "epoch: 420, Accuracy 0.6714413607878246, loss: 0.5336048007011414\n",
      "epoch: 421, Accuracy 0.675022381378693, loss: 0.6530815362930298\n",
      "epoch: 422, Accuracy 0.6768128916741272, loss: 0.6531762480735779\n",
      "epoch: 423, Accuracy 0.675022381378693, loss: 0.6558632850646973\n",
      "epoch: 424, Accuracy 0.675022381378693, loss: 0.8267757892608643\n",
      "epoch: 425, Accuracy 0.6651745747538048, loss: 1.6384758949279785\n",
      "epoch: 426, Accuracy 0.6508504923903312, loss: 1.0294996500015259\n",
      "epoch: 427, Accuracy 0.6768128916741272, loss: 0.8551688194274902\n",
      "epoch: 428, Accuracy 0.6553267681289168, loss: 1.2878363132476807\n",
      "epoch: 429, Accuracy 0.6696508504923904, loss: 0.5996127128601074\n",
      "epoch: 430, Accuracy 0.6723366159355416, loss: 1.2939982414245605\n",
      "epoch: 431, Accuracy 0.683974932855864, loss: 0.8257602453231812\n",
      "epoch: 432, Accuracy 0.6830796777081468, loss: 0.621020495891571\n",
      "epoch: 433, Accuracy 0.6723366159355416, loss: 1.094201922416687\n",
      "epoch: 434, Accuracy 0.6714413607878246, loss: 0.9040147066116333\n",
      "epoch: 435, Accuracy 0.675022381378693, loss: 0.887406587600708\n",
      "epoch: 436, Accuracy 0.6732318710832588, loss: 0.7600165009498596\n",
      "epoch: 437, Accuracy 0.6812891674127126, loss: 0.5024679899215698\n",
      "epoch: 438, Accuracy 0.6911369740376008, loss: 0.856087863445282\n",
      "epoch: 439, Accuracy 0.6821844225604298, loss: 0.4135315418243408\n",
      "epoch: 440, Accuracy 0.6786034019695614, loss: 0.8072124123573303\n",
      "epoch: 441, Accuracy 0.6812891674127126, loss: 0.6815744042396545\n",
      "epoch: 442, Accuracy 0.6651745747538048, loss: 0.6610760688781738\n",
      "epoch: 443, Accuracy 0.6642793196060878, loss: 0.6973413825035095\n",
      "epoch: 444, Accuracy 0.6902417188898836, loss: 0.9983865022659302\n",
      "epoch: 445, Accuracy 0.683974932855864, loss: 0.7119308710098267\n",
      "epoch: 446, Accuracy 0.6741271262309758, loss: 0.8432656526565552\n",
      "epoch: 447, Accuracy 0.6589077887197852, loss: 0.6370348334312439\n",
      "epoch: 448, Accuracy 0.6615935541629364, loss: 0.8950265645980835\n",
      "epoch: 449, Accuracy 0.6965085049239033, loss: 0.8453266024589539\n",
      "epoch: 450, Accuracy 0.675022381378693, loss: 0.8177701234817505\n",
      "epoch: 451, Accuracy 0.666069829901522, loss: 0.7436415553092957\n",
      "epoch: 452, Accuracy 0.6741271262309758, loss: 0.8257915377616882\n",
      "epoch: 453, Accuracy 0.6651745747538048, loss: 0.5588703751564026\n",
      "epoch: 454, Accuracy 0.6911369740376008, loss: 1.107640027999878\n",
      "epoch: 455, Accuracy 0.683974932855864, loss: 0.7740707397460938\n",
      "epoch: 456, Accuracy 0.658012533572068, loss: 0.769214928150177\n",
      "epoch: 457, Accuracy 0.6768128916741272, loss: 0.5831126570701599\n",
      "epoch: 458, Accuracy 0.683974932855864, loss: 1.0403050184249878\n",
      "epoch: 459, Accuracy 0.6696508504923904, loss: 2.494851589202881\n",
      "epoch: 460, Accuracy 0.6902417188898836, loss: 0.6858826279640198\n",
      "epoch: 461, Accuracy 0.6768128916741272, loss: 0.6800902485847473\n",
      "epoch: 462, Accuracy 0.6821844225604298, loss: 0.8480824828147888\n",
      "epoch: 463, Accuracy 0.6517457475380484, loss: 0.6713231801986694\n",
      "epoch: 464, Accuracy 0.6875559534467324, loss: 0.44511327147483826\n",
      "epoch: 465, Accuracy 0.6786034019695614, loss: 0.9572504758834839\n",
      "epoch: 466, Accuracy 0.693822739480752, loss: 0.5458458662033081\n",
      "epoch: 467, Accuracy 0.683974932855864, loss: 0.9993715882301331\n",
      "epoch: 468, Accuracy 0.6866606982990152, loss: 0.725435197353363\n",
      "epoch: 469, Accuracy 0.684870188003581, loss: 0.5167797803878784\n",
      "epoch: 470, Accuracy 0.6768128916741272, loss: 0.49444445967674255\n",
      "epoch: 471, Accuracy 0.6830796777081468, loss: 0.3134500980377197\n",
      "epoch: 472, Accuracy 0.666069829901522, loss: 0.9366883039474487\n",
      "epoch: 473, Accuracy 0.6705461056401074, loss: 0.8992226719856262\n",
      "epoch: 474, Accuracy 0.6911369740376008, loss: 2.2392256259918213\n",
      "epoch: 475, Accuracy 0.6696508504923904, loss: 0.6028949618339539\n",
      "epoch: 476, Accuracy 0.684870188003581, loss: 0.7239975333213806\n",
      "epoch: 477, Accuracy 0.6812891674127126, loss: 0.8575497269630432\n",
      "epoch: 478, Accuracy 0.6956132497761862, loss: 0.623298168182373\n",
      "epoch: 479, Accuracy 0.7036705461056401, loss: 0.21475929021835327\n",
      "epoch: 480, Accuracy 0.6633840644583706, loss: 0.8754966855049133\n",
      "epoch: 481, Accuracy 0.6893464637421666, loss: 0.8480328917503357\n",
      "epoch: 482, Accuracy 0.6696508504923904, loss: 1.057023286819458\n",
      "epoch: 483, Accuracy 0.684870188003581, loss: 0.6612364649772644\n",
      "epoch: 484, Accuracy 0.7000895255147717, loss: 0.9503067135810852\n",
      "epoch: 485, Accuracy 0.67591763652641, loss: 0.5723773837089539\n",
      "epoch: 486, Accuracy 0.6982990152193375, loss: 0.6005005836486816\n",
      "epoch: 487, Accuracy 0.6705461056401074, loss: 1.3165925741195679\n",
      "epoch: 488, Accuracy 0.6651745747538048, loss: 0.8014809489250183\n",
      "epoch: 489, Accuracy 0.6920322291853178, loss: 0.8965373039245605\n",
      "epoch: 490, Accuracy 0.6866606982990152, loss: 0.6422195434570312\n",
      "epoch: 491, Accuracy 0.6714413607878246, loss: 1.0573889017105103\n",
      "epoch: 492, Accuracy 0.6723366159355416, loss: 1.2119524478912354\n",
      "epoch: 493, Accuracy 0.7072515666965085, loss: 0.7879548668861389\n",
      "epoch: 494, Accuracy 0.6732318710832588, loss: 0.7958281636238098\n",
      "epoch: 495, Accuracy 0.6929274843330349, loss: 0.6837940216064453\n",
      "epoch: 496, Accuracy 0.6741271262309758, loss: 1.4348328113555908\n",
      "epoch: 497, Accuracy 0.6884512085944494, loss: 0.8125942945480347\n",
      "epoch: 498, Accuracy 0.6920322291853178, loss: 0.9972432255744934\n",
      "epoch: 499, Accuracy 0.6794986571172784, loss: 0.6667001843452454\n",
      "effort results on User 1\n",
      "train_acc: 69.11369740376007\tsample_size: 1117\n",
      "test_acc: 63.21428571428571\tsample_size: 280\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attention</td>\n",
       "      <td>61.145927</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interest</td>\n",
       "      <td>67.949866</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effort</td>\n",
       "      <td>69.113697</td>\n",
       "      <td>63.214286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  train_acc   test_acc  user\n",
       "0  attention  61.145927  67.500000     1\n",
       "1   interest  67.949866  65.000000     1\n",
       "2     effort  69.113697  63.214286     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_file = \"examples/User_1_sampled_annotated_EEG.pickle\"\n",
    "with open(sampled_file, 'rb') as handle:\n",
    "    dt = pickle.load(handle)\n",
    "\n",
    "labels = [\"attention\", \"interest\", \"effort\"]\n",
    "\n",
    "results = []\n",
    "for label in labels:\n",
    "    \n",
    "    X = dt[\"inputs\"]\n",
    "    y = dt[label]\n",
    "\n",
    "    #Convert the categories into labels \n",
    "    le = LabelEncoder()\n",
    "    y =  le.fit_transform(y)\n",
    "\n",
    "    #Train/test split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "    # scale the data \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "    #Convert to 4D \n",
    "    X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1],X_train.shape[2])\n",
    "    X_test = X_test.reshape(X_test.shape[0],1, X_test.shape[1],X_test.shape[2])\n",
    "\n",
    "    #Create train and test loader\n",
    "    train = data_utils.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train).long())\n",
    "    test = data_utils.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "    train_loader = data_utils.DataLoader(train, batch_size=50, shuffle=True)\n",
    "    test_loader = data_utils.DataLoader(test, batch_size=50, shuffle=False)\n",
    "    \n",
    "    # train the network\n",
    "    net = train_network(X_train, train_loader, 'hybrid', verbose=True)\n",
    "    \n",
    "    #get results\n",
    "    Results = namedtuple(\"Results\",\"label train_acc test_acc user\")\n",
    "    train_acc = get_accuracy(train_loader, test_loader, \"train\", net)\n",
    "    test_acc = get_accuracy(train_loader, test_loader, \"test\", net)\n",
    "    print(\"{0} results on User 1\\ntrain_acc: {1}\\tsample_size: {2}\\ntest_acc: {3}\\tsample_size: {4}\\n\".format(label, \n",
    "                                                                                           train_acc,  len(X_train),\n",
    "                                                                                            test_acc, len(X_test)))\n",
    "    results.append(Results(label, train_acc, test_acc,1))\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(\"results/EEGNet/user1_results_sampled_annotated.csv\", index=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

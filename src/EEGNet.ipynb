{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fedacc9a090>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ipynb.fs.full.Data_Processing import extract_test_number\n",
    "from ipynb.fs.full.Data_Processing import get_samples\n",
    "from sklearn import preprocessing\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "torch.set_printoptions(linewidth=120) #Display options for output\n",
    "torch.set_grad_enabled(True) # Already on by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 8), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*7, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = x.float()\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # FC Layer\n",
    "        x = x.view(-1, 4*2*7)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate function returns values of different criteria like accuracy, precision etc.**\n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(X)//batch_size):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X))\n",
    "    predicted = model(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted , multi_class=\"ovr\"))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted), average='macro'))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted) , average='macro'))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted) , average='macro')\n",
    "            recall = recall_score(Y, np.round(predicted) , average='macro')\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate random data**\n",
    "    \n",
    "*Data format:*\n",
    "\n",
    "Datatype - float32 (both X and Y)\n",
    "\n",
    "X.shape - (#samples, 1, #timepoints, #channels)\n",
    "\n",
    "Y.shape - (#samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ex = np.random.rand(100, 1, 120, 8).astype('float32') # np.random.rand generates between [0, 1)\n",
    "y_train_ex = np.round(np.random.rand(100).astype('float32')) # binary data, so we round it to 0 or 1.\n",
    "\n",
    "X_val = np.random.rand(100, 1, 120, 8).astype('float32')\n",
    "y_val = np.round(np.random.rand(100).astype('float32'))\n",
    "\n",
    "X_test = np.random.rand(100, 1, 120, 8).astype('float32')\n",
    "y_test = np.round(np.random.rand(100).astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_and_labels = get_samples(sample_size=120)\n",
    "inputs = inputs_and_labels['inputs']\n",
    "targets_attention = inputs_and_labels['attention']\n",
    "\n",
    "#Convert the categories into labels \n",
    "le = LabelEncoder()\n",
    "targets_attention = le.fit_transform(targets_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6949, 120, 8), (6949,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets_attention, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1390"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "\n",
    "#Convert to 4D \n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1],X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0],1, X_test.shape[1],X_test.shape[2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "train = data_utils.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "test = data_utils.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_loader = data_utils.DataLoader(train, batch_size=50, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "  return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Accuracy 0.9532289980212268, loss: 0.17539890110492706\n",
      "epoch: 1, Accuracy 0.9870480302212629, loss: 0.0019378432771191\n",
      "epoch: 2, Accuracy 0.9935240151106314, loss: 0.2706335783004761\n",
      "epoch: 3, Accuracy 0.9823709300233855, loss: 0.008593092672526836\n",
      "epoch: 4, Accuracy 0.9935240151106314, loss: 0.8923484086990356\n"
     ]
    }
   ],
   "source": [
    "net = EEGNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
    "\n",
    "preds_list = []\n",
    "labels_list = []\n",
    "for epoch in range(5):\n",
    "    \n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "    #Get Batch\n",
    "    \n",
    "        inputs = batch[0]\n",
    "        labels = batch[1]\n",
    "\n",
    "\n",
    "        preds = net(inputs) #Pass batch\n",
    "    #     criterion=nn.BCEWithLogitsLoss()\n",
    "        loss = F.cross_entropy(preds, labels.long()) #calculate loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #calculate gradients\n",
    "        optimizer.step() #update weights\n",
    "\n",
    "\n",
    "        preds_list.append(preds)\n",
    "        labels_list.append(labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    \n",
    "#     Validation accuracy\n",
    "#     params = [\"acc\", \"fmeasure\"]\n",
    "#     print (params)\n",
    "#     print (\"Train - \", evaluate(net, X_train, y_train_new, params))\n",
    "    print(\"epoch: {0}, Accuracy {1}, loss: {2}\".format(epoch, total_correct/len(X_train), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 1390 test samples: 98.92086330935251\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\"Accuracy of the network on {0} test samples: {1}\".format(total, (correct/total * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21828.2227, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/ybk1/python/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21817.4297, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  2\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21808.3184, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  3\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21764.4453, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  4\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21782.6660, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  5\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21819.1113, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  6\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21773.5547, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  7\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21791.7773, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  8\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21837.3340, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  9\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21810., device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  10\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21804.9570, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  11\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21757.6758, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  12\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21776.6465, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  13\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21810., device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  14\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21810., device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  15\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21786.7344, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  16\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21800.8887, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  17\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21788.4141, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  18\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21782.6660, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  19\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21791.7773, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  20\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21773.5547, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  21\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21810., device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  22\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21782.6660, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  23\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21791.7773, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  24\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21791.7773, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  25\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21800.8887, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  26\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21810., device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  27\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21791.7773, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  28\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21782.6660, device='cuda:0')\n",
      "Train -  [0.0, nan]\n",
      "\n",
      "Epoch  29\n",
      "['acc', 'fmeasure']\n",
      "Training Loss  tensor(-21800.8887, device='cuda:0')\n",
      "Train -  [0.0, nan]\n"
     ]
    }
   ],
   "source": [
    "# new training loo\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        inputs = batch[0].to(\"cuda\")\n",
    "        labels = batch[1].to(\"cuda\")\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"fmeasure\"]\n",
    "    print (params)\n",
    "    print (\"Training Loss \", running_loss)\n",
    "    print (\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "#     print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "#     print (\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print (\"\\nEpoch \", epoch)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(len(t10_AT_X_train)//batch_size-1): # x_train\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = torch.from_numpy(t10_AT_X_train[s:e]) # x_train\n",
    "        labels = torch.FloatTensor(np.array([t10_AT_y_train[s:e]]).T*1.0)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda(0)), Variable(labels.cuda(0))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data\n",
    "    \n",
    "    # Validation accuracy\n",
    "    params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "    print (params)\n",
    "    print (\"Training Loss \", running_loss)\n",
    "    print (\"Train - \", evaluate(net, t10_AT_X_train, t10_AT_y_train, params))\n",
    "#     print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "#     print (\"Test - \", evaluate(net, X_test, y_test, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

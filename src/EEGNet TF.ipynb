{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Sample script using EEGNet to classify Event-Related Potential (ERP) EEG data\n",
    " from a four-class classification task, using the sample dataset provided in\n",
    " the MNE [1, 2] package:\n",
    "     https://martinos.org/mne/stable/manual/sample_dataset.html#ch-sample-data\n",
    "   \n",
    " The four classes used from this dataset are:\n",
    "     LA: Left-ear auditory stimulation\n",
    "     RA: Right-ear auditory stimulation\n",
    "     LV: Left visual field stimulation\n",
    "     RV: Right visual field stimulation\n",
    "\n",
    " The code to process, filter and epoch the data are originally from Alexandre\n",
    " Barachant's PyRiemann [3] package, released under the BSD 3-clause. A copy of \n",
    " the BSD 3-clause license has been provided together with this software to \n",
    " comply with software licensing requirements. \n",
    " \n",
    " When you first run this script, MNE will download the dataset and prompt you\n",
    " to confirm the download location (defaults to ~/mne_data). Follow the prompts\n",
    " to continue. The dataset size is approx. 1.5GB download. \n",
    " \n",
    " For comparative purposes you can also compare EEGNet performance to using \n",
    " Riemannian geometric approaches with xDAWN spatial filtering [4-8] using \n",
    " PyRiemann (code provided below).\n",
    "\n",
    " [1] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck,\n",
    "     L. Parkkonen, M. Hämäläinen, MNE software for processing MEG and EEG data, \n",
    "     NeuroImage, Volume 86, 1 February 2014, Pages 446-460, ISSN 1053-8119.\n",
    "\n",
    " [2] A. Gramfort, M. Luessi, E. Larson, D. Engemann, D. Strohmeier, C. Brodbeck, \n",
    "     R. Goj, M. Jas, T. Brooks, L. Parkkonen, M. Hämäläinen, MEG and EEG data \n",
    "     analysis with MNE-Python, Frontiers in Neuroscience, Volume 7, 2013.\n",
    "\n",
    " [3] https://github.com/alexandrebarachant/pyRiemann. \n",
    "\n",
    " [4] A. Barachant, M. Congedo ,\"A Plug&Play P300 BCI Using Information Geometry\"\n",
    "     arXiv:1409.0107. link\n",
    "\n",
    " [5] M. Congedo, A. Barachant, A. Andreev ,\"A New generation of Brain-Computer \n",
    "     Interface Based on Riemannian Geometry\", arXiv: 1310.8115.\n",
    "\n",
    " [6] A. Barachant and S. Bonnet, \"Channel selection procedure using riemannian \n",
    "     distance for BCI applications,\" in 2011 5th International IEEE/EMBS \n",
    "     Conference on Neural Engineering (NER), 2011, 348-351.\n",
    "\n",
    " [7] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, “Multiclass \n",
    "     Brain-Computer Interface Classification by Riemannian Geometry,” in IEEE \n",
    "     Transactions on Biomedical Engineering, vol. 59, no. 4, p. 920-928, 2012.\n",
    "\n",
    " [8] A. Barachant, S. Bonnet, M. Congedo and C. Jutten, “Classification of \n",
    "     covariance matrices using a Riemannian-based kernel for BCI applications“, \n",
    "     in NeuroComputing, vol. 112, p. 172-178, 2013.\n",
    "\n",
    "\n",
    " Portions of this project are works of the United States Government and are not\n",
    " subject to domestic copyright protection under 17 USC Sec. 105.  Those \n",
    " portions are released world-wide under the terms of the Creative Commons Zero \n",
    " 1.0 (CC0) license.  \n",
    " \n",
    " Other portions of this project are subject to domestic copyright protection \n",
    " under 17 USC Sec. 105.  Those portions are licensed under the Apache 2.0 \n",
    " license.  The complete text of the license governing this material is in \n",
    " the file labeled LICENSE.TXT that is a part of this project's official \n",
    " distribution. \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# mne imports\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "\n",
    "# EEGNet-specific imports\n",
    "from EEGModels import EEGNet\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# PyRiemann imports\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tools for plotting confusion matrices\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default location ~/mne_data for sample...\n",
      "Downloading archive MNE-sample-data-processed.tar.gz to /cs/home/ybk1/mne_data\n",
      "Downloading https://files.osf.io/v1/resources/rxvq7/providers/osfstorage/59c0e26f9ad5a1025c4ab159?version=5&action=download&direct (1.54 GB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce825a5bed8489ca954ec936d402b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1652769680.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying hash 12b75d1cb7df9dfb4ad73ed82f61094f.\n",
      "Decompressing the archive: /cs/home/ybk1/mne_data/MNE-sample-data-processed.tar.gz\n",
      "(please be patient, this can take some time)\n"
     ]
    }
   ],
   "source": [
    "##################### Process, filter and epoch the data ######################\n",
    "data_path = sample.data_path()\n",
    "\n",
    "# Set parameters and read data\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "event_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\n",
    "tmin, tmax = -0., 1\n",
    "event_id = dict(aud_l=1, aud_r=2, vis_l=3, vis_r=4)\n",
    "\n",
    "# Setup for reading the raw data\n",
    "raw = io.Raw(raw_fname, preload=True, verbose=False)\n",
    "raw.filter(2, None, method='iir')  # replace baselining with high-pass\n",
    "events = mne.read_events(event_fname)\n",
    "\n",
    "raw.info['bads'] = ['MEG 2443']  # set bad channels\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read epochs\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True, verbose=False)\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "# extract raw data. scale by 1000 due to scaling sensitivity in deep learning\n",
    "X = epochs.get_data()*1000 # format is in (trials, channels, samples)\n",
    "y = labels\n",
    "\n",
    "kernels, chans, samples = 1, 60, 151\n",
    "\n",
    "# take 50/25/25 percent of the data to train/validate/test\n",
    "X_train      = X[0:144,]\n",
    "Y_train      = y[0:144]\n",
    "X_validate   = X[144:216,]\n",
    "Y_validate   = y[144:216]\n",
    "X_test       = X[216:,]\n",
    "Y_test       = y[216:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# EEGNet portion ##################################\n",
    "\n",
    "# convert labels to one-hot encodings.\n",
    "Y_train      = np_utils.to_categorical(Y_train-1)\n",
    "Y_validate   = np_utils.to_categorical(Y_validate-1)\n",
    "Y_test       = np_utils.to_categorical(Y_test-1)\n",
    "\n",
    "# convert data to NCHW (trials, kernels, channels, samples) format. Data \n",
    "# contains 60 channels and 151 time-points. Set the number of kernels to 1.\n",
    "X_train      = X_train.reshape(X_train.shape[0], kernels, chans, samples)\n",
    "X_validate   = X_validate.reshape(X_validate.shape[0], kernels, chans, samples)\n",
    "X_test       = X_test.reshape(X_test.shape[0], kernels, chans, samples)\n",
    "   \n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# configure the EEGNet-8,2,16 model with kernel length of 32 samples (other \n",
    "# model configurations may do better, but this is a good starting point)\n",
    "model = EEGNet(nb_classes = 4, Chans = chans, Samples = samples, \n",
    "               dropoutRate = 0.5, kernLength = 32, F1 = 8, D = 2, F2 = 16, \n",
    "               dropoutType = 'Dropout')\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# count number of parameters in the model\n",
    "numParams    = model.count_params()    \n",
    "\n",
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "###############################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, accuracy_score, balanced_accuracy_score\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification performance on EEG Dataset\n",
    "\n",
    "Get with 5 fold cross-validation and performance on the test set\n",
    "- Load the data of each user for all tests \n",
    "- Get performance per user - attention, interest, effort\n",
    "- Get performance per user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_base_model(model_type, objective):\n",
    "    # choose model\n",
    "    if model_type == 'clf':\n",
    "        model = LGBMClassifier(objective=objective,num_leaves=31, learning_rate=0.1, random_state=5)\n",
    "        return model\n",
    "    else: \n",
    "        model = LGBMRegressor(num_leaves=31, learning_rate=0.1, random_state=5)\n",
    "        return model\n",
    "\n",
    "def choose_obj(num_classes):\n",
    "    if num_classes == 2:\n",
    "        objective = 'binary'\n",
    "        return objective\n",
    "    else: \n",
    "        objective = 'multiclass' \n",
    "        return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_predict(X,y, model_type):\n",
    "    \"\"\"\n",
    "    Method for running 5 fold cross validation based on a given array of tests\n",
    "    \"\"\"\n",
    "    kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "    \n",
    "    if model_type == 'clf':\n",
    "        results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "              \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "    else:\n",
    "        results = {'RMSE':[], 'R2':[]}\n",
    "        \n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    num_classes = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        #Train/test split\n",
    "        X_train, X_test = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "        y_train, y_test = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "        total_true.append(y_test)\n",
    "        size = len(X_train) + len(X_test)\n",
    "        \n",
    "        if len(set(y_train)) > num_classes:\n",
    "            num_classes = len(set(y_train))\n",
    "        objective = choose_obj(num_classes)           \n",
    "        model = choose_base_model(model_type, objective).fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        total_predictions.append(y_pred)\n",
    "        r = get_results(y_test, y_pred, model_type) # get dictionary of all results\n",
    "        \n",
    "        for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "            results[key].append(r[key])\n",
    "\n",
    "    for key in results: # average out the results \n",
    "        results[key] = average(results[key])\n",
    "\n",
    "    return results, np.concatenate(total_predictions), np.concatenate(total_true) , num_classes , size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_results(r, user, label, num_classes, duration, size, model_type):\n",
    "    \"\"\"\n",
    "    Method for collating the results in a single tuple\n",
    "    :r: results \n",
    "    :user: current user\n",
    "    :num_classes: number of targets \n",
    "    \"\"\"\n",
    "    if model_type == 'clf':\n",
    "        Results = namedtuple(\"Results\",\"user label num_classes duration size accuracy bal_acc precision recall f1_score_macro f1_score_micro\")\n",
    "        collated_results = Results(user, label, num_classes, duration,  size, r['Accuracy'], r['Balanced Accuracy'], r['Precision'], r['Recall'], \n",
    "                                      r['F1 Score Macro'], r['F1 Score Micro'])\n",
    "    else: \n",
    "        Results = namedtuple(\"Results\",\"user label num_classes duration  size RMSE R2\")\n",
    "        collated_results = Results(user, label, num_classes, duration, size, r['RMSE'], r['R2'])\n",
    "    return collated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_per_user(all_users, users, results, labels , bandpass, model_type):\n",
    "    \"\"\"\n",
    "    Method for getting results per user by applying 5 fold cross validation.\n",
    "    \"\"\"\n",
    "    for user in users:\n",
    "        print(\"Running User {0}\".format(user))\n",
    "\n",
    "        for label in labels:\n",
    "            time_start = time.time()\n",
    "            test_list = all_users[user] # list of all the tests\n",
    "            if bandpass == True:\n",
    "                X = np.array([np.array(filter_df(test.iloc[:,:8])) for test in test_list]) # filtered array of all the inputs for each test\n",
    "            else:\n",
    "                X = np.array([np.array(test.iloc[:,:8]) for test in test_list]) # array of all the inputs for each test\n",
    "            y = np.array([np.array(test[label]) for test in test_list]) # array of given labels for each test           \n",
    "\n",
    "            # get results\n",
    "            r, y_pred, y_true, num_classes, size = kfold_predict(X,y, model_type)\n",
    "            duration = time.time() - time_start\n",
    "            results.append(collate_results(r, user, label, num_classes, duration, size, model_type))\n",
    "\n",
    "            if model_type == 'clf':\n",
    "                # plot confusion matrix\n",
    "                cm = confusion_matrix(y_true, y_pred)\n",
    "                saved_file = \"results/baseline/confusion matrices/k_fold_performance/LGBM_User_{0}_{1}.png\".format(user,label)\n",
    "                plot_confusion_matrix(cm, set(y_true), normalize=True , file = saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_cross_users(labels, all_users_agg, results, bandpass, model_type):\n",
    "    \"\"\"\n",
    "    Method for getting results cross-user using 5-Fold cross-validation\n",
    "    \"\"\"\n",
    "    user = 'cross'\n",
    "    # get the results cross-user\n",
    "    for label in labels: #put the inputs and labels in an array for K-fold\n",
    "        time_start = time.time()\n",
    "        if bandpass == True: # filter the channels using bandpass filtering\n",
    "            X = np.array([np.array(filter_df(all_users_agg[key].iloc[:, :8] )) for key in all_users_agg]) #array of aggregated inputs per user\n",
    "        else:\n",
    "            X = np.array([np.array(all_users_agg[key].iloc[:, :8] ) for key in all_users_agg])\n",
    "        y = np.array([np.array(all_users_agg[key][label]) for key in all_users_agg]) # array of aggregated labels per user        \n",
    "\n",
    "        # get results \n",
    "        r, y_pred, y_true, num_classes , size = kfold_predict(X,y, model_type)\n",
    "        duration = time.time() - time_start\n",
    "        results.append(collate_results(r, user, label, num_classes, duration, size, model_type))\n",
    "\n",
    "        if model_type == 'clf':\n",
    "            # plot confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            saved_file = \"results/baseline/confusion matrices/k_fold_performance/LGBM_User_{0}_{1}.png\".format('all',label)\n",
    "            plot_confusion_matrix(cm, set(y_true), normalize=True , file = saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(model_type):\n",
    "    \"\"\"\n",
    "    Method for getting all results per user and across users by applying 5 fold cross validation.\n",
    "    \"\"\"\n",
    "    # Load all the data\n",
    "    per_user_path = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_tests_EEG_no_agg.pickle\"\n",
    "    all_user_path = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_tests_EEG.pickle\"\n",
    "    all_users_no_agg = load_file(per_user_path) # dictionary of all users , where tests are split out by user without aggregation for per user analysis\n",
    "    all_users_agg = load_file(all_user_path) # dictionary of all users, where tests are aggregated by user for cross-user analysis\n",
    "    \n",
    "    users = all_users_no_agg.keys()\n",
    "    results = []\n",
    "    labels = ['attention','interest','effort']\n",
    "    order = 4\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # get the results per user\n",
    "#     get_results_per_user(all_users_no_agg, users, results, labels, True, model_type)\n",
    "\n",
    "     # get the results cross user\n",
    "    get_results_cross_users(labels, all_users_agg, results , True,  model_type)\n",
    "\n",
    "    if model_type == 'clf':\n",
    "        results  = pd.DataFrame(results).to_csv(\"results/baseline/tabulated/k fold/LGBM_5_fold_CV_performance_all_user_bandpass.csv\", index=False)\n",
    "    else:\n",
    "        results  = pd.DataFrame(results).to_csv(\"results/baseline/regression/LGBM_5_fold_CV_performance_cross_user_bandpass_{0}.csv\".format(model_type), index=False)\n",
    "    print(\"Time elapsed! {0}\".format(time.time() - time_start))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed! 255.7533459663391\n"
     ]
    }
   ],
   "source": [
    "r = get_all_results('reg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import namedtuple\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipynb.fs.full.evaluation import *\n",
    "from ipynb.fs.full.Data_Processing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classification performance on EEG Dataset\n",
    "\n",
    "Get with 5 fold cross-validation and performance on the test set\n",
    "- Load the data of each user for all tests \n",
    "- Get performance per user - attention, interest, effort\n",
    "- Get performance per user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_base_model(model_type, objective, model_name):\n",
    "    # choose model\n",
    "    if model_type == 'clf':\n",
    "        model_dict = {'RF': RandomForestClassifier(random_state=0, n_jobs=-1),\n",
    "            'NB': GaussianNB(),\n",
    "            'SVM': LinearSVC(random_state=0, tol=1e-05),\n",
    "            'LGBM': LGBMClassifier(objective=objective, num_leaves=31, learning_rate=0.1,  random_state=5),\n",
    "            'LDA': LinearDiscriminantAnalysis()}       \n",
    "        return model_dict[model_name]\n",
    "    else: \n",
    "        model = LGBMRegressor(num_leaves=31, learning_rate=0.1, random_state=5)\n",
    "        return model\n",
    "    \n",
    "\n",
    "def choose_obj(num_classes):\n",
    "    if num_classes == 2:\n",
    "        objective = 'binary'\n",
    "        return objective\n",
    "    else: \n",
    "        objective = 'multiclass' \n",
    "        return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_predict(X,y, model_type, model_name, class_type):\n",
    "    \"\"\"\n",
    "    Method for running 5 fold cross validation based on a given array of tests\n",
    "    \"\"\"\n",
    "    kf= KFold(n_splits = 5, shuffle = True, random_state =  1)\n",
    "    \n",
    "    if model_type == 'clf':\n",
    "        results = {\"Accuracy\":[], \"Precision\":[], \"Recall\":[], \"F1 Score Macro\":[],\n",
    "              \"F1 Score Micro\":[],\"Balanced Accuracy\":[]}\n",
    "    else:\n",
    "        results = {'RMSE':[], 'R2':[]}\n",
    "        \n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "    num_classes = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        #Train/test split\n",
    "        X_train, X_test = np.concatenate(X[train_index]), np.concatenate(X[test_index])\n",
    "        y_train, y_test = np.concatenate(y[train_index]).astype('int'), np.concatenate(y[test_index]).astype('int')\n",
    "        \n",
    "        #used for finding the maximum number of classes during the 5 fold cross validation\n",
    "        if len(set(y_train)) > num_classes:\n",
    "            num_classes = len(set(y_train))\n",
    "        \n",
    "        #Determine whether it will be multi or binary classification\n",
    "        if class_type == 'binary':\n",
    "            y_train = convert_to_binary(y_train)\n",
    "            y_test = convert_to_binary(y_test)\n",
    "            objective =class_type\n",
    "        else:\n",
    "            objective = choose_obj(num_classes) #choose whether it is binary or multi for LGBM's objective\n",
    "            \n",
    "        #get size for reporting\n",
    "        size = len(X_train) + len(X_test)\n",
    "        \n",
    "        \n",
    "            \n",
    "        model = choose_base_model(model_type, objective, model_name).fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        total_predictions.append(y_pred) # keep track of total predictions\n",
    "        total_true.append(y_test) # keep track of total true for confusion matrix\n",
    "        r = get_results(y_test, y_pred, model_type) # get dictionary of all results\n",
    "        \n",
    "        for key in r: # loop through dictionary to add to all the scores to the results dictionary\n",
    "            results[key].append(r[key])\n",
    "\n",
    "    for key in results: # average out the results after 5 fold cross validation\n",
    "        results[key] = average(results[key])\n",
    "\n",
    "    return results, np.concatenate(total_predictions), np.concatenate(total_true) , num_classes , size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots(model_type, y_true, y_pred, user,label, model_name, class_type):\n",
    "    if model_type == 'clf':\n",
    "        # plot confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        saved_file = \"results/baseline/clf/confusion matrices/k_fold_performance/{2}_User_{0}_{1}_class{3}_.png\".format(user,label, model_name, class_type)\n",
    "        plot_confusion_matrix(cm, set(y_true), normalize=True , file = saved_file)\n",
    "    if model_type == 'reg':\n",
    "        saved_file = \"results/baseline/reg/y vs y_pred/per user/{2}_User_{0}_{1}_class{3}.png\".format(user,label, model_name, class_typ)\n",
    "        plot_model(y_true, y_pred, user, label,file=saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_per_user(all_users, users, labels , bandpass, model_type, multiple, sigma , class_type):\n",
    "    \"\"\"\n",
    "    Method for getting results per user by applying 5 fold cross validation.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "#     model_names =     ['RF', 'NB', 'LGBM', 'LDA']\n",
    "    model_names = ['LGBM']\n",
    "  \n",
    "    n_epochs = None\n",
    "    window_size_samples = None\n",
    "    for model_name in model_names:\n",
    "        print(\"Starting with Baseline Model: {0}...\".format(model_name))\n",
    "        for user in users:\n",
    "            \n",
    "            for label in labels:\n",
    "                print(\"Running - ClassType {3}, Model: {0}, User: {1}, label: {2}\".format(model_name, user,label, class_type))\n",
    "                time_start = time.time()\n",
    "                test_list = all_users[user] # list of all the tests\n",
    "                if bandpass == True:\n",
    "                    X = np.array([filter_sample(np.array(test.iloc[:,:8])) for test in test_list]) # filtered array of all the inputs for each test\n",
    "                else:\n",
    "                    X = np.array([np.array(test.iloc[:,:8]) for test in test_list]) # array of all the inputs for each test\n",
    "                y = np.array([np.array(test[label]) for test in test_list]) # array of given labels for each test           \n",
    "\n",
    "                # get results\n",
    "                r, y_pred, y_true, num_classes, size = kfold_predict(X,y, model_type, model_name, class_type)\n",
    "                duration = time.time() - time_start\n",
    "                results.append(collate_results(r, user, label, duration, \n",
    "                                               num_classes, size, model_type, \n",
    "                                               n_epochs, window_size_samples,\n",
    "                                               model_name, multiple, sigma, bandpass, class_type))\n",
    "\n",
    "                #save resuls\n",
    "                save_plots(model_type, y_true, y_pred, user,label, model_name, class_type)\n",
    " \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_cross_users(labels, all_users_agg, bandpass, model_type, multiple, sigma , class_type):\n",
    "    \"\"\"\n",
    "    Method for getting results cross-user using 5-Fold cross-validation\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    user = 'cross'\n",
    "#     model_names =     ['RF', 'NB', 'LGBM', 'LDA']\n",
    "    model_names = ['LGBM']\n",
    "\n",
    "    n_epochs = None\n",
    "    window_size_samples = None\n",
    "    for model_name in model_names:\n",
    "        print(\"Starting with Baseline Model: {0}...\".format(model_name))\n",
    "    \n",
    "        # get the results cross-user\n",
    "        for label in labels: #put the inputs and labels in an array for K-fold\n",
    "            print(\"Running - Class Type: {3}, Model: {0}, User: {1}, label: {2}\".format(model_name, user,label, class_type))\n",
    "            time_start = time.time()\n",
    "            if bandpass == True: # filter the channels using bandpass filtering\n",
    "                X = np.array([np.array(filter_sample(all_users_agg[key].iloc[:, :8] )) for key in all_users_agg]) #array of aggregated inputs per user\n",
    "            else:\n",
    "                X = np.array([np.array(all_users_agg[key].iloc[:, :8] ) for key in all_users_agg])\n",
    "            y = np.array([np.array(all_users_agg[key][label]) for key in all_users_agg]) # array of aggregated labels per user        \n",
    "\n",
    "            # get results \n",
    "            r, y_pred, y_true, num_classes , size = kfold_predict(X,y, model_type, model_name, class_type)\n",
    "            duration = time.time() - time_start\n",
    "            results.append(collate_results(r, user, label, duration, \n",
    "                                           num_classes, size, model_type, \n",
    "                                           n_epochs, window_size_samples, \n",
    "                                           model_name, multiple, sigma, bandpass, class_type))\n",
    "\n",
    "            # save results\n",
    "            save_plots(model_type, y_true, y_pred, user,label, model_name, class_type)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(model_type, bandpass, eval_type, class_type):\n",
    "    \"\"\"\n",
    "    Method for getting all results per user and across users by applying 5 fold cross validation.\n",
    "    \"\"\"\n",
    "    # Load all the data\n",
    "    per_user_path = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_tests_EEG_no_agg.pickle\"\n",
    "    all_user_path = \"/cs/home/ybk1/Dissertation/data/saved user and test data/all_tests_EEG.pickle\"\n",
    "    all_users_no_agg = load_file(per_user_path) # dictionary of all users , where tests are split out by user without aggregation for per user analysis\n",
    "    all_users_agg = load_file(all_user_path) # dictionary of all users, where tests are aggregated by user for cross-user analysis\n",
    "    \n",
    "    users = all_users_no_agg.keys()\n",
    "  \n",
    "    labels = ['attention','interest','effort']\n",
    "    multiple = None\n",
    "    sigma = None\n",
    "    time_start = time.time()\n",
    "    \n",
    "    file = \"results/baseline/{0}/tabulated/k fold/baselines_5_fold_CV_performance_{1}_bandpass_{2}_class_{3}.csv\".format(model_type, eval_type, bandpass, class_type)\n",
    "    if eval_type == 'per user':\n",
    "        # get the results per user\n",
    "        results = get_results_per_user(all_users_no_agg, users, labels, bandpass, model_type, multiple, sigma , class_type)\n",
    "        results  = pd.DataFrame(results).to_csv(file, index=False)\n",
    "\n",
    "    elif eval_type == 'cross user':\n",
    "        #get results cross user\n",
    "        results = get_results_cross_users(labels, all_users_agg, bandpass,  model_type, multiple, sigma , class_type)\n",
    "        results  = pd.DataFrame(results).to_csv(file, index=False)\n",
    "\n",
    "    elif eval_type == 'both':\n",
    "        results = []\n",
    "        results.append(pd.DataFrame(get_results_cross_users(labels, all_users_agg, bandpass,  model_type, multiple, sigma , class_type)))\n",
    "        results.append(pd.DataFrame(get_results_per_user(all_users_no_agg, users, labels, bandpass, model_type, multiple, sigma , class_type)))                     \n",
    "        results = pd.concat(results).to_csv(file, index=False)\n",
    "       \n",
    "  \n",
    "\n",
    "    print(\"Time elapsed! {0}\".format(time.time() - time_start))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Baseline Model: LGBM...\n",
      "Running - Class Type: multi, Model: LGBM, User: cross, label: attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-261ba826460c>\", line 1, in <module>\n",
      "    r = get_all_results('clf', False, 'both', 'multi')\n",
      "  File \"<ipython-input-18-17d1b0c27ae1>\", line 31, in get_all_results\n",
      "    results.append(pd.DataFrame(get_results_cross_users(labels, all_users_agg, bandpass,  model_type, multiple, sigma , class_type)))\n",
      "  File \"<ipython-input-17-e34259aa2282>\", line 26, in get_results_cross_users\n",
      "    r, y_pred, y_true, num_classes , size = kfold_predict(X,y, model_type, model_name, class_type)\n",
      "  File \"<ipython-input-14-112c1207783f>\", line 39, in kfold_predict\n",
      "    model = choose_base_model(model_type, objective, model_name).fit(X_train,y_train)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/lightgbm/sklearn.py\", line 805, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/lightgbm/sklearn.py\", line 600, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/lightgbm/engine.py\", line 249, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/lightgbm/basic.py\", line 1976, in update\n",
      "    ctypes.byref(is_finished)))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/cs/home/ybk1/python/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/local/python/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/usr/local/python/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "r = get_all_results('clf', False, 'both', 'multi')\n",
    "r2 = get_all_results('clf', True, 'both', 'multi')\n",
    "\n",
    "r3 = pd.concat(r1,r2).to_csv(\"results/bulk/LGBM_bandpass_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
